## Correction of Distribution Shifts

### Covariate Shift Correction

### Label Shift Correction

### Concept Shift Correction

**Concept Shift** is much harder to fix in a principled manner.
For instance, in a situation where the problem suddenly changes from
classifying **`cats` v/s `dogs`** to classying **`white` v/s `black` animals**;
it will be _unreasonable_ to assume that we can do much better by collecting new labels and training
from scratch.

Fortunately, in practice such concept-shifts are very rare, but instead it is usually observed that the 
_task keeps on changing gradually_. For example:

1. Traffic Camera lenses degrade over time due to wear-&-tear and hence the quality of images degrade too.
2. News content changes gradually; i.e. new stories appear while the news still remain almost same.
3. In computational advertising, new products gets launched and hence popularity of products changes 
and the CTR-Predictor needs to change as well.

In such above cases, we use the same strategy that we used while trainign the network to make them 
adapt to change in data i.e.; we use **Transfer Learning** by finetuning the pre-trained weights with
the new aquired data.

## A taxonomy of Learning Problems

Armed with the knowledge of dealing with changes in the distribution of data/labels, 
we now focus on otehr aspects of machine learning formulations:

### Batch Learning

