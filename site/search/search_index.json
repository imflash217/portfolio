{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Contact Details vkumar24@ncsu.edu https://www.linkedin.com/in/imflash217 https://www.github.com/imflash217 My motivation Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import torch as pt import pytorch_lightning as pl ####################################################################### class FlashModel ( pl . LightningModule ): \"\"\"This defines a MODEL\"\"\" def __init__ ( self , num_layers : int = 3 ): super () . __init__ () self . layer1 = pt . nn . Linear () self . layer2 = pt . nn . Linear () self . layer3 = pt . nn . Linear () class FlashModel ( pl . LightningModule ): \"\"\"This defines a SYSTEM\"\"\" def __init__ ( self , encoder : pt . nn . Module = None , decoder : pt . nn . Module = None ): super () . __init__ () self . encoder = encoder self . decoder = decoder","title":"About me"},{"location":"algorithms/023_add_lists/","text":"Add lists Write in a function that takes head of two linked lists , each representing a number. The nodes of the linked-lists contain digits as value. The nodes in the input lists are reversed (i.e. the least significant digit of the number is head). The function should return the head of the new linked list representing the sum of the input lists. The output should have its digits reversed as well. 1 2 3 4 5 6 7 8 9 10 11 12 13 Say we wanted to compute 621 + 354 normally. The sum is 975: 621 + 354 ----- 975 Then, the reversed linked list format of this problem would appear as: 1 -> 2 -> 6 + 4 -> 5 -> 3 -------------- 5 -> 7 -> 9 Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Node : def __init__ ( self , val ): super () . __init__ () self . val = val self . next = None def add_lists ( head_1 , head_2 , carry = 0 ): \"\"\"Recursive solution\"\"\" ## base case: if head_1 is None and head_2 is None and carry == 0 : return None ## grab the values of each node ## or use a dummy value 0 if the node is None val_1 = head_1 . val if head_1 else 0 val_2 = head_2 . val if head_2 else 0 _sum = val_1 + val_2 + carry ## add the two values digit = _sum % 10 ## accounting for carry (next line) carry = 1 if _sum >= 10 else 0 result = Node ( digit ) ## create a new \"Node\" with new digit next_1 = head_1 . next if head_1 else None next_2 = head_2 . next if head_2 else None result . next = add_lists ( next_1 , next_2 , carry ) ## recursive call return result","title":"023_add_lists"},{"location":"blogs/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In scelerisque nibh non dolor mollis congue sed et metus Hariom \u0970\u0970 \u0939\u0930\u093f \u0950 \u0917\u0941\u0930\u0941 \u0970\u0970 DONE Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"blogs/algorithms/blog_01292021_hashtables/","text":"Hash Tables Author: Vinay Kumar (@imflash217) | Date: 29/January/2021 Definition Definition Hash Table is a data structure which stores data in an associative manner (i.e. in a (key, value) pair). In a hash table, the data is stored in an array format where each data-value has its own unique index-value. Due to this feature, the access to data becomes very fast if we know the desired index-value; irrespective of the size of the data. Hash Table uses an array as a storage medium and uses hashing to generate the index where an element is to be inserted or to be located from. Hashing Hashing Hashing is a technique to map a range of keys into a range of indexes (usually of an array). A very generic hashing function is modulo operator ( x % y ). Example Example of Hashing Consider a hash-table of size=20 Following ( key , value ) pairs to be stored using the hash-table 1 2 3 4 5 dict = { 9 : 20 , 12 : 70 , 42 : 80 , 7 : 25 , 2 : 21 } Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 2 As we can see that a given hashing function can create the same hash-value from two different keys. (in above table keys 42 and 2 ). So we use Linear Probing to resolve conflicts. Linear Probing Linear Probing Linear Probing is a method used to resolve conflicts in the hash-value. It may happen that the hash-function creates an already used index of the array. In such case we search the next empty location of the array by looking into the next cell until we find an empty cell So in our above example, the updated hash-table would map key = 2 to index = 3 : Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 3 Search search() method for hash-table Search Delete delete() method for hash-table Delete Python Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 class HashTable : def __init__ ( self , table_size ): \"\"\" Args: table_size (int): the size of the hash table. \"\"\" super () . __init__ () self . table_size = table_size self . hash_table = [[] for _ in range ( self . table_size )] ## ! this kind of nested lists DS is useful for CHAINING def hashing_func ( self , key ): \"\"\"Hashing Function Args: key (int): the key Returns: [int]: index of the hash-table \"\"\" hash = key % self . table_size return hash def insert_linear_probing ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using LINEAR PROBING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) if len ( self . hash_table [ hash_key ]) == 0 : self . hash_table [ hash_key ] . append ( value ) else : ## ! collision happened. so search for the available slot pass def insert ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using TABLE CHAINING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) key_exists = False bucket = self . hash_table [ hash_key ] # print(bucket) for i , kv in enumerate ( bucket ): # print(i, kv) k , v = kv if k == key : key_exists = True break if key_exists : bucket [ i ] = ( key , value ) ## ! the original key already exists. So OVERRIDE else : bucket . append (( key , value )) ## ! two different keys COLLIDING. So APPEND using CHAINING def search ( self , key ): \"\"\"Searching for a \"key\" and returning its (key, value) pair Args: key (int): any hashable type (as per the hash function used) Returns: (key, value) pair \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] for i , kv in enumerate ( bucket ): k , v = kv if k == key : return ( k , v ) def delete ( self , key ): \"\"\"Delete a given key (if present in the hashtable) Args: key ([type]): [description] \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] key_exists = False for i , kv in enumerate ( bucket ): k , v = kv if k == key : key_exists = True break if key_exists : del bucket [ i ] print ( f \"key = { key } is deleted.\" ) else : print ( f \"key= { key } not found.\" ) ########################################################################################## if __name__ == \"__main__\" : import pprint hashtable = HashTable ( table_size = 9 ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 12 , value = \"barry\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 13 , value = \"vinay\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash217\" ) pprint . pprint ( hashtable . hash_table ) ## searching pprint . pprint ( hashtable . search ( key = 32 )) ## deleting hashtable . delete ( key = 13 ) pprint . pprint ( hashtable . hash_table ) ########################################################################################## Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 29/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References https://www.hackerearth.com/practice/data-structures/hash-tables/basics-of-hash-tables/tutorial/ \u21a9 https://www.tutorialspoint.com/python_data_structure/python_hash_table.htm \u21a9 https://www.tutorialspoint.com/data_structures_algorithms/hash_data_structure.htm \u21a9 http://blog.chapagain.com.np/hash-table-implementation-in-python-data-structures-algorithms/ \u21a9 https://runestone.academy/runestone/books/published/pythonds/SortSearch/Hashing.html \u21a9 http://paulmouzas.github.io/2014/12/31/implementing-a-hash-table.html \u21a9","title":"Hash Tables"},{"location":"blogs/algorithms/blog_01292021_hashtables/#hash-tables","text":"Author: Vinay Kumar (@imflash217) | Date: 29/January/2021","title":"Hash Tables"},{"location":"blogs/algorithms/blog_01292021_hashtables/#definition","text":"Definition Hash Table is a data structure which stores data in an associative manner (i.e. in a (key, value) pair). In a hash table, the data is stored in an array format where each data-value has its own unique index-value. Due to this feature, the access to data becomes very fast if we know the desired index-value; irrespective of the size of the data. Hash Table uses an array as a storage medium and uses hashing to generate the index where an element is to be inserted or to be located from.","title":"Definition"},{"location":"blogs/algorithms/blog_01292021_hashtables/#hashing","text":"Hashing Hashing is a technique to map a range of keys into a range of indexes (usually of an array). A very generic hashing function is modulo operator ( x % y ).","title":"Hashing"},{"location":"blogs/algorithms/blog_01292021_hashtables/#example","text":"Example of Hashing Consider a hash-table of size=20 Following ( key , value ) pairs to be stored using the hash-table 1 2 3 4 5 dict = { 9 : 20 , 12 : 70 , 42 : 80 , 7 : 25 , 2 : 21 } Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 2 As we can see that a given hashing function can create the same hash-value from two different keys. (in above table keys 42 and 2 ). So we use Linear Probing to resolve conflicts.","title":"Example"},{"location":"blogs/algorithms/blog_01292021_hashtables/#linear-probing","text":"Linear Probing Linear Probing is a method used to resolve conflicts in the hash-value. It may happen that the hash-function creates an already used index of the array. In such case we search the next empty location of the array by looking into the next cell until we find an empty cell So in our above example, the updated hash-table would map key = 2 to index = 3 : Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 3","title":"Linear Probing"},{"location":"blogs/algorithms/blog_01292021_hashtables/#search","text":"search() method for hash-table Search","title":"Search"},{"location":"blogs/algorithms/blog_01292021_hashtables/#delete","text":"delete() method for hash-table Delete","title":"Delete"},{"location":"blogs/algorithms/blog_01292021_hashtables/#python-implementation","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 class HashTable : def __init__ ( self , table_size ): \"\"\" Args: table_size (int): the size of the hash table. \"\"\" super () . __init__ () self . table_size = table_size self . hash_table = [[] for _ in range ( self . table_size )] ## ! this kind of nested lists DS is useful for CHAINING def hashing_func ( self , key ): \"\"\"Hashing Function Args: key (int): the key Returns: [int]: index of the hash-table \"\"\" hash = key % self . table_size return hash def insert_linear_probing ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using LINEAR PROBING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) if len ( self . hash_table [ hash_key ]) == 0 : self . hash_table [ hash_key ] . append ( value ) else : ## ! collision happened. so search for the available slot pass def insert ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using TABLE CHAINING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) key_exists = False bucket = self . hash_table [ hash_key ] # print(bucket) for i , kv in enumerate ( bucket ): # print(i, kv) k , v = kv if k == key : key_exists = True break if key_exists : bucket [ i ] = ( key , value ) ## ! the original key already exists. So OVERRIDE else : bucket . append (( key , value )) ## ! two different keys COLLIDING. So APPEND using CHAINING def search ( self , key ): \"\"\"Searching for a \"key\" and returning its (key, value) pair Args: key (int): any hashable type (as per the hash function used) Returns: (key, value) pair \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] for i , kv in enumerate ( bucket ): k , v = kv if k == key : return ( k , v ) def delete ( self , key ): \"\"\"Delete a given key (if present in the hashtable) Args: key ([type]): [description] \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] key_exists = False for i , kv in enumerate ( bucket ): k , v = kv if k == key : key_exists = True break if key_exists : del bucket [ i ] print ( f \"key = { key } is deleted.\" ) else : print ( f \"key= { key } not found.\" ) ########################################################################################## if __name__ == \"__main__\" : import pprint hashtable = HashTable ( table_size = 9 ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 12 , value = \"barry\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 13 , value = \"vinay\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash217\" ) pprint . pprint ( hashtable . hash_table ) ## searching pprint . pprint ( hashtable . search ( key = 32 )) ## deleting hashtable . delete ( key = 13 ) pprint . pprint ( hashtable . hash_table ) ########################################################################################## Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 29/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Python Implementation"},{"location":"blogs/algorithms/blog_01292021_hashtables/#references","text":"https://www.hackerearth.com/practice/data-structures/hash-tables/basics-of-hash-tables/tutorial/ \u21a9 https://www.tutorialspoint.com/python_data_structure/python_hash_table.htm \u21a9 https://www.tutorialspoint.com/data_structures_algorithms/hash_data_structure.htm \u21a9 http://blog.chapagain.com.np/hash-table-implementation-in-python-data-structures-algorithms/ \u21a9 https://runestone.academy/runestone/books/published/pythonds/SortSearch/Hashing.html \u21a9 http://paulmouzas.github.io/2014/12/31/implementing-a-hash-table.html \u21a9","title":"References"},{"location":"blogs/algorithms/blog_01312021_sorting/","text":"Sorting Algorithms Insertion Sort Vanilla Insertion Sort Vanilla Insertion Sort 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"pairwise swaps\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(n)\\) comparisons. SO this version of the algorithm is \\(\\theta(n^2)\\) runtime complexity. Binary Insertion Sort Binary Insertion Sort This improved version is slightly improved by using Binary Search while searching for the position to place the key A[i] in the sorted part of the array (i.e. A[0:i-1] ) 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"Binary Search\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(\\log(n))\\) comparisons due to Binary Search. SO this version of the algorithm is \\(\\theta(n\\times \\log(n))\\) runtime complexity (in sorting but not in swappings ). If we consider swapping operations too then even Binary Search will take \\(\\theta(n)\\) time to swap positions as it might have to move a lot of positions. References https://twitter.com/pottolama/status/1354745837524553728 \u21a9 https://github.com/mportesi/sorting_algo_visualizer \u21a9","title":"Sorting"},{"location":"blogs/algorithms/blog_01312021_sorting/#sorting-algorithms","text":"","title":"Sorting Algorithms"},{"location":"blogs/algorithms/blog_01312021_sorting/#insertion-sort","text":"","title":"Insertion Sort"},{"location":"blogs/algorithms/blog_01312021_sorting/#vanilla-insertion-sort","text":"Vanilla Insertion Sort 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"pairwise swaps\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(n)\\) comparisons. SO this version of the algorithm is \\(\\theta(n^2)\\) runtime complexity.","title":"Vanilla Insertion Sort"},{"location":"blogs/algorithms/blog_01312021_sorting/#binary-insertion-sort","text":"Binary Insertion Sort This improved version is slightly improved by using Binary Search while searching for the position to place the key A[i] in the sorted part of the array (i.e. A[0:i-1] ) 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"Binary Search\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(\\log(n))\\) comparisons due to Binary Search. SO this version of the algorithm is \\(\\theta(n\\times \\log(n))\\) runtime complexity (in sorting but not in swappings ). If we consider swapping operations too then even Binary Search will take \\(\\theta(n)\\) time to swap positions as it might have to move a lot of positions.","title":"Binary Insertion Sort"},{"location":"blogs/algorithms/blog_01312021_sorting/#references","text":"https://twitter.com/pottolama/status/1354745837524553728 \u21a9 https://github.com/mportesi/sorting_algo_visualizer \u21a9","title":"References"},{"location":"blogs/algorithms/blog_02012021_document_distance/","text":"Document Distance Call Graph for the code 1 2 3 4 5 6 - main() - word_frequencies_for_file() - get_words_from_line_list() - count_frequency() - vector_angle() - inner_product() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"Document Distance"},{"location":"blogs/algorithms/blog_02012021_document_distance/#document-distance","text":"Call Graph for the code 1 2 3 4 5 6 - main() - word_frequencies_for_file() - get_words_from_line_list() - count_frequency() - vector_angle() - inner_product() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Document Distance"},{"location":"blogs/algorithms/blog_02012021_document_distance/#references","text":"","title":"References"},{"location":"blogs/algorithms/blog_02012021_priority_queue/","text":"Priority Queue Definition Implements a set S of elements; each of the elements is associated with a key Operations: search() , insert() , delete() , change_priorities() , max_priority() , min_priority() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"Priority Queue"},{"location":"blogs/algorithms/blog_02012021_priority_queue/#priority-queue","text":"Definition Implements a set S of elements; each of the elements is associated with a key Operations: search() , insert() , delete() , change_priorities() , max_priority() , min_priority() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Priority Queue"},{"location":"blogs/algorithms/blog_02012021_priority_queue/#references","text":"","title":"References"},{"location":"blogs/algorithms/blog_03152021_arrays/","text":"Arrays Author: Vinay Kumar (@imflash217) | Date: 15/March/2021 Definition Definition An Array is an ordered list of data that we access with a numerical index. Generally speaking an array is allocated upfront as a single block of memory based on the number of elements and type of the data we want the array to hold. This allows us to read and write elements into the array efficiently, since our program knows exactly where each element is stored in the memory. On the other hand removing , adding and finding arbitrary values in an array can be a linear-time operation. Removing or splicing requires shifting all elements by one to fill the gap. Inserting a new element would requires shifting or allocating a new larger array to hold the elements. Finding an element in the array would require iterating over the entire array in the worst-case. Dynamic Array Dynamic Arrays It is worth noting that in many statically-typed programming languages (e.g. Java, C++); an array is limited to its initially declared size . ALL modern languages support DYNAMICALLY-SIZED arrays; which automatically increase or decrease their size by allocating a new copy of the array when it begins to run out-of-memory. Dynamic arrays guarantee better amortized performance by only performing these costly operations when necessary. Calculating Memory Usage Calculating Memory Usage To calculate the memory usage of an array simply multiply the size of the array with the size of the data-type. What is the memory usage of an array that contains one-thousand 32-bit integers? 1 1000 * 32 bits = 1000 * 4 bytes = 4000 bytes = 4Kb What is the memory usage of an array that contains one-hundred 10-char strings? 1 100 * 10 chars = 100 * 10 * 1 byte = 1000 bytes = 1Kb Common Array Operations Common Array Operations Insert an item Remove an item Update an item Find an item Loop over array Copy an array Copy-part-of-the-array Sort an array Reverse an array Swap an array Filter an array When to use an array in an interview When to use an array in an interview Use an array when you need dta in an ordered list with fast-indexing or compact-memory-footprint . Don't use an array if you need to search for unsorted items efficiently or insert and remove items frequently.","title":"Arrays"},{"location":"blogs/algorithms/blog_03152021_arrays/#arrays","text":"Author: Vinay Kumar (@imflash217) | Date: 15/March/2021","title":"Arrays"},{"location":"blogs/algorithms/blog_03152021_arrays/#definition","text":"Definition An Array is an ordered list of data that we access with a numerical index. Generally speaking an array is allocated upfront as a single block of memory based on the number of elements and type of the data we want the array to hold. This allows us to read and write elements into the array efficiently, since our program knows exactly where each element is stored in the memory. On the other hand removing , adding and finding arbitrary values in an array can be a linear-time operation. Removing or splicing requires shifting all elements by one to fill the gap. Inserting a new element would requires shifting or allocating a new larger array to hold the elements. Finding an element in the array would require iterating over the entire array in the worst-case.","title":"Definition"},{"location":"blogs/algorithms/blog_03152021_arrays/#dynamic-array","text":"Dynamic Arrays It is worth noting that in many statically-typed programming languages (e.g. Java, C++); an array is limited to its initially declared size . ALL modern languages support DYNAMICALLY-SIZED arrays; which automatically increase or decrease their size by allocating a new copy of the array when it begins to run out-of-memory. Dynamic arrays guarantee better amortized performance by only performing these costly operations when necessary.","title":"Dynamic Array"},{"location":"blogs/algorithms/blog_03152021_arrays/#calculating-memory-usage","text":"Calculating Memory Usage To calculate the memory usage of an array simply multiply the size of the array with the size of the data-type. What is the memory usage of an array that contains one-thousand 32-bit integers? 1 1000 * 32 bits = 1000 * 4 bytes = 4000 bytes = 4Kb What is the memory usage of an array that contains one-hundred 10-char strings? 1 100 * 10 chars = 100 * 10 * 1 byte = 1000 bytes = 1Kb","title":"Calculating Memory Usage"},{"location":"blogs/algorithms/blog_03152021_arrays/#common-array-operations","text":"Common Array Operations Insert an item Remove an item Update an item Find an item Loop over array Copy an array Copy-part-of-the-array Sort an array Reverse an array Swap an array Filter an array","title":"Common Array Operations"},{"location":"blogs/algorithms/blog_03152021_arrays/#when-to-use-an-array-in-an-interview","text":"When to use an array in an interview Use an array when you need dta in an ordered list with fast-indexing or compact-memory-footprint . Don't use an array if you need to search for unsorted items efficiently or insert and remove items frequently.","title":"When to use an array in an interview"},{"location":"blogs/deep_learning/blog_dataloaders/","text":"PyTorch Dataloaders","title":"PyTorch Dataloaders"},{"location":"blogs/deep_learning/blog_dataloaders/#pytorch-dataloaders","text":"","title":"PyTorch Dataloaders"},{"location":"blogs/deep_learning/blog_tf_v1/","text":"Tensorflow Tutorial In this session you will learn to do the following in TensorFlow v1.0 Initialize Variables Start your own session Train Algorithms Implement a Neural Network Exploring the Tensorflow Library Example-1: General Overview 1 2 3 4 5 6 7 8 9 10 11 12 13 import tensorflow as tf y_hat = tf . constant ( 36 , name = \"y_hat\" ) ## Defins a \"y_hat\" constant. Sets its value to 36 y = tf . constant ( 39 , name = \"y\" ) ## Defins a \"y\" constant. Sets its value to 39 loss = tf . Variable (( y - y_hat ) ** 2 , name = \"loss\" ) init = tf . global_variables_initializer () ## Used to initialize the variables with the ## respective values when \"sess.run(init)\" is called with tf . Session () as sess : ## Creates a session to execute our program sess . run ( init ) ## initializes the global variables sess . run ( loss ) ## executes the program stored in \"loss\" variable print ( loss ) ## prints the value stored in \"loss\" variable Writing and running programs in Tensorflow has the following steps: Create tensors (variables) that are not yet evaluated/executed. Write operations between those tensors. Initialize the tensors. Create a Session . Run the session . This will run the operations written in step-2. So, when we created a variable for loss , we simply defined the loss as a function of other quantities but did not evaluate its value. To evaluate it, we had to run tf.global_variables_initializer() to intialize the values and then inside sess.run(init) we calculated the updated value and prited it in the last line above. Example-2: tf.Session() Now, let's take a look at 1 2 3 4 a = tf . constant ( 2 ) b = tf . constant ( 10 ) c = tf . multiply ( a , b ) print ( c ) 1 Tensor(\"Mul:0\", shape=(), dtype=int32) As expected we will not see 20 . We got a tensor saying that the result of the tensor does not have the shape attribute and is of the type int32 . All we did was to put in the computation graph ; but we haven't run this computation yet! In order to actually multiply the two numbers we have to create a sessiona nd run it. 1 2 sess = tf . Session () print ( sess . run ( c )) 1 20 Awesome!! . To summarize, remember the following: Initialize your variables. Create a session. Run the operations inside the session. Example-3: tf.placeholder() Next, we will see how to use a placeholder. A placeholder is an object whose value we can specify ONLY later. To specify values for a placeholder, we can pass in values by using a \"feed dictionary\" ( feed_dict variable). 1 2 3 4 5 6 7 8 9 ## Below we create a placeholder for x. ## This allows us to pass in a number later when we run the SESSION sess = tf . Session () x = tf . placeholder ( tf . int64 , name = \"x\" ) ## the placeholder variable print ( sess . run ( 2 * x , feed_dict = { x : 9 })) sess . close () 1 18 Using one-hot encodings: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def one_hot_matrix ( labels , num_classes ): \"\"\" Creates a matrix where the i-th row corresponds to the ith class number. j-th column corresponds to the j-th example. So, if the label for j-th example is i; then only the ith value is 1 in j-th column Args: labels: the labels for each example num_classes: the number of classes in this task Returns: a one-hot matrix \"\"\" ## create a tf.constant & name it \"num_classes\" num_classes = tf . constant ( num_classes , name = \"num_classes\" ) ## Use tf.one_hot (be careful with \"axis\") one_hot_matrix = tf . one_hot ( indices = labels , depth = num_classes , axis = 0 ) ## Create a session sess = tf . Session () ## Execute the one_hot_matrix graph inside the session one_hot = sess . run ( one_hot_matrix ) ## Close the session sess . close () ## return the one_hot matrix return one_hot 1 2 3 4 5 6 import numpy as np labels = np . array ([ 1 , 2 , 0 , 1 , 2 , 2 , 3 ]) num_classes = 4 one_hot = one_hot_matrix ( labels , num_classes ) print ( one_hot ) 1 2 3 4 [[0,0,1,0,0,0,0], [1,0,0,1,0,0,0], [0,1,0,0,1,1,0], [0,0,0,0,0,0,1]] Initialize with zeros & ones We will use tf.ones() and tf.zeros() to initialize a tensor of shape shape , where all elements are either zeros or ones 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def ones ( shape , dtype = tf . int64 ): \"\"\"Creates a tensor of ones with shape=shape Args: shape: the shape of the resulting tensor dtype: the datatype of every element in the resulting tensor Returns: A tensor where all elements are 1 \"\"\" ## Create ones tensor using `tf.ones()` ones = tf . ones ( shape , dtype = dtype ) ## Create a session sess = tf . Session () ## Execute the op in the session to calculate its value ones = sess . run ( ones ) ## Close the session sess . close () ## Return the ones tensor return ones 1 2 ones_tensor = ones ([ 2 , 3 ]) print ( ones_tensor ) 1 2 [[1,1,1], [1,1,1]] Building a Neural Network Building the model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 from tf_utils import load_dataset , random_mini_batches , convert_to_one_hot , predict from tensorflow.python.framework import ops def model ( X_train , Y_train , X_test , Y_test , lr = 1e-3 , num_epochs = 1500 , bs = 32 , verbose = True ): \"\"\" Implements a 3-layer Tensorflow Neural Network: [Linear]->[Relu]->[Linear]->[Relu]->[Linear]-[Softmax] Args: X_train: the train dataset inputs Y_train: the train dataset labels X_test: the test dataset inputs Y_test: the test dataset labels lr: the learnign rate num_epochs: number of epochs bs: batch-size verbose: True if you want to print the process else False Returns: the trained model parameters. \"\"\" ops . reset_default_graph () ## to be able to rerun the model, w/o overwriting the tf.variables tf . set_random_seed ( 217 ) ## to keep consistent results seed = 3 ## to keep consistent results ( n_x , m ) = X_train . shape ## n_x = input size; m = number of training examples n_y = Y_train . shape [ 0 ] ## n_y = output size costs = [] ## to keep track of the costs ## Step-1: Create placeholders of shape = (n_x, n_y) X , Y = create_placeholders ( n_x , n_y ) ## Step-2: Initialize parameters parameters = initialize_parameters () ## Step-3: Forward propagation ## Build the forward propagation the tf graph Z3 = forward_proagation ( X , parameters ) ## Step-4: Cost function ## Add cost function to tf graph cost = compute_cost ( Z3 , Y ) ## Step-5: Backward propagation ## Define the tf optimizer. Use `AdamOptimizer` optimizer = tf . train . AdamOptimizer ( lr ) . minimize ( cost ) ## Step-6: Initialize all variables init = tf . global_variables_initializer () ## Step-7: Start the session to compute the tf graph with tf . Session () as sess : ## Step-7.1: Run the initializer `init` sess . run ( init ) ## Step-7.2: Do the training loop for epoch in range ( num_epchs ): epoch_cost = 0.0 ## Define the cost for each epoch num_batches = m // bs seed += 1 minibatches = random_mini_batches ( X_train , Y_train , bs , seed ) for ( Xb , Yb ) in minibatches : _ , minibatch_cost = sess . run ([ optimizer , cost ], feed_dict = { X : Xb , Y : Yb }) epoch_cost += minibatch_cost epoch_cost /= num_batches ## Step-8: Save the trained model parameters parameters = sess . run ( parameters ) print ( \"parameters have been trained\" ) ## Step-9: How to calculate the correct predictions & accuracy correct_preds = tf . equal ( tf . argmax ( Z3 ), tf . argmax ( Y )) accuracy = tf . reduce_mean ( tf . cast ( correct_preds , \"float\" )) ## Step-10: Calculate the train & test accuracies accuracy_train = accuracy . eval ({ X : X_train , Y : Y_train }) accuracy_test = accuracy . eval ({ X : X_test , Y : Y_test }) return parameters","title":"Tensorflow Tutorial"},{"location":"blogs/deep_learning/blog_tf_v1/#tensorflow-tutorial","text":"In this session you will learn to do the following in TensorFlow v1.0 Initialize Variables Start your own session Train Algorithms Implement a Neural Network","title":"Tensorflow Tutorial"},{"location":"blogs/deep_learning/blog_tf_v1/#exploring-the-tensorflow-library","text":"","title":"Exploring the Tensorflow Library"},{"location":"blogs/deep_learning/blog_tf_v1/#example-1-general-overview","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 import tensorflow as tf y_hat = tf . constant ( 36 , name = \"y_hat\" ) ## Defins a \"y_hat\" constant. Sets its value to 36 y = tf . constant ( 39 , name = \"y\" ) ## Defins a \"y\" constant. Sets its value to 39 loss = tf . Variable (( y - y_hat ) ** 2 , name = \"loss\" ) init = tf . global_variables_initializer () ## Used to initialize the variables with the ## respective values when \"sess.run(init)\" is called with tf . Session () as sess : ## Creates a session to execute our program sess . run ( init ) ## initializes the global variables sess . run ( loss ) ## executes the program stored in \"loss\" variable print ( loss ) ## prints the value stored in \"loss\" variable Writing and running programs in Tensorflow has the following steps: Create tensors (variables) that are not yet evaluated/executed. Write operations between those tensors. Initialize the tensors. Create a Session . Run the session . This will run the operations written in step-2. So, when we created a variable for loss , we simply defined the loss as a function of other quantities but did not evaluate its value. To evaluate it, we had to run tf.global_variables_initializer() to intialize the values and then inside sess.run(init) we calculated the updated value and prited it in the last line above.","title":"Example-1: General Overview"},{"location":"blogs/deep_learning/blog_tf_v1/#example-2-tfsession","text":"Now, let's take a look at 1 2 3 4 a = tf . constant ( 2 ) b = tf . constant ( 10 ) c = tf . multiply ( a , b ) print ( c ) 1 Tensor(\"Mul:0\", shape=(), dtype=int32) As expected we will not see 20 . We got a tensor saying that the result of the tensor does not have the shape attribute and is of the type int32 . All we did was to put in the computation graph ; but we haven't run this computation yet! In order to actually multiply the two numbers we have to create a sessiona nd run it. 1 2 sess = tf . Session () print ( sess . run ( c )) 1 20 Awesome!! . To summarize, remember the following: Initialize your variables. Create a session. Run the operations inside the session.","title":"Example-2: tf.Session()"},{"location":"blogs/deep_learning/blog_tf_v1/#example-3-tfplaceholder","text":"Next, we will see how to use a placeholder. A placeholder is an object whose value we can specify ONLY later. To specify values for a placeholder, we can pass in values by using a \"feed dictionary\" ( feed_dict variable). 1 2 3 4 5 6 7 8 9 ## Below we create a placeholder for x. ## This allows us to pass in a number later when we run the SESSION sess = tf . Session () x = tf . placeholder ( tf . int64 , name = \"x\" ) ## the placeholder variable print ( sess . run ( 2 * x , feed_dict = { x : 9 })) sess . close () 1 18","title":"Example-3: tf.placeholder()"},{"location":"blogs/deep_learning/blog_tf_v1/#using-one-hot-encodings","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def one_hot_matrix ( labels , num_classes ): \"\"\" Creates a matrix where the i-th row corresponds to the ith class number. j-th column corresponds to the j-th example. So, if the label for j-th example is i; then only the ith value is 1 in j-th column Args: labels: the labels for each example num_classes: the number of classes in this task Returns: a one-hot matrix \"\"\" ## create a tf.constant & name it \"num_classes\" num_classes = tf . constant ( num_classes , name = \"num_classes\" ) ## Use tf.one_hot (be careful with \"axis\") one_hot_matrix = tf . one_hot ( indices = labels , depth = num_classes , axis = 0 ) ## Create a session sess = tf . Session () ## Execute the one_hot_matrix graph inside the session one_hot = sess . run ( one_hot_matrix ) ## Close the session sess . close () ## return the one_hot matrix return one_hot 1 2 3 4 5 6 import numpy as np labels = np . array ([ 1 , 2 , 0 , 1 , 2 , 2 , 3 ]) num_classes = 4 one_hot = one_hot_matrix ( labels , num_classes ) print ( one_hot ) 1 2 3 4 [[0,0,1,0,0,0,0], [1,0,0,1,0,0,0], [0,1,0,0,1,1,0], [0,0,0,0,0,0,1]]","title":"Using one-hot encodings:"},{"location":"blogs/deep_learning/blog_tf_v1/#initialize-with-zeros-ones","text":"We will use tf.ones() and tf.zeros() to initialize a tensor of shape shape , where all elements are either zeros or ones 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def ones ( shape , dtype = tf . int64 ): \"\"\"Creates a tensor of ones with shape=shape Args: shape: the shape of the resulting tensor dtype: the datatype of every element in the resulting tensor Returns: A tensor where all elements are 1 \"\"\" ## Create ones tensor using `tf.ones()` ones = tf . ones ( shape , dtype = dtype ) ## Create a session sess = tf . Session () ## Execute the op in the session to calculate its value ones = sess . run ( ones ) ## Close the session sess . close () ## Return the ones tensor return ones 1 2 ones_tensor = ones ([ 2 , 3 ]) print ( ones_tensor ) 1 2 [[1,1,1], [1,1,1]]","title":"Initialize with zeros &amp; ones"},{"location":"blogs/deep_learning/blog_tf_v1/#building-a-neural-network","text":"","title":"Building a Neural Network"},{"location":"blogs/deep_learning/blog_tf_v1/#building-the-model","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 from tf_utils import load_dataset , random_mini_batches , convert_to_one_hot , predict from tensorflow.python.framework import ops def model ( X_train , Y_train , X_test , Y_test , lr = 1e-3 , num_epochs = 1500 , bs = 32 , verbose = True ): \"\"\" Implements a 3-layer Tensorflow Neural Network: [Linear]->[Relu]->[Linear]->[Relu]->[Linear]-[Softmax] Args: X_train: the train dataset inputs Y_train: the train dataset labels X_test: the test dataset inputs Y_test: the test dataset labels lr: the learnign rate num_epochs: number of epochs bs: batch-size verbose: True if you want to print the process else False Returns: the trained model parameters. \"\"\" ops . reset_default_graph () ## to be able to rerun the model, w/o overwriting the tf.variables tf . set_random_seed ( 217 ) ## to keep consistent results seed = 3 ## to keep consistent results ( n_x , m ) = X_train . shape ## n_x = input size; m = number of training examples n_y = Y_train . shape [ 0 ] ## n_y = output size costs = [] ## to keep track of the costs ## Step-1: Create placeholders of shape = (n_x, n_y) X , Y = create_placeholders ( n_x , n_y ) ## Step-2: Initialize parameters parameters = initialize_parameters () ## Step-3: Forward propagation ## Build the forward propagation the tf graph Z3 = forward_proagation ( X , parameters ) ## Step-4: Cost function ## Add cost function to tf graph cost = compute_cost ( Z3 , Y ) ## Step-5: Backward propagation ## Define the tf optimizer. Use `AdamOptimizer` optimizer = tf . train . AdamOptimizer ( lr ) . minimize ( cost ) ## Step-6: Initialize all variables init = tf . global_variables_initializer () ## Step-7: Start the session to compute the tf graph with tf . Session () as sess : ## Step-7.1: Run the initializer `init` sess . run ( init ) ## Step-7.2: Do the training loop for epoch in range ( num_epchs ): epoch_cost = 0.0 ## Define the cost for each epoch num_batches = m // bs seed += 1 minibatches = random_mini_batches ( X_train , Y_train , bs , seed ) for ( Xb , Yb ) in minibatches : _ , minibatch_cost = sess . run ([ optimizer , cost ], feed_dict = { X : Xb , Y : Yb }) epoch_cost += minibatch_cost epoch_cost /= num_batches ## Step-8: Save the trained model parameters parameters = sess . run ( parameters ) print ( \"parameters have been trained\" ) ## Step-9: How to calculate the correct predictions & accuracy correct_preds = tf . equal ( tf . argmax ( Z3 ), tf . argmax ( Y )) accuracy = tf . reduce_mean ( tf . cast ( correct_preds , \"float\" )) ## Step-10: Calculate the train & test accuracies accuracy_train = accuracy . eval ({ X : X_train , Y : Y_train }) accuracy_test = accuracy . eval ({ X : X_test , Y : Y_test }) return parameters","title":"Building the model"},{"location":"blogs/physics/blog_01282021/","text":"Electromagnetic Spectrum, properties of material medium & its effects. Author: Vinay Kumar (@imflash217) | Date: 28/January/2021 Electromagnetic Spectrum Electromagnetic Spectrum The different parts of the electromagnetic spectrum have very different effects upon interaction with matter. Starting with low frequency radio waves , the human body is quite transparent ( you can listen to your portable radio inside your home since the waves pass freely through the walls of your house and even through the person beside you! ) As you move upward through microwaves and infrared to visible light , you absorb more and more strongly. In the lower ultraviolet range, all the UV from the sun is absorbed in a thin outer layer of your skin. As you move further up into the x-ray region of the spectrum, you become transparent again, because most of the mechanisms for absorption are gone. You then absorb only a small fraction of the radiation, but that absorption involves the more violent ionization events . Each portion of the electromagnetic spectrum has quantum energies appropriate for the excitation of certain types of physical processes. The energy levels for all physical processes at the atomic and molecular levels are quantized, and if there are no available quantized energy levels with spacings which match the quantum energy of the incident radiation, then the material will be transparent to that radiation , and it will pass through. If electromagnetic energy is absorbed, but cannot eject electrons from the atoms of the material, then it is classified as non-ionizing radiation, and will typically just heat the material. Microwaves Microwaves The quantum energy of microwave photons is in the range 0.00001 to 0.001 eV which is in the range of energies separating the quantum states of molecular rotation and torsion . The interaction of microwaves with matter other than metallic conductors ** will be to rotate molecules and produce heat as result of that molecular motion. Conductors will strongly absorb microwaves and any lower frequencies because they will cause electric currents which will heat the material. Most matter, including the human body, is largely transparent to microwaves. High intensity microwaves, as in a microwave oven where they pass back and forth through the food millions of times, will heat the material by producing molecular rotations and torsions. Since the quantum energies are a million times lower than those of x-rays, they cannot produce ionization and the characteristic types of radiation damage associated with ionizing radiation. Infrared Infrared The quantum energy of infrared photons is in the range 0.001 to 1.7 eV which is in the range of energies separating the quantum states of molecular vibrations. Infrared is absorbed more strongly than microwaves, but less strongly than visible light. The result of infrared absorption is heating of the tissue since it increases molecular vibrational activity. Infrared radiation does penetrate the skin further than visible light and can thus be used for photographic imaging of subcutaneous blood vessels. Visible Light Visible Light The primary mechanism for the absorption of visible light photons is the elevation of electrons to higher energy levels. There are many available states, so visible light is absorbed strongly. With a strong light source, red light can be transmitted through the hand or a fold of skin, showing that the red end of the spectrum is not absorbed as strongly as the violet end. While exposure to visible light causes heating, it does not cause ionization with its risks. You may be heated by the sun through a car windshield, but you will not be sunburned - that is an effect of the higher frequency uv part of sunlight which is blocked by the glass of the windshield. Ultraviolet Ultraviolet The near ultraviolet is absorbed very strongly in the surface layer of the skin by electron transitions . As you go to higher energies, the ionization energies for many molecules are reached and the more dangerous photoionization processes take place. Sunburn is primarily an effect of uv, and ionization produces the risk of skin cancer . The ozone layer in the upper atmosphere is important for human health because it absorbs most of the harmful ultraviolet radiation from the sun before it reaches the surface. The higher frequencies in the ultraviolet are ionizing radiation and can produce harmful physiological effects ranging from sunburn to skin cancer . Health concerns for UV exposure are mostly for the range 290-330 nm in wavelength, the range called UVB . According to Scotto, et al , the most effective biological wavelength for producing skin burns is 297 nm . Their research indicates that the biological effects increase logarithmically within the UVB range, with 330 nm being only 0.1% as effective as 297 nm for biological effects. So it is clearly important to control exposure to UVB. X-ray X-men First Header Second Header Since the quantum energies of x-ray photons are much too high to be absorbed in electron transitions between states for most atoms, they can interact with an electron only by knocking it completely out of the atom. That is, all x-rays are classified as ionizing radiation . This can occur by giving all of the energy to an electron ( photoionization ) or by giving part of the energy to the electron and the remainder to a lower energy photon ( Compton Scattering ). At sufficiently high energies, the x-ray photon can create an electron positron pair. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 28/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References: http://hyperphysics.phy-astr.gsu.edu/hbase/mod3.html \u21a9 http://hyperphysics.phy-astr.gsu.edu/hbase/mod2.html \u21a9 https://physics.stackexchange.com/questions/300551/how-can-wifi-penetrate-through-walls-when-visible-light-cant \u21a9 https://physics.stackexchange.com/questions/1836/why-is-air-invisible \u21a9 https://physics.stackexchange.com/questions/7437/why-is-glass-transparent \u21a9","title":"Electromagnetic Spectrum, properties of material medium & its effects"},{"location":"blogs/physics/blog_01282021/#electromagnetic-spectrum-properties-of-material-medium-its-effects","text":"Author: Vinay Kumar (@imflash217) | Date: 28/January/2021","title":"Electromagnetic Spectrum, properties of material medium &amp; its effects."},{"location":"blogs/physics/blog_01282021/#electromagnetic-spectrum","text":"Electromagnetic Spectrum The different parts of the electromagnetic spectrum have very different effects upon interaction with matter. Starting with low frequency radio waves , the human body is quite transparent ( you can listen to your portable radio inside your home since the waves pass freely through the walls of your house and even through the person beside you! ) As you move upward through microwaves and infrared to visible light , you absorb more and more strongly. In the lower ultraviolet range, all the UV from the sun is absorbed in a thin outer layer of your skin. As you move further up into the x-ray region of the spectrum, you become transparent again, because most of the mechanisms for absorption are gone. You then absorb only a small fraction of the radiation, but that absorption involves the more violent ionization events . Each portion of the electromagnetic spectrum has quantum energies appropriate for the excitation of certain types of physical processes. The energy levels for all physical processes at the atomic and molecular levels are quantized, and if there are no available quantized energy levels with spacings which match the quantum energy of the incident radiation, then the material will be transparent to that radiation , and it will pass through. If electromagnetic energy is absorbed, but cannot eject electrons from the atoms of the material, then it is classified as non-ionizing radiation, and will typically just heat the material.","title":"Electromagnetic Spectrum"},{"location":"blogs/physics/blog_01282021/#microwaves","text":"Microwaves The quantum energy of microwave photons is in the range 0.00001 to 0.001 eV which is in the range of energies separating the quantum states of molecular rotation and torsion . The interaction of microwaves with matter other than metallic conductors ** will be to rotate molecules and produce heat as result of that molecular motion. Conductors will strongly absorb microwaves and any lower frequencies because they will cause electric currents which will heat the material. Most matter, including the human body, is largely transparent to microwaves. High intensity microwaves, as in a microwave oven where they pass back and forth through the food millions of times, will heat the material by producing molecular rotations and torsions. Since the quantum energies are a million times lower than those of x-rays, they cannot produce ionization and the characteristic types of radiation damage associated with ionizing radiation.","title":"Microwaves"},{"location":"blogs/physics/blog_01282021/#infrared","text":"Infrared The quantum energy of infrared photons is in the range 0.001 to 1.7 eV which is in the range of energies separating the quantum states of molecular vibrations. Infrared is absorbed more strongly than microwaves, but less strongly than visible light. The result of infrared absorption is heating of the tissue since it increases molecular vibrational activity. Infrared radiation does penetrate the skin further than visible light and can thus be used for photographic imaging of subcutaneous blood vessels.","title":"Infrared"},{"location":"blogs/physics/blog_01282021/#visible-light","text":"Visible Light The primary mechanism for the absorption of visible light photons is the elevation of electrons to higher energy levels. There are many available states, so visible light is absorbed strongly. With a strong light source, red light can be transmitted through the hand or a fold of skin, showing that the red end of the spectrum is not absorbed as strongly as the violet end. While exposure to visible light causes heating, it does not cause ionization with its risks. You may be heated by the sun through a car windshield, but you will not be sunburned - that is an effect of the higher frequency uv part of sunlight which is blocked by the glass of the windshield.","title":"Visible Light"},{"location":"blogs/physics/blog_01282021/#ultraviolet","text":"Ultraviolet The near ultraviolet is absorbed very strongly in the surface layer of the skin by electron transitions . As you go to higher energies, the ionization energies for many molecules are reached and the more dangerous photoionization processes take place. Sunburn is primarily an effect of uv, and ionization produces the risk of skin cancer . The ozone layer in the upper atmosphere is important for human health because it absorbs most of the harmful ultraviolet radiation from the sun before it reaches the surface. The higher frequencies in the ultraviolet are ionizing radiation and can produce harmful physiological effects ranging from sunburn to skin cancer . Health concerns for UV exposure are mostly for the range 290-330 nm in wavelength, the range called UVB . According to Scotto, et al , the most effective biological wavelength for producing skin burns is 297 nm . Their research indicates that the biological effects increase logarithmically within the UVB range, with 330 nm being only 0.1% as effective as 297 nm for biological effects. So it is clearly important to control exposure to UVB.","title":"Ultraviolet"},{"location":"blogs/physics/blog_01282021/#x-ray","text":"X-men First Header Second Header Since the quantum energies of x-ray photons are much too high to be absorbed in electron transitions between states for most atoms, they can interact with an electron only by knocking it completely out of the atom. That is, all x-rays are classified as ionizing radiation . This can occur by giving all of the energy to an electron ( photoionization ) or by giving part of the energy to the electron and the remainder to a lower energy photon ( Compton Scattering ). At sufficiently high energies, the x-ray photon can create an electron positron pair. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 28/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"X-ray"},{"location":"blogs/physics/blog_01282021/#references","text":"http://hyperphysics.phy-astr.gsu.edu/hbase/mod3.html \u21a9 http://hyperphysics.phy-astr.gsu.edu/hbase/mod2.html \u21a9 https://physics.stackexchange.com/questions/300551/how-can-wifi-penetrate-through-walls-when-visible-light-cant \u21a9 https://physics.stackexchange.com/questions/1836/why-is-air-invisible \u21a9 https://physics.stackexchange.com/questions/7437/why-is-glass-transparent \u21a9","title":"References:"},{"location":"gists/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"gists/python_snippets/","text":"Python Snippets 1: MappingProxyType Immutable Mappings The mapping types provided by the standard library are all mutable; but you may need to gurantee that a user cannot change a mapping by mistake. Since Python 3.3 the types module provides a wrapper class MappingProxyType which, given a mapping returns a mappingproxy instance that is read-only but a dynamic-view of the original mapping. This means that the original mapping can be seen through mappingproxy but changes cannot be made through it. 1 2 3 4 5 6 7 8 9 10 11 12 13 from types import MappingProxyType d = { 1 : \"A\" } d_proxy = MappingProxyType ( d ) ## creating a proxy for the original dict d ## d_proxy = {1:\"A\"} print ( d_proxy [ 1 ]) ## \"A\" d_proxy [ 2 ] = \"X\" ## TypeERROR. mappingproxy does not support item assignment d [ 2 ] = \"B\" ## OKAY. The original dictionary is still mutable print ( d_proxy ) ## The proxy has a dynamic view of the original dict. ## So, it refelects the change ## {1:\"A\", 2:\"B\"} 2: Set operators Set Operators 1 2 3 4 5 6 7 8 9 10 11 **operator: method: desciption:** `s.isdisjoint(z)` `s` and `z` are disjoint (i.e. have no elements in common) `e in s` `s.__contains__(e)` element `e` is a subset of `s` set `s <= z` `s.__le__(z)` `s` is a **subset** of `z` set `s.issubset(it)` `s` is a **subset** of the set built from the iterable `it` `s < z` `s.__lt__(z)` `s` is a **PROPER-subset** of `z` set `s >= z` `s.__ge__(z)` `s` is a **superset** of `z` set `s.issuperset(it)` `s` is a **superset** of the set built from iterable `it` `s > z` `s.__gt__(z)` `s` is a **PROPER-superset** of the set `z` 3: set v/s frozenset Set v/s Frozenset 1 2 3 4 5 6 7 8 9 **operator: set: frozenset: description:** `s.add(e)` \u2705 Add element `e` to set `s` `s.clear()` \u2705 Remove all elements from set `s` `s.copy()` \u2705 \u2705 Shallow copy of set/frozenset `s` `s.discard(e)` \u2705 Remove element `e` from set `s` IF it is present `s.__iter__()` \u2705 \u2705 Get iterator over set/frozenset `s` `s.__len__()` \u2705 \u2705 `len(s)` `s.pop()` \u2705 Remove and return an element from `s` ; raising `keyError` if `s` is empty `s.remove(e)` \u2705 Remive element `e` from set `s` ; raise `KeyError` if `e not in s`","title":"Python_Snippets"},{"location":"gists/python_snippets/#python-snippets","text":"","title":"Python Snippets"},{"location":"gists/python_snippets/#1-mappingproxytype","text":"Immutable Mappings The mapping types provided by the standard library are all mutable; but you may need to gurantee that a user cannot change a mapping by mistake. Since Python 3.3 the types module provides a wrapper class MappingProxyType which, given a mapping returns a mappingproxy instance that is read-only but a dynamic-view of the original mapping. This means that the original mapping can be seen through mappingproxy but changes cannot be made through it. 1 2 3 4 5 6 7 8 9 10 11 12 13 from types import MappingProxyType d = { 1 : \"A\" } d_proxy = MappingProxyType ( d ) ## creating a proxy for the original dict d ## d_proxy = {1:\"A\"} print ( d_proxy [ 1 ]) ## \"A\" d_proxy [ 2 ] = \"X\" ## TypeERROR. mappingproxy does not support item assignment d [ 2 ] = \"B\" ## OKAY. The original dictionary is still mutable print ( d_proxy ) ## The proxy has a dynamic view of the original dict. ## So, it refelects the change ## {1:\"A\", 2:\"B\"}","title":"1: MappingProxyType"},{"location":"gists/python_snippets/#2-set-operators","text":"Set Operators 1 2 3 4 5 6 7 8 9 10 11 **operator: method: desciption:** `s.isdisjoint(z)` `s` and `z` are disjoint (i.e. have no elements in common) `e in s` `s.__contains__(e)` element `e` is a subset of `s` set `s <= z` `s.__le__(z)` `s` is a **subset** of `z` set `s.issubset(it)` `s` is a **subset** of the set built from the iterable `it` `s < z` `s.__lt__(z)` `s` is a **PROPER-subset** of `z` set `s >= z` `s.__ge__(z)` `s` is a **superset** of `z` set `s.issuperset(it)` `s` is a **superset** of the set built from iterable `it` `s > z` `s.__gt__(z)` `s` is a **PROPER-superset** of the set `z`","title":"2: Set operators"},{"location":"gists/python_snippets/#3-set-vs-frozenset","text":"Set v/s Frozenset 1 2 3 4 5 6 7 8 9 **operator: set: frozenset: description:** `s.add(e)` \u2705 Add element `e` to set `s` `s.clear()` \u2705 Remove all elements from set `s` `s.copy()` \u2705 \u2705 Shallow copy of set/frozenset `s` `s.discard(e)` \u2705 Remove element `e` from set `s` IF it is present `s.__iter__()` \u2705 \u2705 Get iterator over set/frozenset `s` `s.__len__()` \u2705 \u2705 `len(s)` `s.pop()` \u2705 Remove and return an element from `s` ; raising `keyError` if `s` is empty `s.remove(e)` \u2705 Remive element `e` from set `s` ; raise `KeyError` if `e not in s`","title":"3: set v/s frozenset"},{"location":"gists/lightning/api/configure_optimizers/","text":"pl.LightningModule.configure_optimizers() Code Snippets 1 2 3 4 5 6 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-44 ## ## ! pl.LightningModule.configure_optimizers() ## Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"configure_optimizers()"},{"location":"gists/lightning/api/configure_optimizers/#pllightningmoduleconfigure_optimizers","text":"","title":"pl.LightningModule.configure_optimizers()"},{"location":"gists/lightning/api/configure_optimizers/#code-snippets","text":"1 2 3 4 5 6 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-44 ## ## ! pl.LightningModule.configure_optimizers() ## Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/configure_optimizers/#references","text":"","title":"References"},{"location":"gists/lightning/api/forward/","text":"pl.LightningModule.forward() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-46 ## ## ! pl.LightningModule.forward(*args, **kwargs) ## \"\"\" Same as 'torch.nn.Module.forward()' However in Lightning; we want it to define the operations we want to use it during prediction. \"\"\" ################################################################################################### ################################################################################################### # example: if we were using this model as a feature extractor. import torch import pytorch_lightning as pl class FlashModel ( pl . LightningModule ): def forward ( self , x ): feature_maps = self . convnet ( x ) return feature_maps def training_step ( self , batch , batch_idx ): x , y = batch feature_maps = self ( x ) ## ! <-- calls forward() method logits = self . classifier ( feature_maps ) ## TODO: DO something ... return loss ###################### # splitting it this way allows the model to be used as a feature extractor model = FlashModel () inputs = server . get_request () results = model ( inputs ) server . write_results ( results ) ######################################################################################## ######################################################################################## # Using vanilla \"torch.nn.Module\" only. # ! So use \"pl.LightningModule.forward()\" instead of \"torch.nn.Module.forward()\" class Model ( torch . nn . Module ): def forward ( self , batch ): x , y = batch feature_maps = self . convnet ( x ) logits = self . classifier ( feature_maps ) return logits ######################################################################################## ######################################################################################## Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"forward()"},{"location":"gists/lightning/api/forward/#pllightningmoduleforward","text":"","title":"pl.LightningModule.forward()"},{"location":"gists/lightning/api/forward/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-46 ## ## ! pl.LightningModule.forward(*args, **kwargs) ## \"\"\" Same as 'torch.nn.Module.forward()' However in Lightning; we want it to define the operations we want to use it during prediction. \"\"\" ################################################################################################### ################################################################################################### # example: if we were using this model as a feature extractor. import torch import pytorch_lightning as pl class FlashModel ( pl . LightningModule ): def forward ( self , x ): feature_maps = self . convnet ( x ) return feature_maps def training_step ( self , batch , batch_idx ): x , y = batch feature_maps = self ( x ) ## ! <-- calls forward() method logits = self . classifier ( feature_maps ) ## TODO: DO something ... return loss ###################### # splitting it this way allows the model to be used as a feature extractor model = FlashModel () inputs = server . get_request () results = model ( inputs ) server . write_results ( results ) ######################################################################################## ######################################################################################## # Using vanilla \"torch.nn.Module\" only. # ! So use \"pl.LightningModule.forward()\" instead of \"torch.nn.Module.forward()\" class Model ( torch . nn . Module ): def forward ( self , batch ): x , y = batch feature_maps = self . convnet ( x ) logits = self . classifier ( feature_maps ) return logits ######################################################################################## ######################################################################################## Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/forward/#references","text":"","title":"References"},{"location":"gists/lightning/api/freeze/","text":"pl.LightningModule.freeze() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.freeze() ## \"\"\" Freezes all parameters for inference. Return: None \"\"\" ################################################################################################### from lightning.api.forward import FlashModel import pytorch_lightning as pl model = FlashModel () model . freeze () ## ! <<- this freezes all model parameters. ################################################################################################### Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"freeze()"},{"location":"gists/lightning/api/freeze/#pllightningmodulefreeze","text":"","title":"pl.LightningModule.freeze()"},{"location":"gists/lightning/api/freeze/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.freeze() ## \"\"\" Freezes all parameters for inference. Return: None \"\"\" ################################################################################################### from lightning.api.forward import FlashModel import pytorch_lightning as pl model = FlashModel () model . freeze () ## ! <<- this freezes all model parameters. ################################################################################################### Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/freeze/#references","text":"","title":"References"},{"location":"gists/lightning/api/log/","text":"pl.LightningModule.log() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.log() ## \"\"\"Log a (key, value) Args: name ([type]): [description] value ([type]): [description] prog_bar ([type]): [description] logger ([type]): [description] on_step ([type]): [description] on_epoch ([type]): [description] reduce_fx ([type]): [description] tbptt_reduce_fx ([type]): [description] tbptt_pad_token ([type]): [description] enable_graph ([type]): [description] sync_dist ([type]): [description] sync_dist_op ([type]): [description] sync_dist_group ([type]): [description] \"\"\" Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"log()"},{"location":"gists/lightning/api/log/#pllightningmodulelog","text":"","title":"pl.LightningModule.log()"},{"location":"gists/lightning/api/log/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.log() ## \"\"\"Log a (key, value) Args: name ([type]): [description] value ([type]): [description] prog_bar ([type]): [description] logger ([type]): [description] on_step ([type]): [description] on_epoch ([type]): [description] reduce_fx ([type]): [description] tbptt_reduce_fx ([type]): [description] tbptt_pad_token ([type]): [description] enable_graph ([type]): [description] sync_dist ([type]): [description] sync_dist_op ([type]): [description] sync_dist_group ([type]): [description] \"\"\" Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/log/#references","text":"","title":"References"},{"location":"gists/lightning/api/test_step/","text":"pl.LightningModule.test_step() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-50 ## ## ! pl.LightningModule.test_step() ## \"\"\" Operates on a single batch of data from the test set. In this step you would normally generate examples or calculate anything of interest such as accuracy. \"\"\" import torch import torchvision import pytorch_lightning as pl # The pseudocode for these calls test_outs = [] for test_batch in test_data : out = test_step ( test_batch ) test_outs . append ( out ) test_epoch_end ( test_outs ) ## if we have one test dataloader def test_step ( self , batch , batch_idx ): pass # if we have multiple test dataloaders def test_step ( self , batch , batch_idx , dataloader_idx ): pass ################################################################################ # Examples: case-1 [a single test dataset] def test_set ( self , batch , batch_idx ): x , y = batch # implement your own out = self ( x ) loss = self . loss ( out , y ) #log 6 example images or generated text or whatever sample_images = x [: 6 ] grid = torchvision . utils . make_grid ( sample_images ) self . logger . experiment . add_image ( \"example_images\" , grid , 0 ) # calculate accuracy labels_hat = torch . argmax ( out , dim = 1 ) test_acc = torch . sum ( y == labels_hat ) . item () / ( len ( y ) * 1.0 ) # log the outputs self . log_dict ({ \"test_loss\" : loss , \"test_acc\" : test_acc }) ################################################################################ # If we pass in multiple test datasets def test_set ( self , batch , batch_idx , dataloader_idx ): \"\"\" dataloader_idx ->> tells which dataset to use during test iterations \"\"\" # TODO: do whatever you want # TODO: ... pass ################################################################################ # NOTE: If you don't need to validate then you don't need to implement this method. # NOTE: When the test_step() is called; the model has been put in EVAL mode and all gradients have been disbaled. # At the end of the test epoch, the model goes back to the training mode and the gradients are enabled. ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"test_step()"},{"location":"gists/lightning/api/test_step/#pllightningmoduletest_step","text":"","title":"pl.LightningModule.test_step()"},{"location":"gists/lightning/api/test_step/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-50 ## ## ! pl.LightningModule.test_step() ## \"\"\" Operates on a single batch of data from the test set. In this step you would normally generate examples or calculate anything of interest such as accuracy. \"\"\" import torch import torchvision import pytorch_lightning as pl # The pseudocode for these calls test_outs = [] for test_batch in test_data : out = test_step ( test_batch ) test_outs . append ( out ) test_epoch_end ( test_outs ) ## if we have one test dataloader def test_step ( self , batch , batch_idx ): pass # if we have multiple test dataloaders def test_step ( self , batch , batch_idx , dataloader_idx ): pass ################################################################################ # Examples: case-1 [a single test dataset] def test_set ( self , batch , batch_idx ): x , y = batch # implement your own out = self ( x ) loss = self . loss ( out , y ) #log 6 example images or generated text or whatever sample_images = x [: 6 ] grid = torchvision . utils . make_grid ( sample_images ) self . logger . experiment . add_image ( \"example_images\" , grid , 0 ) # calculate accuracy labels_hat = torch . argmax ( out , dim = 1 ) test_acc = torch . sum ( y == labels_hat ) . item () / ( len ( y ) * 1.0 ) # log the outputs self . log_dict ({ \"test_loss\" : loss , \"test_acc\" : test_acc }) ################################################################################ # If we pass in multiple test datasets def test_set ( self , batch , batch_idx , dataloader_idx ): \"\"\" dataloader_idx ->> tells which dataset to use during test iterations \"\"\" # TODO: do whatever you want # TODO: ... pass ################################################################################ # NOTE: If you don't need to validate then you don't need to implement this method. # NOTE: When the test_step() is called; the model has been put in EVAL mode and all gradients have been disbaled. # At the end of the test epoch, the model goes back to the training mode and the gradients are enabled. ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/test_step/#references","text":"","title":"References"},{"location":"gists/lightning/api/training_step/","text":"pl.LightningModule.training_step() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-55 ## ## ! pl.LightningModule.training_step() ## \"\"\" Here we compute and return the training loss and some additional metrics. In this step you would normally do the forward pass and compute the loss for the batch. We can also do fancier things like multiple forward passes or something model specific. Parameters: batch (Tensor | (Tensor,...) | [Tensor, ...]) ->> The output of the dataloader batch_idx (int) ->> integer displaying the index of this batch optimizer_idx (int) ->> when using multiple optimizers this argument will also be present hiddens (Tensor) ->> Passed if `truncated_bptt_steps > 0` Returns: Any of Tensor (or) ->> The loss tensor dict (or) ->> A dictionary. Can include any keys but MUST include the key \"loss\" None ->> Training will skip to the next batch \"\"\" ## NOTE: The loss value shown in the progress bar is SMOOTHED (i.e. averaged) over its previous values. ## NOTE: So, it differs from the actual lossreturned in training/validation step import torch import pytorch_lightning as pl ################################################################################ class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx ): x , y , z = batch out = self . encoder ( x ) loss = self . loss ( out , x ) return loss ################################################################################ ## ! If we are using MULTIPLE OPTIMIZERS class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx , optimizer_idx ): if optimizer_idx == 0 : ## TODO: do training with encoder pass elif optimizer_idx == 1 : # TODO: DO training with decoder pass ################################################################################ ## ! Truncated BPTT class FlashModel ( pl . LightningModule ): def __init__ ( self , lstm ): super () . __init__ () self . lstm = lstm def training_step ( self , batch , batch_idx , hiddens ): # ! 'hiddens' are the hidden states from the previous truncated backprop step # ... out , hiddens = self . lstm ( data , hiddens ) loss = self . loss ( out , data ) # ... return { \"loss\" : loss , \"hiddens\" : hiddens } ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"training_step()"},{"location":"gists/lightning/api/training_step/#pllightningmoduletraining_step","text":"","title":"pl.LightningModule.training_step()"},{"location":"gists/lightning/api/training_step/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-55 ## ## ! pl.LightningModule.training_step() ## \"\"\" Here we compute and return the training loss and some additional metrics. In this step you would normally do the forward pass and compute the loss for the batch. We can also do fancier things like multiple forward passes or something model specific. Parameters: batch (Tensor | (Tensor,...) | [Tensor, ...]) ->> The output of the dataloader batch_idx (int) ->> integer displaying the index of this batch optimizer_idx (int) ->> when using multiple optimizers this argument will also be present hiddens (Tensor) ->> Passed if `truncated_bptt_steps > 0` Returns: Any of Tensor (or) ->> The loss tensor dict (or) ->> A dictionary. Can include any keys but MUST include the key \"loss\" None ->> Training will skip to the next batch \"\"\" ## NOTE: The loss value shown in the progress bar is SMOOTHED (i.e. averaged) over its previous values. ## NOTE: So, it differs from the actual lossreturned in training/validation step import torch import pytorch_lightning as pl ################################################################################ class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx ): x , y , z = batch out = self . encoder ( x ) loss = self . loss ( out , x ) return loss ################################################################################ ## ! If we are using MULTIPLE OPTIMIZERS class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx , optimizer_idx ): if optimizer_idx == 0 : ## TODO: do training with encoder pass elif optimizer_idx == 1 : # TODO: DO training with decoder pass ################################################################################ ## ! Truncated BPTT class FlashModel ( pl . LightningModule ): def __init__ ( self , lstm ): super () . __init__ () self . lstm = lstm def training_step ( self , batch , batch_idx , hiddens ): # ! 'hiddens' are the hidden states from the previous truncated backprop step # ... out , hiddens = self . lstm ( data , hiddens ) loss = self . loss ( out , data ) # ... return { \"loss\" : loss , \"hiddens\" : hiddens } ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/training_step/#references","text":"","title":"References"},{"location":"hobbies/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"notes/about/","text":"Notes .video-wrapper { position: relative; display: block; height: 0; padding: 0; overflow: hidden; padding-bottom: 56.25%; } .video-wrapper > iframe { position: absolute; top: 0; bottom: 0; left: 0; width: 100%; height: 100%; border: 0; } Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Pied Piper Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Submit C 1 2 3 4 5 6 #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ 1 2 3 4 5 6 #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Welcome to MkDocs For full documentation visit mkdocs.org . Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C . 1 2 nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout 1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Deployment 1 git add . && git commit -m \"update\" && git push -u origin main && mkdocs gh-deploy --force Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod \u21a9","title":"About"},{"location":"notes/about/#notes","text":".video-wrapper { position: relative; display: block; height: 0; padding: 0; overflow: hidden; padding-bottom: 56.25%; } .video-wrapper > iframe { position: absolute; top: 0; bottom: 0; left: 0; width: 100%; height: 100%; border: 0; } Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Pied Piper Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Submit C 1 2 3 4 5 6 #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ 1 2 3 4 5 6 #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Notes"},{"location":"notes/about/#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org . Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C . 1 2 nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Welcome to MkDocs"},{"location":"notes/about/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"notes/about/#project-layout","text":"1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"notes/about/#deployment","text":"1 git add . && git commit -m \"update\" && git push -u origin main && mkdocs gh-deploy --force Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod \u21a9","title":"Deployment"},{"location":"notes/CS224N/cs224n_lecture1/","text":"Lecture #1 Word Meaning Denotational Semantics Distributional Semantics Localist Representation (like one-hot vectors ) Distributed Representation (like word-vectors ) NLTK example: synonyms of word good 1 2 3 4 5 6 7 8 9 10 11 ## Word Meaning from nltk.corpus import wordnet as wn poses = { \"n\" : \"noun\" , \"v\" : \"verb\" , \"s\" : \"adj (s)\" , \"a\" : \"adj\" , \"r\" : \"adv\" } for synset in wn . synsets ( \"good\" ): print ( f \" { poses [ synset . pos ()] } : { '' . join ([ l . name () for l in synset . lemmas ()]) } \" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u276f python 01_word_meaning.py noun: good noun: goodgoodness noun: goodgoodness noun: commoditytrade_goodgood adj: good adj (s): fullgood adj: good adj (s): estimablegoodhonorablerespectable adj (s): beneficialgood adj (s): good adj (s): goodjustupright adj (s): adeptexpertgoodpracticedproficientskillfulskilful adj (s): good adj (s): deargoodnear adj (s): dependablegoodsafesecure adj (s): goodrightripe adj (s): goodwell adj (s): effectivegoodin_effectin_force adj (s): good adj (s): goodserious adj (s): goodsound adj (s): goodsalutary adj (s): goodhonest adj (s): goodundecomposedunspoiledunspoilt adj (s): good adv: wellgood adv: thoroughlysoundlygood Problems with toolkits like WordNet Great as a resource but missing nuance Example: proficent is listed as a synonym for good ; but it is correct only in some contexts. Missing new meaning of words Example: new slang words etc like wicked , badass , nifty etc. IMPOSSIBLE to keep up-to-date Very Subjective Requires human labour to curate and maintain Can't compute accurate word-similarity. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 02/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"Lecture 1"},{"location":"notes/CS224N/cs224n_lecture1/#lecture-1","text":"","title":"Lecture #1"},{"location":"notes/CS224N/cs224n_lecture1/#word-meaning","text":"Denotational Semantics Distributional Semantics Localist Representation (like one-hot vectors ) Distributed Representation (like word-vectors ) NLTK example: synonyms of word good 1 2 3 4 5 6 7 8 9 10 11 ## Word Meaning from nltk.corpus import wordnet as wn poses = { \"n\" : \"noun\" , \"v\" : \"verb\" , \"s\" : \"adj (s)\" , \"a\" : \"adj\" , \"r\" : \"adv\" } for synset in wn . synsets ( \"good\" ): print ( f \" { poses [ synset . pos ()] } : { '' . join ([ l . name () for l in synset . lemmas ()]) } \" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u276f python 01_word_meaning.py noun: good noun: goodgoodness noun: goodgoodness noun: commoditytrade_goodgood adj: good adj (s): fullgood adj: good adj (s): estimablegoodhonorablerespectable adj (s): beneficialgood adj (s): good adj (s): goodjustupright adj (s): adeptexpertgoodpracticedproficientskillfulskilful adj (s): good adj (s): deargoodnear adj (s): dependablegoodsafesecure adj (s): goodrightripe adj (s): goodwell adj (s): effectivegoodin_effectin_force adj (s): good adj (s): goodserious adj (s): goodsound adj (s): goodsalutary adj (s): goodhonest adj (s): goodundecomposedunspoiledunspoilt adj (s): good adv: wellgood adv: thoroughlysoundlygood Problems with toolkits like WordNet Great as a resource but missing nuance Example: proficent is listed as a synonym for good ; but it is correct only in some contexts. Missing new meaning of words Example: new slang words etc like wicked , badass , nifty etc. IMPOSSIBLE to keep up-to-date Very Subjective Requires human labour to curate and maintain Can't compute accurate word-similarity. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 02/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Word Meaning"},{"location":"notes/CS224N/cs224n_lecture1/#references","text":"","title":"References"},{"location":"notes/ECE542/ece542_hw1a/","text":"Homework 1a Author: Vinay Kumar (@imflash217) | Date: 31/January/2021 Q1 Q1 Given a vector \\(v \\in R^n\\) and square matrices \\(A, B \\in R^{n\\times n}\\) ; show that: \\(v^T v\\) = trace( \\(vv^T\\) ) trace(AB) = trace(BA) Q1 Solution Let \\(v = [v_1, v_2, \\cdots, v_n]^T\\) be a column vector of size \\((n,1)\\) - [ ] Then, $v^T v = $","title":"HW1a"},{"location":"notes/ECE542/ece542_hw1a/#homework-1a","text":"Author: Vinay Kumar (@imflash217) | Date: 31/January/2021","title":"Homework 1a"},{"location":"notes/ECE542/ece542_hw1a/#q1","text":"Q1 Given a vector \\(v \\in R^n\\) and square matrices \\(A, B \\in R^{n\\times n}\\) ; show that: \\(v^T v\\) = trace( \\(vv^T\\) ) trace(AB) = trace(BA) Q1 Solution Let \\(v = [v_1, v_2, \\cdots, v_n]^T\\) be a column vector of size \\((n,1)\\) - [ ] Then, $v^T v = $","title":"Q1"},{"location":"notes/ECE542/ece542_lecture1/","text":"Lecture #1 Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 AI v/s ML v/s DL (Venn Diagram) One-hot-encoding Loss Function Training v/s Evaluation Error Model Selection Hyperparams Overfitting v/s Underfitting Generalization Gap Model Capacity K-fold Cross Validation Leave-one-out Cross Validation What is Machine Learning? It is a field that aims to extract relationships and structures in the data. Example: How to map data to annotations? Loss Function We need a measure to see how well our system is doing at learning. This measure is called Loss Function Sum-of-Squared-Error (SSE): \\(2^2\\) \\(\\sum_{i}\\normalize{(y_i - f(x_i)}_2^2\\) Training The process of teaching our system to minimize errors is called as Training . Evaluation The process of determining the performance of our trained system over an unseen dataset is called as Evaluation . Unsupervised Learning Generative Models (GAN, AE, RBM) Latent Variable Modeling (PCA, AE) Clustering [special case of] Cross Validation If there are many point on the graph of CV( \\(\\theta\\) ) with similar values near the minimum; we choose the most parsimonious model that has a CV value within the standard deviation from the best model \\(\\theta^*\\) . In other words; we pick the first \\(\\theta\\) for which the CV value satisfies \\(CV(\\theta) < CV(\\theta^*) + std(CV(\\theta^*))\\) Benefits of this process: It decreases the possibility of choose an underfit or slightly ovefit model than what is required. Provides better Guarantees.","title":"Lecture 1"},{"location":"notes/ECE542/ece542_lecture1/#lecture-1","text":"Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 AI v/s ML v/s DL (Venn Diagram) One-hot-encoding Loss Function Training v/s Evaluation Error Model Selection Hyperparams Overfitting v/s Underfitting Generalization Gap Model Capacity K-fold Cross Validation Leave-one-out Cross Validation What is Machine Learning? It is a field that aims to extract relationships and structures in the data. Example: How to map data to annotations? Loss Function We need a measure to see how well our system is doing at learning. This measure is called Loss Function Sum-of-Squared-Error (SSE): \\(2^2\\) \\(\\sum_{i}\\normalize{(y_i - f(x_i)}_2^2\\) Training The process of teaching our system to minimize errors is called as Training . Evaluation The process of determining the performance of our trained system over an unseen dataset is called as Evaluation . Unsupervised Learning Generative Models (GAN, AE, RBM) Latent Variable Modeling (PCA, AE) Clustering [special case of] Cross Validation If there are many point on the graph of CV( \\(\\theta\\) ) with similar values near the minimum; we choose the most parsimonious model that has a CV value within the standard deviation from the best model \\(\\theta^*\\) . In other words; we pick the first \\(\\theta\\) for which the CV value satisfies \\(CV(\\theta) < CV(\\theta^*) + std(CV(\\theta^*))\\) Benefits of this process: It decreases the possibility of choose an underfit or slightly ovefit model than what is required. Provides better Guarantees.","title":"Lecture #1"},{"location":"projects/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"publications/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"publications/interspeech_2014/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Interspeech 2014"},{"location":"publications/odyssey_2014/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Odyssey 2014"},{"location":"python/cookbook_dabeaz/ch01/","text":"Data Structures & Algorithms 1.1: Unpacking a sequence into separate variables Problem You have a N-element tuple or sequence that you would like to unpack into a collection of N variables. Solution Any sequence or iterable can be unpacked into variables using a simple assignment operation. The only requirement is that the the number of variables and structure of the sequence must match . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##---------------------------------------------------------- p = ( 4 , 5 ) ## create a tuple x , y = p ## unpack the tuple into variables 'x' & 'y'. ## x=4; y=5 ##---------------------------------------------------------- data = [ \"ACME\" , 50 , 91.1 , ( 2021 , 10 , 07 )] name , shares , price , date = data ## unpack the list ## name=\"ACME\"; shares=50 ## price=91.1; date=(2021,10,07) ## another way to unpack the nested iterable or container ## name=\"ACME\"; shares=50; price=91.1; ## year = 2021; month=10; day=07 name , shares , price , ( year , month , day ) = data If there is a mismatch in the number of elements; you will get an ERROR. 1 2 p = ( 4 , 5 ) x , y , z = p 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> ValueError: need more than 2 values to unpack Discussion Unpacking actually works with any object that happens to be iterable (tuples, lists, dicts, str, files, iteratirs, generators...) 1.2: Unpacking elements from iterables of arbitrary length Problem You need to unpack N elements from an iterable ; but the iterable may be longer than N elements (causing a too many values to unpack exception) Solution 1.3 Keeping last N items Problem You want to keep a limited history of last few items seen during iteration. Solution Keeping a limited history is a perfect use for collections.deque 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \"\"\" Performs a simple text match on a sequence of lines and yields the matching line & previous N lines of context when found \"\"\" from collections import deque def search ( lines , pattern , history = 5 ): previous_lines = deque ( maxlen = history ) for line in lines : if pattern in line : yield line , previous_lines previous_lines . append ( line ) ##-----------------------------------------------------------## ## Example use ona file if __name__ == \"__main__\" : with open ( \"somefile.txt\" , \"r\" ) as f : for line , prev_lines in search ( f , \"my_pattern\" ): for x in lines : print ( x , end = \"\" ) print ( line , end = \"\" ) print ( \"--\" * 10 ) 1.5: Priority Queue Problem You want to implement a queue that sorts items by a given priority & always returns the item with highest priority on each pop operation. Solution The following class uses heapq module to implement a simple priority queue 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import heapq class PriorityQueue : def __init__ ( self ): self . _queue = [] self . _idx = 0 def __repr__ ( self ): return self . _queue def push ( self , item , priority ): ## because heappop returns the 1st item in the queue ## (which has the smallest priority); ## So, we need to invert the priority as (-priority) ## Thus, we get the item with highest priority on pop heapq . heappush ( self . _queue , ( - priority , self . _idx , item )) self . _idx += 1 def pop ( self ): \"\"\" Returns item with HIGHEST priority in the priority queue \"\"\" result = heapq . heappop ( self . _queue ) ## a tuple of type (-priority, idx, item) return result [ - 1 ] ## \"item\" from above line Here is an example of how we might use the above PriorityQueue class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Item : def __init__ ( self , name ): self . name = name def __repr__ ( self ): return f \"Item( { self . name } )\" ##-----------------------------------------------------------## q = PriorityQueue () ## Create a priority-queue object q . push ( Item ( \"foo\" ), priority = 1 ) ## push an Item(\"foo\") with priority=1 q . push ( Item ( \"bar\" ), priority = 5 ) ## push an Item(\"bar\") with priority=5 q . push ( Item ( \"spam\" ), priority = 4 ) ## push an Item(\"spam\") with priority=4 q . push ( Item ( \"grok\" ), priority = 1 ) ## push an Item(\"grok\") with priority=1 q . pop () ## Item(\"bar\") q . pop () ## Item(\"spam\") q . pop () ## Item(\"foo\") q . pop () ## Item(\"grok\") In the above example note that the items with same priority ( Item(\"foo\") and Item(\"grok\") ) are returned in the same order as they were inserted into the queue. Discussion The core of this recipe concerns with the use of heapq module. The methods heapq.heappush() and heapq.heappop() insert and remove items from self._queue in such a way that the first tem in the list has the smallest priority . The heappop() method always returns the smallest item; so that is the key idea to make our PriorityQueue pop correct items. In this recipe the queue consists of tuple (-priority, idx, item) . The priority value is negated to get the queue to sort items from highest priority to lowest priority . This is opposite from normal heap ordering; which sorts items from smallest to highest value. The role of the idx value is to properly order items with the same priority level. By keeping a constantly increasing index, the items will be sorted according to the order in which they were inserted. However, the idx also serves an important role in making the comparision work for items with the smae priority level. To elaborate on this, the instances of Item can't be ordered. 1 2 3 4 5 6 7 ## Item class objects cannot be compared; ## because we have not implemented __eq__, __le__ etc...methods to support it a = Item ( \"foo\" ) b = Item ( \"bar\" ) a < b ## ERROR. ## because \"Item\" object cannot be compared. 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> TypeError: unorderable types: Item () < Item () But, if you make (priority, item) tuple and compare them, then it works fine as long as the priorities are different. 1 2 3 4 5 6 7 ## tuples (priority, item) with different priorities. ## Comparision works fine a = ( 1 , Item ( \"foo\" )) b = ( 2 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because priority: 1 < 2 So, to handle the case of same priority value; the idx is used. The idx is always increasing and unique; so there is no chance of collision as shown below 1 2 3 4 5 6 7 ## Tuples (priority, idx, item) with same priorities but unique idx. ## Comparision works fine a = ( 1 , 7 , Item ( \"foo\" )) b = ( 1 , 8 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because idx: 7 < 8 1.6: collections.defaultdict Mapping Keys to multiple values in Dictionary You want to make a dictionary that maps keys to more than one value (so called multdict ) Solution A dictionary is a mapping where each key is mapped to a single value. If you want to map keys to multiple values ; you need to store multiple values in another container (like list or set or other container types ) 1 2 3 4 5 6 7 d = { \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 ], } e = { \"a\" : { 1 , 2 , 3 }, \"b\" : { 4 , 5 }, } 1. Use a list if you want to preserve the insertion-order of items. 2. Use a set if you want to eliminate duplicates . To easily construct such dictionaries, you can use collections.defaultdict . A feature of defaultdict is that it automatically initializes the first value so you can simply focus on adding items. 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( list ) ## use \"list\" as a constructor to initialize values map for new keys d [ \"a\" ] . append ( 1 ) ## d = {\"a\":[1]} d [ \"a\" ] . append ( 2 ) ## d = {\"a\":[1,2]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5,5]} duplication of 5 is allowed in list 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( set ) ## use \"set\" as a constructor to initialize values map for new keys d [ \"a\" ] . add ( 1 ) ## d = {\"a\": {1}} d [ \"a\" ] . add ( 2 ) ## d = {\"a\": {1,2}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} duplicates NOT allowed in \"set\" NOTE : One caution with defaultdict is that it will automatically create dictionary entries for keys accessed later on ( even if they aren't found in the dictionary ) i.e. instead of throwing KeyError for keys that are not found, it adds that key to the dictinary and maps its value to the empty constructor ( list or set etc. as above). If you want to avoid this behavior, its better to use usual dict() with setdefault() . This process is a bit messy and hard-to-read as shown below; but provides user-control to handle edge cases. 1 2 3 4 d = {} ## a regular dictionary d . setdefault ( \"a\" , []) . append ( 1 ) ## d = {\"a\": [1]} d . setdefault ( \"a\" , []) . append ( 2 ) ## d = {\"a\": [1,2]} d . setdefault ( \"b\" , []) . append ( 5 ) ## d = {\"a\": [1,2], \"b\": [5]} Discussion In principle, constructing a multivariate dictionary is simple. However, initialization of the first value can be messy if you try to do it yourself. Below two code-snippets show this tradeoff. 1 2 3 4 5 6 7 8 9 10 11 12 d = {} for key , value in pairs : if key not in d : d [ key ] = [] d [ key ] . append ( value ) ##--------------- v/s -----------------## from collections import defaultdict d = defaultdict () for key , value in items : d [ key ] . append ( value )","title":"Data Structures & Algorithms"},{"location":"python/cookbook_dabeaz/ch01/#data-structures-algorithms","text":"","title":"Data Structures &amp; Algorithms"},{"location":"python/cookbook_dabeaz/ch01/#11-unpacking-a-sequence-into-separate-variables","text":"Problem You have a N-element tuple or sequence that you would like to unpack into a collection of N variables. Solution Any sequence or iterable can be unpacked into variables using a simple assignment operation. The only requirement is that the the number of variables and structure of the sequence must match . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##---------------------------------------------------------- p = ( 4 , 5 ) ## create a tuple x , y = p ## unpack the tuple into variables 'x' & 'y'. ## x=4; y=5 ##---------------------------------------------------------- data = [ \"ACME\" , 50 , 91.1 , ( 2021 , 10 , 07 )] name , shares , price , date = data ## unpack the list ## name=\"ACME\"; shares=50 ## price=91.1; date=(2021,10,07) ## another way to unpack the nested iterable or container ## name=\"ACME\"; shares=50; price=91.1; ## year = 2021; month=10; day=07 name , shares , price , ( year , month , day ) = data If there is a mismatch in the number of elements; you will get an ERROR. 1 2 p = ( 4 , 5 ) x , y , z = p 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> ValueError: need more than 2 values to unpack Discussion Unpacking actually works with any object that happens to be iterable (tuples, lists, dicts, str, files, iteratirs, generators...)","title":"1.1: Unpacking a sequence into separate variables"},{"location":"python/cookbook_dabeaz/ch01/#12-unpacking-elements-from-iterables-of-arbitrary-length","text":"Problem You need to unpack N elements from an iterable ; but the iterable may be longer than N elements (causing a too many values to unpack exception) Solution","title":"1.2: Unpacking elements from iterables of arbitrary length"},{"location":"python/cookbook_dabeaz/ch01/#13-keeping-last-n-items","text":"Problem You want to keep a limited history of last few items seen during iteration. Solution Keeping a limited history is a perfect use for collections.deque 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \"\"\" Performs a simple text match on a sequence of lines and yields the matching line & previous N lines of context when found \"\"\" from collections import deque def search ( lines , pattern , history = 5 ): previous_lines = deque ( maxlen = history ) for line in lines : if pattern in line : yield line , previous_lines previous_lines . append ( line ) ##-----------------------------------------------------------## ## Example use ona file if __name__ == \"__main__\" : with open ( \"somefile.txt\" , \"r\" ) as f : for line , prev_lines in search ( f , \"my_pattern\" ): for x in lines : print ( x , end = \"\" ) print ( line , end = \"\" ) print ( \"--\" * 10 )","title":"1.3 Keeping last N items"},{"location":"python/cookbook_dabeaz/ch01/#15-priority-queue","text":"Problem You want to implement a queue that sorts items by a given priority & always returns the item with highest priority on each pop operation. Solution The following class uses heapq module to implement a simple priority queue 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import heapq class PriorityQueue : def __init__ ( self ): self . _queue = [] self . _idx = 0 def __repr__ ( self ): return self . _queue def push ( self , item , priority ): ## because heappop returns the 1st item in the queue ## (which has the smallest priority); ## So, we need to invert the priority as (-priority) ## Thus, we get the item with highest priority on pop heapq . heappush ( self . _queue , ( - priority , self . _idx , item )) self . _idx += 1 def pop ( self ): \"\"\" Returns item with HIGHEST priority in the priority queue \"\"\" result = heapq . heappop ( self . _queue ) ## a tuple of type (-priority, idx, item) return result [ - 1 ] ## \"item\" from above line Here is an example of how we might use the above PriorityQueue class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Item : def __init__ ( self , name ): self . name = name def __repr__ ( self ): return f \"Item( { self . name } )\" ##-----------------------------------------------------------## q = PriorityQueue () ## Create a priority-queue object q . push ( Item ( \"foo\" ), priority = 1 ) ## push an Item(\"foo\") with priority=1 q . push ( Item ( \"bar\" ), priority = 5 ) ## push an Item(\"bar\") with priority=5 q . push ( Item ( \"spam\" ), priority = 4 ) ## push an Item(\"spam\") with priority=4 q . push ( Item ( \"grok\" ), priority = 1 ) ## push an Item(\"grok\") with priority=1 q . pop () ## Item(\"bar\") q . pop () ## Item(\"spam\") q . pop () ## Item(\"foo\") q . pop () ## Item(\"grok\") In the above example note that the items with same priority ( Item(\"foo\") and Item(\"grok\") ) are returned in the same order as they were inserted into the queue. Discussion The core of this recipe concerns with the use of heapq module. The methods heapq.heappush() and heapq.heappop() insert and remove items from self._queue in such a way that the first tem in the list has the smallest priority . The heappop() method always returns the smallest item; so that is the key idea to make our PriorityQueue pop correct items. In this recipe the queue consists of tuple (-priority, idx, item) . The priority value is negated to get the queue to sort items from highest priority to lowest priority . This is opposite from normal heap ordering; which sorts items from smallest to highest value. The role of the idx value is to properly order items with the same priority level. By keeping a constantly increasing index, the items will be sorted according to the order in which they were inserted. However, the idx also serves an important role in making the comparision work for items with the smae priority level. To elaborate on this, the instances of Item can't be ordered. 1 2 3 4 5 6 7 ## Item class objects cannot be compared; ## because we have not implemented __eq__, __le__ etc...methods to support it a = Item ( \"foo\" ) b = Item ( \"bar\" ) a < b ## ERROR. ## because \"Item\" object cannot be compared. 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> TypeError: unorderable types: Item () < Item () But, if you make (priority, item) tuple and compare them, then it works fine as long as the priorities are different. 1 2 3 4 5 6 7 ## tuples (priority, item) with different priorities. ## Comparision works fine a = ( 1 , Item ( \"foo\" )) b = ( 2 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because priority: 1 < 2 So, to handle the case of same priority value; the idx is used. The idx is always increasing and unique; so there is no chance of collision as shown below 1 2 3 4 5 6 7 ## Tuples (priority, idx, item) with same priorities but unique idx. ## Comparision works fine a = ( 1 , 7 , Item ( \"foo\" )) b = ( 1 , 8 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because idx: 7 < 8","title":"1.5: Priority Queue"},{"location":"python/cookbook_dabeaz/ch01/#16-collectionsdefaultdict","text":"Mapping Keys to multiple values in Dictionary You want to make a dictionary that maps keys to more than one value (so called multdict ) Solution A dictionary is a mapping where each key is mapped to a single value. If you want to map keys to multiple values ; you need to store multiple values in another container (like list or set or other container types ) 1 2 3 4 5 6 7 d = { \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 ], } e = { \"a\" : { 1 , 2 , 3 }, \"b\" : { 4 , 5 }, } 1. Use a list if you want to preserve the insertion-order of items. 2. Use a set if you want to eliminate duplicates . To easily construct such dictionaries, you can use collections.defaultdict . A feature of defaultdict is that it automatically initializes the first value so you can simply focus on adding items. 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( list ) ## use \"list\" as a constructor to initialize values map for new keys d [ \"a\" ] . append ( 1 ) ## d = {\"a\":[1]} d [ \"a\" ] . append ( 2 ) ## d = {\"a\":[1,2]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5,5]} duplication of 5 is allowed in list 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( set ) ## use \"set\" as a constructor to initialize values map for new keys d [ \"a\" ] . add ( 1 ) ## d = {\"a\": {1}} d [ \"a\" ] . add ( 2 ) ## d = {\"a\": {1,2}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} duplicates NOT allowed in \"set\" NOTE : One caution with defaultdict is that it will automatically create dictionary entries for keys accessed later on ( even if they aren't found in the dictionary ) i.e. instead of throwing KeyError for keys that are not found, it adds that key to the dictinary and maps its value to the empty constructor ( list or set etc. as above). If you want to avoid this behavior, its better to use usual dict() with setdefault() . This process is a bit messy and hard-to-read as shown below; but provides user-control to handle edge cases. 1 2 3 4 d = {} ## a regular dictionary d . setdefault ( \"a\" , []) . append ( 1 ) ## d = {\"a\": [1]} d . setdefault ( \"a\" , []) . append ( 2 ) ## d = {\"a\": [1,2]} d . setdefault ( \"b\" , []) . append ( 5 ) ## d = {\"a\": [1,2], \"b\": [5]} Discussion In principle, constructing a multivariate dictionary is simple. However, initialization of the first value can be messy if you try to do it yourself. Below two code-snippets show this tradeoff. 1 2 3 4 5 6 7 8 9 10 11 12 d = {} for key , value in pairs : if key not in d : d [ key ] = [] d [ key ] . append ( value ) ##--------------- v/s -----------------## from collections import defaultdict d = defaultdict () for key , value in items : d [ key ] . append ( value )","title":"1.6: collections.defaultdict"},{"location":"work/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"work/aros/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"ARoS Lab, NC State"},{"location":"work/cognizant/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Cognizant"},{"location":"work/flashai/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Flash.AI"},{"location":"work/ivmcl/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"iVMCL Lab, NC State"},{"location":"work/meeami/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Meeami Technologies"},{"location":"work/springboard/","text":"","title":"Springboard Inc."}]}