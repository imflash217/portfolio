{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".card { box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2); transition: 0.3s; width: 60%; display: flex; margin: auto; } .card:hover { box-shadow: 0 8px 16px 0 rgba(0,0,0,0.2); } .container { padding: 2px 10px; } Vinay Kumar / \u0935\u093f\u0928\u092f \u0915\u0941\u092e\u093e\u0930 Machine Learning Engineer \ud83c\udf93 BTech in EE @IIT-Hyderabad \ud83c\udf93 Masters in EE @NC State University Find me on GitHub , LinkedIn & WandB by the handle @imflash217 or drop me an email at vkumar24@ncsu.edu","title":"\ud83c\udfe1 Home / \u0917\u0943\u0939"},{"location":"awesome/","text":"\ud83d\udfe1 PositionalEncoding: https://e2eml.school/transformers.html \u21a9 \ud83d\udfe1 PositionalEncoding: https://github.com/tensorflow/tensor2tensor/issues/1591 \u21a9 \ud83d\udfe2 PositionalEncoding: https://kazemnejad.com/blog/transformer_architecture_positional_encoding/ \u21a9 \ud83d\udfe1 BatchNorm: https://colab.research.google.com/drive/1Sw2GXJmylz9DvtPaBfJIeutoXNISelZy?usp=sharing \u21a9 \ud83d\udfe2 BatchNorm: https://e2eml.school/batch_normalization.html \u21a9 \ud83d\udfe1 How BatchNorm Helps? https://arxiv.org/pdf/1805.11604.pdf \u21a9 \ud83d\udfe1 Understanding BatchNorm: https://proceedings.neurips.cc/paper/2018/file/36072923bfc3cf47745d704feb489480-Paper.pdf \u21a9 \ud83d\udfe1 Batch-ReNorm: https://arxiv.org/pdf/1702.03275.pdf \u21a9 \ud83d\udfe1 StreamingNorm: https://arxiv.org/pdf/1610.06160.pdf \u21a9 \ud83d\udfe1 Online Norm: https://proceedings.neurips.cc/paper/2019/file/cb3ce9b06932da6faaa7fc70d5b5d2f4-Paper.pdf \u21a9 \ud83d\udfe2 How optimization works: https://e2eml.school/how_optimization_works_1.html \u21a9 \ud83d\udfe2 How optimization works: https://e2eml.school/how_optimization_works_2.html \u21a9 \ud83d\udfe2 Optimizing a linear model: https://e2eml.school/how_optimization_works_3.html \u21a9 \ud83d\udfe2 Optimizing complex models: https://e2eml.school/how_optimization_works_4.html \u21a9 \ud83d\udfe2 EINSUM: https://obilaniu6266h16.wordpress.com/2016/02/04/einstein-summation-in-numpy/ \u21a9 \ud83d\udfe2 EINSUM: https://rockt.github.io/2018/04/30/einsum \u21a9 \ud83d\udfe2 EINSUM: https://ajcr.net/Basic-guide-to-einsum/ \u21a9 \ud83d\udfe2 einops: https://einops.rocks/ \u21a9 \ud83d\udfe2 einops EXAMPLES: http://einops.rocks/pytorch-examples.html \u21a9 \ud83d\udfe2 EINSUM / einops / PyTorch: https://theaisummer.com/einsum-attention/ \u21a9","title":"\ud83c\udf1f Awesome List"},{"location":"algorithms/023_add_lists/","text":"Problem","title":"023 add lists"},{"location":"algorithms/023_add_lists/#problem","text":"","title":"Problem"},{"location":"algorithms/024_depth_first_values/","text":"Problem","title":"024 depth first values"},{"location":"algorithms/024_depth_first_values/#problem","text":"","title":"Problem"},{"location":"algorithms/025_breadth_first_values/","text":"Problem","title":"025 breadth first values"},{"location":"algorithms/025_breadth_first_values/#problem","text":"","title":"Problem"},{"location":"algorithms/026_tree_includes/","text":"Problem","title":"026 tree includes"},{"location":"algorithms/026_tree_includes/#problem","text":"","title":"Problem"},{"location":"algorithms/027_tree_sum/","text":"Problem","title":"027 tree sum"},{"location":"algorithms/027_tree_sum/#problem","text":"","title":"Problem"},{"location":"algorithms/028_tree_min_value/","text":"Problem","title":"028 tree min value"},{"location":"algorithms/028_tree_min_value/#problem","text":"","title":"Problem"},{"location":"algorithms/QA/","text":"Linked List Question #1 What two properties are typically stored in the nodes of a singly linked list? value and next Question #2 What terms are commonly used to describe the first node & last node of a linked list? HEAD for first-node TAIL for last-node Question #3 What is the dummy head pattern for a linked-list? The dummy head pattern is where we use a fake node to act as the HEAD of the linked-list. The dummy-head is used to simplify edge cases such as inserting teh first node into an empty linked-list. Question #4 Why might the expression current_node.next.val be UNSAFE? If the current node is a TAIL-node then its .next will be None and None object does not have .val attribute. Question #5 What is the OPTIMAL COMPLEXITY for searching a target value in a tandard singly-linked-list ? \\(O(n)\\) time-complexity and \\(O(1)\\) space-complexity for ITERATIVE Solution. \\(O(n)\\) time-complexity and \\(O(n)\\) space-complexity for RECURSIVE solution.","title":"Q/A"},{"location":"algorithms/QA/#linked-list","text":"Question #1 What two properties are typically stored in the nodes of a singly linked list? value and next Question #2 What terms are commonly used to describe the first node & last node of a linked list? HEAD for first-node TAIL for last-node Question #3 What is the dummy head pattern for a linked-list? The dummy head pattern is where we use a fake node to act as the HEAD of the linked-list. The dummy-head is used to simplify edge cases such as inserting teh first node into an empty linked-list. Question #4 Why might the expression current_node.next.val be UNSAFE? If the current node is a TAIL-node then its .next will be None and None object does not have .val attribute. Question #5 What is the OPTIMAL COMPLEXITY for searching a target value in a tandard singly-linked-list ? \\(O(n)\\) time-complexity and \\(O(1)\\) space-complexity for ITERATIVE Solution. \\(O(n)\\) time-complexity and \\(O(n)\\) space-complexity for RECURSIVE solution.","title":"Linked List"},{"location":"algorithms/arrays/","text":"Arrays Author: Vinay Kumar (@imflash217) | Date: 15/March/2021 Definition Definition An Array is an ordered list of data that we access with a numerical index. Generally speaking an array is allocated upfront as a single block of memory based on the number of elements and type of the data we want the array to hold. This allows us to read and write elements into the array efficiently, since our program knows exactly where each element is stored in the memory. On the other hand removing , adding and finding arbitrary values in an array can be a linear-time operation. Removing or splicing requires shifting all elements by one to fill the gap. Inserting a new element would requires shifting or allocating a new larger array to hold the elements. Finding an element in the array would require iterating over the entire array in the worst-case. Dynamic Array Dynamic Arrays It is worth noting that in many statically-typed programming languages (e.g. Java, C++); an array is limited to its initially declared size . ALL modern languages support DYNAMICALLY-SIZED arrays; which automatically increase or decrease their size by allocating a new copy of the array when it begins to run out-of-memory. Dynamic arrays guarantee better amortized performance by only performing these costly operations when necessary. Calculating Memory Usage Calculating Memory Usage To calculate the memory usage of an array simply multiply the size of the array with the size of the data-type. What is the memory usage of an array that contains one-thousand 32-bit integers? 1 1000 * 32 bits = 1000 * 4 bytes = 4000 bytes = 4Kb What is the memory usage of an array that contains one-hundred 10-char strings? 1 100 * 10 chars = 100 * 10 * 1 byte = 1000 bytes = 1Kb Common Array Operations Common Array Operations Insert an item Remove an item Update an item Find an item Loop over array Copy an array Copy-part-of-the-array Sort an array Reverse an array Swap an array Filter an array When to use an array in an interview When to use an array in an interview Use an array when you need dta in an ordered list with fast-indexing or compact-memory-footprint . Don't use an array if you need to search for unsorted items efficiently or insert and remove items frequently.","title":"Arrays"},{"location":"algorithms/arrays/#arrays","text":"Author: Vinay Kumar (@imflash217) | Date: 15/March/2021","title":"Arrays"},{"location":"algorithms/arrays/#definition","text":"Definition An Array is an ordered list of data that we access with a numerical index. Generally speaking an array is allocated upfront as a single block of memory based on the number of elements and type of the data we want the array to hold. This allows us to read and write elements into the array efficiently, since our program knows exactly where each element is stored in the memory. On the other hand removing , adding and finding arbitrary values in an array can be a linear-time operation. Removing or splicing requires shifting all elements by one to fill the gap. Inserting a new element would requires shifting or allocating a new larger array to hold the elements. Finding an element in the array would require iterating over the entire array in the worst-case.","title":"Definition"},{"location":"algorithms/arrays/#dynamic-array","text":"Dynamic Arrays It is worth noting that in many statically-typed programming languages (e.g. Java, C++); an array is limited to its initially declared size . ALL modern languages support DYNAMICALLY-SIZED arrays; which automatically increase or decrease their size by allocating a new copy of the array when it begins to run out-of-memory. Dynamic arrays guarantee better amortized performance by only performing these costly operations when necessary.","title":"Dynamic Array"},{"location":"algorithms/arrays/#calculating-memory-usage","text":"Calculating Memory Usage To calculate the memory usage of an array simply multiply the size of the array with the size of the data-type. What is the memory usage of an array that contains one-thousand 32-bit integers? 1 1000 * 32 bits = 1000 * 4 bytes = 4000 bytes = 4Kb What is the memory usage of an array that contains one-hundred 10-char strings? 1 100 * 10 chars = 100 * 10 * 1 byte = 1000 bytes = 1Kb","title":"Calculating Memory Usage"},{"location":"algorithms/arrays/#common-array-operations","text":"Common Array Operations Insert an item Remove an item Update an item Find an item Loop over array Copy an array Copy-part-of-the-array Sort an array Reverse an array Swap an array Filter an array","title":"Common Array Operations"},{"location":"algorithms/arrays/#when-to-use-an-array-in-an-interview","text":"When to use an array in an interview Use an array when you need dta in an ordered list with fast-indexing or compact-memory-footprint . Don't use an array if you need to search for unsorted items efficiently or insert and remove items frequently.","title":"When to use an array in an interview"},{"location":"algorithms/binary_tree/","text":"25: Depth First values Depth First Values Write a function, depth_first_values , that takes in the root of a binary tree. The function should return a list containing all values of the tree in depth-first order . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 a = Node ( 'a' ) b = Node ( 'b' ) c = Node ( 'c' ) d = Node ( 'd' ) e = Node ( 'e' ) f = Node ( 'f' ) g = Node ( 'g' ) a . left = b a . right = c b . left = d b . right = e c . right = f e . left = g # a # / \\ # b c # / \\ \\ # d e f # / # g depth_first_values ( a ) # -> ['a', 'b', 'd', 'e', 'g', 'c', 'f'] Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def depth_first_values ( root ): \"\"\"recursive solution Depth First Traversal\"\"\" ## base case if root is None : return [] left_values = depth_first_values ( root . left ) right_values = depth_first_values ( root . right ) ## in DFS, the visiting order is ## root, left-child, right-child return [ root . val , * left_values , * right_values ] 26: Breadth First Values Breadth First Values Write a function, breadth_first_values , that takes in the root of a binary tree. The function should return a list containing all values of the tree in breadth-first order . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 a = Node ( 'a' ) b = Node ( 'b' ) c = Node ( 'c' ) d = Node ( 'd' ) e = Node ( 'e' ) x = Node ( 'x' ) a . right = b b . left = c c . left = x c . right = d d . right = e # a # \\ # b # / # c # / \\ # x d # \\ # e breadth_first_values ( a ) # -> ['a', 'b', 'c', 'x', 'd', 'e'] Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def breadth_first_values ( root ): ## base case for empty tree if root is None : return [] ## using double-ended queue struct from collections import deque ## step-1: add the root into the queue queue = deque ([ root ]) visited = [] while queue : ## grabbing current visited node current_node = queue . popleft () ## put that node in the visited list visited . append ( current_node . val ) ## and add their children (if present) into the queue if current_node . left : queue . append ( current_node . left ) if current_node . right : queue . append ( current_node . right ) return visited 27: Tree Includes Problem Write a function, tree_includes, that takes in the root of a binary tree and a target value. The function should return a boolean indicating whether or not the value is contained in the tree. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 a = Node ( \"a\" ) b = Node ( \"b\" ) c = Node ( \"c\" ) d = Node ( \"d\" ) e = Node ( \"e\" ) f = Node ( \"f\" ) a . left = b a . right = c b . left = d b . right = e c . right = f # a # / \\ # b c # / \\ \\ # d e f tree_includes ( a , \"e\" ) # -> True Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def tree_includes ( root , target ): ## base case of leaf-nodes if not root : return False ## success if root . val == target : return True ## else search in the children tree return tree_includes ( root . left , target ) or tree_includes ( root . right , target ) 28: Tree Sum Problem Write a function, tree_sum , that takes in the root of a binary tree that contains number values. The function should return the total sum of all values in the tree. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 a = Node ( 3 ) b = Node ( 11 ) c = Node ( 4 ) d = Node ( 4 ) e = Node ( - 2 ) f = Node ( 1 ) a . left = b a . right = c b . left = d b . right = e c . right = f # 3 # / \\ # 11 4 # / \\ \\ # 4 -2 1 tree_sum ( a ) # -> 21 Solution 1 2 3 4 5 6 7 8 9 10 11 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def tree_sum ( root ): if not root : return 0 ## base-case of leaf nodes left_sum = tree_sum ( root . left ) ## sum of left subtree right_sum = tree_sum ( root . right ) ## sum of right subtree return root . val + left_sum + right_sum 29: Binary Tree Min Value Minimum value in a binary tree Write a function, tree_min_value, that takes in the root of a binary tree that contains number values. The function should return the minimum value within the tree. You may assume that the input tree is non-empty. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 a = Node ( 3 ) b = Node ( 11 ) c = Node ( 4 ) d = Node ( 4 ) e = Node ( - 2 ) f = Node ( 1 ) a . left = b a . right = c b . left = d b . right = e c . right = f # 3 # / \\ # 11 4 # / \\ \\ # 4 -2 1 tree_min_value ( a ) # -> -2 Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def tree_min_value ( root ): import math if not root : return math . inf ## base case for leaf nodes's children left_min = tree_min_value ( root . left ) ## minimum value in left subtree right_min = tree_min_value ( root . right ) ## minimum value in right subtree return min ( root . val , left_min , right_min ) ## return minimum of root, lef, & right subtrees 30:","title":"Binary Tree"},{"location":"algorithms/binary_tree/#25-depth-first-values","text":"Depth First Values Write a function, depth_first_values , that takes in the root of a binary tree. The function should return a list containing all values of the tree in depth-first order . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 a = Node ( 'a' ) b = Node ( 'b' ) c = Node ( 'c' ) d = Node ( 'd' ) e = Node ( 'e' ) f = Node ( 'f' ) g = Node ( 'g' ) a . left = b a . right = c b . left = d b . right = e c . right = f e . left = g # a # / \\ # b c # / \\ \\ # d e f # / # g depth_first_values ( a ) # -> ['a', 'b', 'd', 'e', 'g', 'c', 'f'] Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def depth_first_values ( root ): \"\"\"recursive solution Depth First Traversal\"\"\" ## base case if root is None : return [] left_values = depth_first_values ( root . left ) right_values = depth_first_values ( root . right ) ## in DFS, the visiting order is ## root, left-child, right-child return [ root . val , * left_values , * right_values ]","title":"25: Depth First values"},{"location":"algorithms/binary_tree/#26-breadth-first-values","text":"Breadth First Values Write a function, breadth_first_values , that takes in the root of a binary tree. The function should return a list containing all values of the tree in breadth-first order . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 a = Node ( 'a' ) b = Node ( 'b' ) c = Node ( 'c' ) d = Node ( 'd' ) e = Node ( 'e' ) x = Node ( 'x' ) a . right = b b . left = c c . left = x c . right = d d . right = e # a # \\ # b # / # c # / \\ # x d # \\ # e breadth_first_values ( a ) # -> ['a', 'b', 'c', 'x', 'd', 'e'] Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def breadth_first_values ( root ): ## base case for empty tree if root is None : return [] ## using double-ended queue struct from collections import deque ## step-1: add the root into the queue queue = deque ([ root ]) visited = [] while queue : ## grabbing current visited node current_node = queue . popleft () ## put that node in the visited list visited . append ( current_node . val ) ## and add their children (if present) into the queue if current_node . left : queue . append ( current_node . left ) if current_node . right : queue . append ( current_node . right ) return visited","title":"26: Breadth First Values"},{"location":"algorithms/binary_tree/#27-tree-includes","text":"Problem Write a function, tree_includes, that takes in the root of a binary tree and a target value. The function should return a boolean indicating whether or not the value is contained in the tree. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 a = Node ( \"a\" ) b = Node ( \"b\" ) c = Node ( \"c\" ) d = Node ( \"d\" ) e = Node ( \"e\" ) f = Node ( \"f\" ) a . left = b a . right = c b . left = d b . right = e c . right = f # a # / \\ # b c # / \\ \\ # d e f tree_includes ( a , \"e\" ) # -> True Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def tree_includes ( root , target ): ## base case of leaf-nodes if not root : return False ## success if root . val == target : return True ## else search in the children tree return tree_includes ( root . left , target ) or tree_includes ( root . right , target )","title":"27: Tree Includes"},{"location":"algorithms/binary_tree/#28-tree-sum","text":"Problem Write a function, tree_sum , that takes in the root of a binary tree that contains number values. The function should return the total sum of all values in the tree. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 a = Node ( 3 ) b = Node ( 11 ) c = Node ( 4 ) d = Node ( 4 ) e = Node ( - 2 ) f = Node ( 1 ) a . left = b a . right = c b . left = d b . right = e c . right = f # 3 # / \\ # 11 4 # / \\ \\ # 4 -2 1 tree_sum ( a ) # -> 21 Solution 1 2 3 4 5 6 7 8 9 10 11 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def tree_sum ( root ): if not root : return 0 ## base-case of leaf nodes left_sum = tree_sum ( root . left ) ## sum of left subtree right_sum = tree_sum ( root . right ) ## sum of right subtree return root . val + left_sum + right_sum","title":"28: Tree Sum"},{"location":"algorithms/binary_tree/#29-binary-tree-min-value","text":"Minimum value in a binary tree Write a function, tree_min_value, that takes in the root of a binary tree that contains number values. The function should return the minimum value within the tree. You may assume that the input tree is non-empty. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 a = Node ( 3 ) b = Node ( 11 ) c = Node ( 4 ) d = Node ( 4 ) e = Node ( - 2 ) f = Node ( 1 ) a . left = b a . right = c b . left = d b . right = e c . right = f # 3 # / \\ # 11 4 # / \\ \\ # 4 -2 1 tree_min_value ( a ) # -> -2 Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 # class Node: # def __init__(self, val): # self.val = val # self.left = None # self.right = None def tree_min_value ( root ): import math if not root : return math . inf ## base case for leaf nodes's children left_min = tree_min_value ( root . left ) ## minimum value in left subtree right_min = tree_min_value ( root . right ) ## minimum value in right subtree return min ( root . val , left_min , right_min ) ## return minimum of root, lef, & right subtrees","title":"29: Binary Tree Min Value"},{"location":"algorithms/binary_tree/#30","text":"","title":"30:"},{"location":"algorithms/document_distance/","text":"Document Distance Call Graph for the code 1 2 3 4 5 6 - main() - word_frequencies_for_file() - get_words_from_line_list() - count_frequency() - vector_angle() - inner_product() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"Document Distance"},{"location":"algorithms/document_distance/#document-distance","text":"Call Graph for the code 1 2 3 4 5 6 - main() - word_frequencies_for_file() - get_words_from_line_list() - count_frequency() - vector_angle() - inner_product() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Document Distance"},{"location":"algorithms/document_distance/#references","text":"","title":"References"},{"location":"algorithms/hashtables/","text":"Hash Tables Author: Vinay Kumar (@imflash217) | Date: 29/January/2021 Definition Definition Hash Table is a data structure which stores data in an associative manner (i.e. in a (key, value) pair). In a hash table, the data is stored in an array format where each data-value has its own unique index-value. Due to this feature, the access to data becomes very fast if we know the desired index-value; irrespective of the size of the data. Hash Table uses an array as a storage medium and uses hashing to generate the index where an element is to be inserted or to be located from. Hashing Hashing Hashing is a technique to map a range of keys into a range of indexes (usually of an array). A very generic hashing function is modulo operator ( x % y ). Example Example of Hashing Consider a hash-table of size=20 Following ( key , value ) pairs to be stored using the hash-table 1 2 3 4 5 dict = { 9 : 20 , 12 : 70 , 42 : 80 , 7 : 25 , 2 : 21 } Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 2 As we can see that a given hashing function can create the same hash-value from two different keys. (in above table keys 42 and 2 ). So we use Linear Probing to resolve conflicts. Linear Probing Linear Probing Linear Probing is a method used to resolve conflicts in the hash-value. It may happen that the hash-function creates an already used index of the array. In such case we search the next empty location of the array by looking into the next cell until we find an empty cell So in our above example, the updated hash-table would map key = 2 to index = 3 : Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 3 Search search() method for hash-table Search Delete delete() method for hash-table Delete Python Implementation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 class HashTable : def __init__ ( self , table_size ): \"\"\" Args: table_size (int): the size of the hash table. \"\"\" super () . __init__ () self . table_size = table_size self . hash_table = [[] for _ in range ( self . table_size )] ## ! this kind of nested lists DS is useful for CHAINING def hashing_func ( self , key ): \"\"\"Hashing Function Args: key (int): the key Returns: [int]: index of the hash-table \"\"\" hash = key % self . table_size return hash def insert_linear_probing ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using LINEAR PROBING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) if len ( self . hash_table [ hash_key ]) == 0 : self . hash_table [ hash_key ] . append ( value ) else : ## ! collision happened. so search for the available slot pass def insert ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using TABLE CHAINING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) key_exists = False bucket = self . hash_table [ hash_key ] # print(bucket) for i , kv in enumerate ( bucket ): # print(i, kv) k , v = kv if k == key : key_exists = True break if key_exists : bucket [ i ] = ( key , value ) ## ! the original key already exists. So OVERRIDE else : bucket . append (( key , value )) ## ! two different keys COLLIDING. So APPEND using CHAINING def search ( self , key ): \"\"\"Searching for a \"key\" and returning its (key, value) pair Args: key (int): any hashable type (as per the hash function used) Returns: (key, value) pair \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] for i , kv in enumerate ( bucket ): k , v = kv if k == key : return ( k , v ) def delete ( self , key ): \"\"\"Delete a given key (if present in the hashtable) Args: key ([type]): [description] \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] key_exists = False for i , kv in enumerate ( bucket ): k , v = kv if k == key : key_exists = True break if key_exists : del bucket [ i ] print ( f \"key = { key } is deleted.\" ) else : print ( f \"key= { key } not found.\" ) ########################################################################################## if __name__ == \"__main__\" : import pprint hashtable = HashTable ( table_size = 9 ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 12 , value = \"barry\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 13 , value = \"vinay\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash217\" ) pprint . pprint ( hashtable . hash_table ) ## searching pprint . pprint ( hashtable . search ( key = 32 )) ## deleting hashtable . delete ( key = 13 ) pprint . pprint ( hashtable . hash_table ) ########################################################################################## References https://www.hackerearth.com/practice/data-structures/hash-tables/basics-of-hash-tables/tutorial/ \u21a9 https://www.tutorialspoint.com/python_data_structure/python_hash_table.htm \u21a9 https://www.tutorialspoint.com/data_structures_algorithms/hash_data_structure.htm \u21a9 http://blog.chapagain.com.np/hash-table-implementation-in-python-data-structures-algorithms/ \u21a9 https://runestone.academy/runestone/books/published/pythonds/SortSearch/Hashing.html \u21a9 http://paulmouzas.github.io/2014/12/31/implementing-a-hash-table.html \u21a9","title":"Hash Tables"},{"location":"algorithms/hashtables/#hash-tables","text":"Author: Vinay Kumar (@imflash217) | Date: 29/January/2021","title":"Hash Tables"},{"location":"algorithms/hashtables/#definition","text":"Definition Hash Table is a data structure which stores data in an associative manner (i.e. in a (key, value) pair). In a hash table, the data is stored in an array format where each data-value has its own unique index-value. Due to this feature, the access to data becomes very fast if we know the desired index-value; irrespective of the size of the data. Hash Table uses an array as a storage medium and uses hashing to generate the index where an element is to be inserted or to be located from.","title":"Definition"},{"location":"algorithms/hashtables/#hashing","text":"Hashing Hashing is a technique to map a range of keys into a range of indexes (usually of an array). A very generic hashing function is modulo operator ( x % y ).","title":"Hashing"},{"location":"algorithms/hashtables/#example","text":"Example of Hashing Consider a hash-table of size=20 Following ( key , value ) pairs to be stored using the hash-table 1 2 3 4 5 dict = { 9 : 20 , 12 : 70 , 42 : 80 , 7 : 25 , 2 : 21 } Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 2 As we can see that a given hashing function can create the same hash-value from two different keys. (in above table keys 42 and 2 ). So we use Linear Probing to resolve conflicts.","title":"Example"},{"location":"algorithms/hashtables/#linear-probing","text":"Linear Probing Linear Probing is a method used to resolve conflicts in the hash-value. It may happen that the hash-function creates an already used index of the array. In such case we search the next empty location of the array by looking into the next cell until we find an empty cell So in our above example, the updated hash-table would map key = 2 to index = 3 : Key Hash Array index 9 9 % 20 = 9 9 12 12 % 20 = 12 12 42 42 % 20 = 2 2 7 7 % 20 = 7 7 2 2 % 20 = 2 3","title":"Linear Probing"},{"location":"algorithms/hashtables/#search","text":"search() method for hash-table Search","title":"Search"},{"location":"algorithms/hashtables/#delete","text":"delete() method for hash-table Delete","title":"Delete"},{"location":"algorithms/hashtables/#python-implementation","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 class HashTable : def __init__ ( self , table_size ): \"\"\" Args: table_size (int): the size of the hash table. \"\"\" super () . __init__ () self . table_size = table_size self . hash_table = [[] for _ in range ( self . table_size )] ## ! this kind of nested lists DS is useful for CHAINING def hashing_func ( self , key ): \"\"\"Hashing Function Args: key (int): the key Returns: [int]: index of the hash-table \"\"\" hash = key % self . table_size return hash def insert_linear_probing ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using LINEAR PROBING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) if len ( self . hash_table [ hash_key ]) == 0 : self . hash_table [ hash_key ] . append ( value ) else : ## ! collision happened. so search for the available slot pass def insert ( self , key , value ): \"\"\" Insert a (key, value) pair in the hash table. Using TABLE CHAINING Args: key (int): the key to be hashed value (any type): value to be stored \"\"\" hash_key = self . hashing_func ( key = key ) key_exists = False bucket = self . hash_table [ hash_key ] # print(bucket) for i , kv in enumerate ( bucket ): # print(i, kv) k , v = kv if k == key : key_exists = True break if key_exists : bucket [ i ] = ( key , value ) ## ! the original key already exists. So OVERRIDE else : bucket . append (( key , value )) ## ! two different keys COLLIDING. So APPEND using CHAINING def search ( self , key ): \"\"\"Searching for a \"key\" and returning its (key, value) pair Args: key (int): any hashable type (as per the hash function used) Returns: (key, value) pair \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] for i , kv in enumerate ( bucket ): k , v = kv if k == key : return ( k , v ) def delete ( self , key ): \"\"\"Delete a given key (if present in the hashtable) Args: key ([type]): [description] \"\"\" hash_key = self . hashing_func ( key = key ) bucket = self . hash_table [ hash_key ] key_exists = False for i , kv in enumerate ( bucket ): k , v = kv if k == key : key_exists = True break if key_exists : del bucket [ i ] print ( f \"key = { key } is deleted.\" ) else : print ( f \"key= { key } not found.\" ) ########################################################################################## if __name__ == \"__main__\" : import pprint hashtable = HashTable ( table_size = 9 ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 12 , value = \"barry\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 13 , value = \"vinay\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash\" ) pprint . pprint ( hashtable . hash_table ) hashtable . insert ( key = 32 , value = \"flash217\" ) pprint . pprint ( hashtable . hash_table ) ## searching pprint . pprint ( hashtable . search ( key = 32 )) ## deleting hashtable . delete ( key = 13 ) pprint . pprint ( hashtable . hash_table ) ##########################################################################################","title":"Python Implementation"},{"location":"algorithms/hashtables/#references","text":"https://www.hackerearth.com/practice/data-structures/hash-tables/basics-of-hash-tables/tutorial/ \u21a9 https://www.tutorialspoint.com/python_data_structure/python_hash_table.htm \u21a9 https://www.tutorialspoint.com/data_structures_algorithms/hash_data_structure.htm \u21a9 http://blog.chapagain.com.np/hash-table-implementation-in-python-data-structures-algorithms/ \u21a9 https://runestone.academy/runestone/books/published/pythonds/SortSearch/Hashing.html \u21a9 http://paulmouzas.github.io/2014/12/31/implementing-a-hash-table.html \u21a9","title":"References"},{"location":"algorithms/linked_list/","text":"23: Adding lists Add lists Write in a function that takes head of two linked lists , each representing a number. The nodes of the linked-lists contain digits as value. The nodes in the input lists are reversed (i.e. the least significant digit of the number is head). The function should return the head of the new linked list representing the sum of the input lists. The output should have its digits reversed as well. 1 2 3 4 5 6 7 8 9 10 11 12 13 Say we wanted to compute 621 + 354 normally. The sum is 975: 621 + 354 ----- 975 Then, the reversed linked list format of this problem would appear as: 1 -> 2 -> 6 + 4 -> 5 -> 3 -------------- 5 -> 7 -> 9 Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Node : def __init__ ( self , val ): super () . __init__ () self . val = val self . next = None def add_lists ( head_1 , head_2 , carry = 0 ): \"\"\"Recursive solution\"\"\" ## base case: if head_1 is None and head_2 is None and carry == 0 : return None ## grab the values of each node ## or use a dummy value 0 if the node is None val_1 = head_1 . val if head_1 else 0 val_2 = head_2 . val if head_2 else 0 _sum = val_1 + val_2 + carry ## add the two values digit = _sum % 10 ## accounting for carry (next line) carry = 1 if _sum >= 10 else 0 result = Node ( digit ) ## create a new \"Node\" with new digit next_1 = head_1 . next if head_1 else None next_2 = head_2 . next if head_2 else None result . next = add_lists ( next_1 , next_2 , carry ) ## recursive call return result Discussion ...","title":"Linked List"},{"location":"algorithms/linked_list/#23-adding-lists","text":"Add lists Write in a function that takes head of two linked lists , each representing a number. The nodes of the linked-lists contain digits as value. The nodes in the input lists are reversed (i.e. the least significant digit of the number is head). The function should return the head of the new linked list representing the sum of the input lists. The output should have its digits reversed as well. 1 2 3 4 5 6 7 8 9 10 11 12 13 Say we wanted to compute 621 + 354 normally. The sum is 975: 621 + 354 ----- 975 Then, the reversed linked list format of this problem would appear as: 1 -> 2 -> 6 + 4 -> 5 -> 3 -------------- 5 -> 7 -> 9 Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Node : def __init__ ( self , val ): super () . __init__ () self . val = val self . next = None def add_lists ( head_1 , head_2 , carry = 0 ): \"\"\"Recursive solution\"\"\" ## base case: if head_1 is None and head_2 is None and carry == 0 : return None ## grab the values of each node ## or use a dummy value 0 if the node is None val_1 = head_1 . val if head_1 else 0 val_2 = head_2 . val if head_2 else 0 _sum = val_1 + val_2 + carry ## add the two values digit = _sum % 10 ## accounting for carry (next line) carry = 1 if _sum >= 10 else 0 result = Node ( digit ) ## create a new \"Node\" with new digit next_1 = head_1 . next if head_1 else None next_2 = head_2 . next if head_2 else None result . next = add_lists ( next_1 , next_2 , carry ) ## recursive call return result Discussion ...","title":"23: Adding lists"},{"location":"algorithms/priority_queue/","text":"Priority Queue Definition Implements a set S of elements; each of the elements is associated with a key Operations: search() , insert() , delete() , change_priorities() , max_priority() , min_priority() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"Priority Queue"},{"location":"algorithms/priority_queue/#priority-queue","text":"Definition Implements a set S of elements; each of the elements is associated with a key Operations: search() , insert() , delete() , change_priorities() , max_priority() , min_priority() Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 01/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Priority Queue"},{"location":"algorithms/priority_queue/#references","text":"","title":"References"},{"location":"algorithms/sorting/","text":"Sorting Algorithms Insertion Sort Vanilla Insertion Sort Vanilla Insertion Sort 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"pairwise swaps\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(n)\\) comparisons. SO this version of the algorithm is \\(\\theta(n^2)\\) runtime complexity. Binary Insertion Sort Binary Insertion Sort This improved version is slightly improved by using Binary Search while searching for the position to place the key A[i] in the sorted part of the array (i.e. A[0:i-1] ) 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"Binary Search\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(\\log(n))\\) comparisons due to Binary Search. SO this version of the algorithm is \\(\\theta(n\\times \\log(n))\\) runtime complexity (in sorting but not in swappings ). If we consider swapping operations too then even Binary Search will take \\(\\theta(n)\\) time to swap positions as it might have to move a lot of positions. References https://twitter.com/pottolama/status/1354745837524553728 \u21a9 https://github.com/mportesi/sorting_algo_visualizer \u21a9","title":"Sorting"},{"location":"algorithms/sorting/#sorting-algorithms","text":"","title":"Sorting Algorithms"},{"location":"algorithms/sorting/#insertion-sort","text":"","title":"Insertion Sort"},{"location":"algorithms/sorting/#vanilla-insertion-sort","text":"Vanilla Insertion Sort 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"pairwise swaps\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(n)\\) comparisons. SO this version of the algorithm is \\(\\theta(n^2)\\) runtime complexity.","title":"Vanilla Insertion Sort"},{"location":"algorithms/sorting/#binary-insertion-sort","text":"Binary Insertion Sort This improved version is slightly improved by using Binary Search while searching for the position to place the key A[i] in the sorted part of the array (i.e. A[0:i-1] ) 1 2 3 4 for i = 1, 2, 3, ..., n{ insert A[i] into sorted array A[0:i-1] by \"Binary Search\" down to the correct position } This above version has \\(\\theta(n)\\) steps and each step has \\(\\theta(\\log(n))\\) comparisons due to Binary Search. SO this version of the algorithm is \\(\\theta(n\\times \\log(n))\\) runtime complexity (in sorting but not in swappings ). If we consider swapping operations too then even Binary Search will take \\(\\theta(n)\\) time to swap positions as it might have to move a lot of positions.","title":"Binary Insertion Sort"},{"location":"algorithms/sorting/#references","text":"https://twitter.com/pottolama/status/1354745837524553728 \u21a9 https://github.com/mportesi/sorting_algo_visualizer \u21a9","title":"References"},{"location":"blogs/about/","text":"The Preface of the key technological stuffs here Tips & Tricks LR Scheduler Similar to the learning rate , the lr-scheduler to apply depends on the classifier & the model. For image classifiers and SGD optimizer , the Multi-Step LR Scheduler is shown to be a good choice. Models trained with Adam commonly use a smooth exponential-decay in the lr or a cosine-like scheduler. For TRANSFORMERS: Remember to use a learning rate WARMUP The cosine-scheduler is often used for decaying the lr afterwards (but can also be replaced by exponential decay ) Regularizaation Regularization is important in networks when we see a significantly higher training performance than test performance. The regularization parameters all interact with each other and hence must be tuned together . The most commonly used regularization techniques are: Weight Decaay Dropout Augmentation Dropout is a good regularization technique as it has shown to be applicable on most architectures and has shown to reduce overfitting . If you want to use weight-decay in Adam , use torch.optim.AdamW instead of torch.optim.Adam . Domain specific regularization: There are a couple of regularization techniques that depend on the input-data / domain as shown below. Computer Vision: Image augmenatation like horizontal_flip , rotation , scale_and_crop , color_distortion , gaussian_noise etc. NLP: input dropout of whole words Graphs: Dropping edges Dropping nodes Dropping part of the features of all nodes Debugging in PyTorch Under-performing model Situation/Problem Your model is not reaching the performance it should, but PyTorch is not telling you why that happens!! These are very annoying bugs. Softmax, CrossEntropy & NLLLoss The most common mistake is the mismatch between the loss function and the output activations. A very usual common source of confusion is the relationship between nn.Softmax , nn.LogSoftmax , nn.NLLLoss , & nn.CrossEntropyLoss nn.CrossEntropyLoss does two operations on its inputs: nn.LogSoftmax & nn.NLLLoss . Hence, the input to the nn.CrossEntropyLoss should be the output of the last layer of the network. Don't apply nn.Softmax before the nn.CrossEntropyLoss . Otherwise, PyTorch will apply the Softmax TWICE which will signifacntly worsen the performance. If you use nn.NLLLoss , you need to apply log-softmax before yourselves. nn.NLLLoss requires log-probabilities as its input not just plain probabilities . So, make sure to use F.log_softmax() instead of nn.Softmax Softmax over correct dimension/axis Be careful to apply softmax over correct dimensio/axis in your output. For eg. you apply softamx over last dimension like this: nn.Softmax(dim=-1) Categorical Data & Embeddings Hidden size mismatch If you perform matrix multiplications and have a shape mismatch between two matrices, PyTorch will contain and throw error. However, there are situations where PyTorch does not throw any error because the misaligned dimensions have (unluckily) the same dimension. For example, imagine you have a weight matrix W of shape [d_in, d_out] . If you take an inout x of shape [batch_size, d_in] . And you want to do the matrix multiplication as out = W.matmul(x) then the shape of the output out will be correct as [batch_size, d_out] . But, suppose if by chance batch_size == d_in then both W.matmul(x) and x.matmul(W) will produce the same sized output [d_in, d_out] . This is definitely not the behaviour we want as it hides the error in the order of matrix maultiplication over different dimension. So, always test your code with multiple different batch sizes to prevent shape misalignments with the batch dimension . Use nn.Sequential & nn.ModuleList If you have a model with lots of layers, you might waant to summarize them into nn.Sequential or nn.ModuleList object. In the forward pass, you only need to call the Sequential or iterate through the ModuleList . A multi-layer-perceptron (MLP) can be implemented as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import torch import torch.nn as nn class MLP ( nn . Module ): def __init__ ( self , input_dims = 64 , hidden_dims = [ 128 , 256 ], output_dims = 10 , ): super () . __init__ () hidden_dims = [ input_dims ] + hidden_dims layers = [] for i in range ( len ( hidden_dims ) - 1 ): layers += [ nn . Linear ( hidden_dims [ i ], hidden_dims [ i + 1 ], nn . ReLU ( inplace = True ) ] self . layers = nn . Sequential ( * layers ) def forward ( self , x ): return self . layers ( x ) In-place Activation functions Some activation functions such as nn.ReLU and nn.LeakyReLU have an argument inplace . By default, it is set to False , but it is highly recommended to set it to True in neural networks. Setting it to True , makes the original value of the input overridden by the new output during the forward pass. This option of inplace is ONLY available to activations functions where we don't need to know the original input for backpropagation. For example, in nn.ReLU , the value sthat are set to zero have a gradient of ZERO independent of the specific input values. In-place operations can save a lot of memory, especially if you have a very large feature map. References Learning rate finder: https://pytorch-lightning.readthedocs.io/en/latest/advanced/lr_finder.html#learning-rate-finder \u21a9 Auto Scaling batch sizes: https://pytorch-lightning.readthedocs.io/en/latest/advanced/training_tricks.html#auto-scaling-of-batch-size \u21a9 Compare hyperparam search performance in TensorBoard: https://towardsdatascience.com/a-complete-guide-to-using-tensorboard-with-pytorch-53cb2301e8c3 \u21a9 \\(3^{rd}\\) party libraries: https://medium.com/pytorch/accelerate-your-hyperparameter-optimization-with-pytorchs-ecosystem-tools-bc17001b9a49 \u21a9 Saving git hash metadata: https://github.com/Nithin-Holla/meme_challenge/blob/f4dc2079acb78ae30caaa31e112c4c210f93bf27/utils/save.py#L26 \u21a9 PyTorch Tutorials: https://effectivemachinelearning.com/ \u21a9 Attention & Transformers: https://e2eml.school/transformers.html \u21a9","title":"About"},{"location":"blogs/about/#the-preface-of-the-key-technological-stuffs-here","text":"","title":"The Preface of the key technological stuffs here"},{"location":"blogs/about/#tips-tricks","text":"","title":"Tips &amp; Tricks"},{"location":"blogs/about/#lr-scheduler","text":"Similar to the learning rate , the lr-scheduler to apply depends on the classifier & the model. For image classifiers and SGD optimizer , the Multi-Step LR Scheduler is shown to be a good choice. Models trained with Adam commonly use a smooth exponential-decay in the lr or a cosine-like scheduler. For TRANSFORMERS: Remember to use a learning rate WARMUP The cosine-scheduler is often used for decaying the lr afterwards (but can also be replaced by exponential decay )","title":"LR Scheduler"},{"location":"blogs/about/#regularizaation","text":"Regularization is important in networks when we see a significantly higher training performance than test performance. The regularization parameters all interact with each other and hence must be tuned together . The most commonly used regularization techniques are: Weight Decaay Dropout Augmentation Dropout is a good regularization technique as it has shown to be applicable on most architectures and has shown to reduce overfitting . If you want to use weight-decay in Adam , use torch.optim.AdamW instead of torch.optim.Adam . Domain specific regularization: There are a couple of regularization techniques that depend on the input-data / domain as shown below. Computer Vision: Image augmenatation like horizontal_flip , rotation , scale_and_crop , color_distortion , gaussian_noise etc. NLP: input dropout of whole words Graphs: Dropping edges Dropping nodes Dropping part of the features of all nodes","title":"Regularizaation"},{"location":"blogs/about/#debugging-in-pytorch","text":"","title":"Debugging in PyTorch"},{"location":"blogs/about/#under-performing-model","text":"Situation/Problem Your model is not reaching the performance it should, but PyTorch is not telling you why that happens!! These are very annoying bugs.","title":"Under-performing model"},{"location":"blogs/about/#softmax-crossentropy-nllloss","text":"The most common mistake is the mismatch between the loss function and the output activations. A very usual common source of confusion is the relationship between nn.Softmax , nn.LogSoftmax , nn.NLLLoss , & nn.CrossEntropyLoss nn.CrossEntropyLoss does two operations on its inputs: nn.LogSoftmax & nn.NLLLoss . Hence, the input to the nn.CrossEntropyLoss should be the output of the last layer of the network. Don't apply nn.Softmax before the nn.CrossEntropyLoss . Otherwise, PyTorch will apply the Softmax TWICE which will signifacntly worsen the performance. If you use nn.NLLLoss , you need to apply log-softmax before yourselves. nn.NLLLoss requires log-probabilities as its input not just plain probabilities . So, make sure to use F.log_softmax() instead of nn.Softmax","title":"Softmax, CrossEntropy &amp; NLLLoss"},{"location":"blogs/about/#softmax-over-correct-dimensionaxis","text":"Be careful to apply softmax over correct dimensio/axis in your output. For eg. you apply softamx over last dimension like this: nn.Softmax(dim=-1)","title":"Softmax over correct dimension/axis"},{"location":"blogs/about/#categorical-data-embeddings","text":"","title":"Categorical Data &amp; Embeddings"},{"location":"blogs/about/#hidden-size-mismatch","text":"If you perform matrix multiplications and have a shape mismatch between two matrices, PyTorch will contain and throw error. However, there are situations where PyTorch does not throw any error because the misaligned dimensions have (unluckily) the same dimension. For example, imagine you have a weight matrix W of shape [d_in, d_out] . If you take an inout x of shape [batch_size, d_in] . And you want to do the matrix multiplication as out = W.matmul(x) then the shape of the output out will be correct as [batch_size, d_out] . But, suppose if by chance batch_size == d_in then both W.matmul(x) and x.matmul(W) will produce the same sized output [d_in, d_out] . This is definitely not the behaviour we want as it hides the error in the order of matrix maultiplication over different dimension. So, always test your code with multiple different batch sizes to prevent shape misalignments with the batch dimension .","title":"Hidden size mismatch"},{"location":"blogs/about/#use-nnsequential-nnmodulelist","text":"If you have a model with lots of layers, you might waant to summarize them into nn.Sequential or nn.ModuleList object. In the forward pass, you only need to call the Sequential or iterate through the ModuleList . A multi-layer-perceptron (MLP) can be implemented as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import torch import torch.nn as nn class MLP ( nn . Module ): def __init__ ( self , input_dims = 64 , hidden_dims = [ 128 , 256 ], output_dims = 10 , ): super () . __init__ () hidden_dims = [ input_dims ] + hidden_dims layers = [] for i in range ( len ( hidden_dims ) - 1 ): layers += [ nn . Linear ( hidden_dims [ i ], hidden_dims [ i + 1 ], nn . ReLU ( inplace = True ) ] self . layers = nn . Sequential ( * layers ) def forward ( self , x ): return self . layers ( x )","title":"Use nn.Sequential &amp; nn.ModuleList"},{"location":"blogs/about/#in-place-activation-functions","text":"Some activation functions such as nn.ReLU and nn.LeakyReLU have an argument inplace . By default, it is set to False , but it is highly recommended to set it to True in neural networks. Setting it to True , makes the original value of the input overridden by the new output during the forward pass. This option of inplace is ONLY available to activations functions where we don't need to know the original input for backpropagation. For example, in nn.ReLU , the value sthat are set to zero have a gradient of ZERO independent of the specific input values. In-place operations can save a lot of memory, especially if you have a very large feature map.","title":"In-place Activation functions"},{"location":"blogs/about/#references","text":"Learning rate finder: https://pytorch-lightning.readthedocs.io/en/latest/advanced/lr_finder.html#learning-rate-finder \u21a9 Auto Scaling batch sizes: https://pytorch-lightning.readthedocs.io/en/latest/advanced/training_tricks.html#auto-scaling-of-batch-size \u21a9 Compare hyperparam search performance in TensorBoard: https://towardsdatascience.com/a-complete-guide-to-using-tensorboard-with-pytorch-53cb2301e8c3 \u21a9 \\(3^{rd}\\) party libraries: https://medium.com/pytorch/accelerate-your-hyperparameter-optimization-with-pytorchs-ecosystem-tools-bc17001b9a49 \u21a9 Saving git hash metadata: https://github.com/Nithin-Holla/meme_challenge/blob/f4dc2079acb78ae30caaa31e112c4c210f93bf27/utils/save.py#L26 \u21a9 PyTorch Tutorials: https://effectivemachinelearning.com/ \u21a9 Attention & Transformers: https://e2eml.school/transformers.html \u21a9","title":"References"},{"location":"blogs/deep_learning/blog_dataloaders/","text":"PyTorch Dataloaders","title":"PyTorch Dataloaders"},{"location":"blogs/deep_learning/blog_dataloaders/#pytorch-dataloaders","text":"","title":"PyTorch Dataloaders"},{"location":"blogs/deep_learning/blog_tf_v1/","text":"Tensorflow Tutorial In this session you will learn to do the following in TensorFlow v1.0 Initialize Variables Start your own session Train Algorithms Implement a Neural Network Exploring the Tensorflow Library Example-1: General Overview 1 2 3 4 5 6 7 8 9 10 11 12 13 import tensorflow as tf y_hat = tf . constant ( 36 , name = \"y_hat\" ) ## Defins a \"y_hat\" constant. Sets its value to 36 y = tf . constant ( 39 , name = \"y\" ) ## Defins a \"y\" constant. Sets its value to 39 loss = tf . Variable (( y - y_hat ) ** 2 , name = \"loss\" ) init = tf . global_variables_initializer () ## Used to initialize the variables with the ## respective values when \"sess.run(init)\" is called with tf . Session () as sess : ## Creates a session to execute our program sess . run ( init ) ## initializes the global variables sess . run ( loss ) ## executes the program stored in \"loss\" variable print ( loss ) ## prints the value stored in \"loss\" variable Writing and running programs in Tensorflow has the following steps: Create tensors (variables) that are not yet evaluated/executed. Write operations between those tensors. Initialize the tensors. Create a Session . Run the session . This will run the operations written in step-2. So, when we created a variable for loss , we simply defined the loss as a function of other quantities but did not evaluate its value. To evaluate it, we had to run tf.global_variables_initializer() to intialize the values and then inside sess.run(init) we calculated the updated value and prited it in the last line above. Example-2: tf.Session() Now, let's take a look at 1 2 3 4 a = tf . constant ( 2 ) b = tf . constant ( 10 ) c = tf . multiply ( a , b ) print ( c ) 1 Tensor(\"Mul:0\", shape=(), dtype=int32) As expected we will not see 20 . We got a tensor saying that the result of the tensor does not have the shape attribute and is of the type int32 . All we did was to put in the computation graph ; but we haven't run this computation yet! In order to actually multiply the two numbers we have to create a sessiona nd run it. 1 2 sess = tf . Session () print ( sess . run ( c )) 1 20 Awesome!! . To summarize, remember the following: Initialize your variables. Create a session. Run the operations inside the session. Example-3: tf.placeholder() Next, we will see how to use a placeholder. A placeholder is an object whose value we can specify ONLY later. To specify values for a placeholder, we can pass in values by using a \"feed dictionary\" ( feed_dict variable). 1 2 3 4 5 6 7 8 9 ## Below we create a placeholder for x. ## This allows us to pass in a number later when we run the SESSION sess = tf . Session () x = tf . placeholder ( tf . int64 , name = \"x\" ) ## the placeholder variable print ( sess . run ( 2 * x , feed_dict = { x : 9 })) sess . close () 1 18 Using one-hot encodings: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def one_hot_matrix ( labels , num_classes ): \"\"\" Creates a matrix where the i-th row corresponds to the ith class number. j-th column corresponds to the j-th example. So, if the label for j-th example is i; then only the ith value is 1 in j-th column Args: labels: the labels for each example num_classes: the number of classes in this task Returns: a one-hot matrix \"\"\" ## create a tf.constant & name it \"num_classes\" num_classes = tf . constant ( num_classes , name = \"num_classes\" ) ## Use tf.one_hot (be careful with \"axis\") one_hot_matrix = tf . one_hot ( indices = labels , depth = num_classes , axis = 0 ) ## Create a session sess = tf . Session () ## Execute the one_hot_matrix graph inside the session one_hot = sess . run ( one_hot_matrix ) ## Close the session sess . close () ## return the one_hot matrix return one_hot 1 2 3 4 5 6 import numpy as np labels = np . array ([ 1 , 2 , 0 , 1 , 2 , 2 , 3 ]) num_classes = 4 one_hot = one_hot_matrix ( labels , num_classes ) print ( one_hot ) 1 2 3 4 [[0,0,1,0,0,0,0], [1,0,0,1,0,0,0], [0,1,0,0,1,1,0], [0,0,0,0,0,0,1]] Initialize with zeros & ones We will use tf.ones() and tf.zeros() to initialize a tensor of shape shape , where all elements are either zeros or ones 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def ones ( shape , dtype = tf . int64 ): \"\"\"Creates a tensor of ones with shape=shape Args: shape: the shape of the resulting tensor dtype: the datatype of every element in the resulting tensor Returns: A tensor where all elements are 1 \"\"\" ## Create ones tensor using `tf.ones()` ones = tf . ones ( shape , dtype = dtype ) ## Create a session sess = tf . Session () ## Execute the op in the session to calculate its value ones = sess . run ( ones ) ## Close the session sess . close () ## Return the ones tensor return ones 1 2 ones_tensor = ones ([ 2 , 3 ]) print ( ones_tensor ) 1 2 [[1,1,1], [1,1,1]] Building a Neural Network Building the model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 from tf_utils import load_dataset , random_mini_batches , convert_to_one_hot , predict from tensorflow.python.framework import ops def model ( X_train , Y_train , X_test , Y_test , lr = 1e-3 , num_epochs = 1500 , bs = 32 , verbose = True ): \"\"\" Implements a 3-layer Tensorflow Neural Network: [Linear]->[Relu]->[Linear]->[Relu]->[Linear]-[Softmax] Args: X_train: the train dataset inputs Y_train: the train dataset labels X_test: the test dataset inputs Y_test: the test dataset labels lr: the learnign rate num_epochs: number of epochs bs: batch-size verbose: True if you want to print the process else False Returns: the trained model parameters. \"\"\" ops . reset_default_graph () ## to be able to rerun the model, w/o overwriting the tf.variables tf . set_random_seed ( 217 ) ## to keep consistent results seed = 3 ## to keep consistent results ( n_x , m ) = X_train . shape ## n_x = input size; m = number of training examples n_y = Y_train . shape [ 0 ] ## n_y = output size costs = [] ## to keep track of the costs ## Step-1: Create placeholders of shape = (n_x, n_y) X , Y = create_placeholders ( n_x , n_y ) ## Step-2: Initialize parameters parameters = initialize_parameters () ## Step-3: Forward propagation ## Build the forward propagation the tf graph Z3 = forward_proagation ( X , parameters ) ## Step-4: Cost function ## Add cost function to tf graph cost = compute_cost ( Z3 , Y ) ## Step-5: Backward propagation ## Define the tf optimizer. Use `AdamOptimizer` optimizer = tf . train . AdamOptimizer ( lr ) . minimize ( cost ) ## Step-6: Initialize all variables init = tf . global_variables_initializer () ## Step-7: Start the session to compute the tf graph with tf . Session () as sess : ## Step-7.1: Run the initializer `init` sess . run ( init ) ## Step-7.2: Do the training loop for epoch in range ( num_epchs ): epoch_cost = 0.0 ## Define the cost for each epoch num_batches = m // bs seed += 1 minibatches = random_mini_batches ( X_train , Y_train , bs , seed ) for ( Xb , Yb ) in minibatches : _ , minibatch_cost = sess . run ([ optimizer , cost ], feed_dict = { X : Xb , Y : Yb }) epoch_cost += minibatch_cost epoch_cost /= num_batches ## Step-8: Save the trained model parameters parameters = sess . run ( parameters ) print ( \"parameters have been trained\" ) ## Step-9: How to calculate the correct predictions & accuracy correct_preds = tf . equal ( tf . argmax ( Z3 ), tf . argmax ( Y )) accuracy = tf . reduce_mean ( tf . cast ( correct_preds , \"float\" )) ## Step-10: Calculate the train & test accuracies accuracy_train = accuracy . eval ({ X : X_train , Y : Y_train }) accuracy_test = accuracy . eval ({ X : X_test , Y : Y_test }) return parameters","title":"Tensorflow Tutorial"},{"location":"blogs/deep_learning/blog_tf_v1/#tensorflow-tutorial","text":"In this session you will learn to do the following in TensorFlow v1.0 Initialize Variables Start your own session Train Algorithms Implement a Neural Network","title":"Tensorflow Tutorial"},{"location":"blogs/deep_learning/blog_tf_v1/#exploring-the-tensorflow-library","text":"","title":"Exploring the Tensorflow Library"},{"location":"blogs/deep_learning/blog_tf_v1/#example-1-general-overview","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 import tensorflow as tf y_hat = tf . constant ( 36 , name = \"y_hat\" ) ## Defins a \"y_hat\" constant. Sets its value to 36 y = tf . constant ( 39 , name = \"y\" ) ## Defins a \"y\" constant. Sets its value to 39 loss = tf . Variable (( y - y_hat ) ** 2 , name = \"loss\" ) init = tf . global_variables_initializer () ## Used to initialize the variables with the ## respective values when \"sess.run(init)\" is called with tf . Session () as sess : ## Creates a session to execute our program sess . run ( init ) ## initializes the global variables sess . run ( loss ) ## executes the program stored in \"loss\" variable print ( loss ) ## prints the value stored in \"loss\" variable Writing and running programs in Tensorflow has the following steps: Create tensors (variables) that are not yet evaluated/executed. Write operations between those tensors. Initialize the tensors. Create a Session . Run the session . This will run the operations written in step-2. So, when we created a variable for loss , we simply defined the loss as a function of other quantities but did not evaluate its value. To evaluate it, we had to run tf.global_variables_initializer() to intialize the values and then inside sess.run(init) we calculated the updated value and prited it in the last line above.","title":"Example-1: General Overview"},{"location":"blogs/deep_learning/blog_tf_v1/#example-2-tfsession","text":"Now, let's take a look at 1 2 3 4 a = tf . constant ( 2 ) b = tf . constant ( 10 ) c = tf . multiply ( a , b ) print ( c ) 1 Tensor(\"Mul:0\", shape=(), dtype=int32) As expected we will not see 20 . We got a tensor saying that the result of the tensor does not have the shape attribute and is of the type int32 . All we did was to put in the computation graph ; but we haven't run this computation yet! In order to actually multiply the two numbers we have to create a sessiona nd run it. 1 2 sess = tf . Session () print ( sess . run ( c )) 1 20 Awesome!! . To summarize, remember the following: Initialize your variables. Create a session. Run the operations inside the session.","title":"Example-2: tf.Session()"},{"location":"blogs/deep_learning/blog_tf_v1/#example-3-tfplaceholder","text":"Next, we will see how to use a placeholder. A placeholder is an object whose value we can specify ONLY later. To specify values for a placeholder, we can pass in values by using a \"feed dictionary\" ( feed_dict variable). 1 2 3 4 5 6 7 8 9 ## Below we create a placeholder for x. ## This allows us to pass in a number later when we run the SESSION sess = tf . Session () x = tf . placeholder ( tf . int64 , name = \"x\" ) ## the placeholder variable print ( sess . run ( 2 * x , feed_dict = { x : 9 })) sess . close () 1 18","title":"Example-3: tf.placeholder()"},{"location":"blogs/deep_learning/blog_tf_v1/#using-one-hot-encodings","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def one_hot_matrix ( labels , num_classes ): \"\"\" Creates a matrix where the i-th row corresponds to the ith class number. j-th column corresponds to the j-th example. So, if the label for j-th example is i; then only the ith value is 1 in j-th column Args: labels: the labels for each example num_classes: the number of classes in this task Returns: a one-hot matrix \"\"\" ## create a tf.constant & name it \"num_classes\" num_classes = tf . constant ( num_classes , name = \"num_classes\" ) ## Use tf.one_hot (be careful with \"axis\") one_hot_matrix = tf . one_hot ( indices = labels , depth = num_classes , axis = 0 ) ## Create a session sess = tf . Session () ## Execute the one_hot_matrix graph inside the session one_hot = sess . run ( one_hot_matrix ) ## Close the session sess . close () ## return the one_hot matrix return one_hot 1 2 3 4 5 6 import numpy as np labels = np . array ([ 1 , 2 , 0 , 1 , 2 , 2 , 3 ]) num_classes = 4 one_hot = one_hot_matrix ( labels , num_classes ) print ( one_hot ) 1 2 3 4 [[0,0,1,0,0,0,0], [1,0,0,1,0,0,0], [0,1,0,0,1,1,0], [0,0,0,0,0,0,1]]","title":"Using one-hot encodings:"},{"location":"blogs/deep_learning/blog_tf_v1/#initialize-with-zeros-ones","text":"We will use tf.ones() and tf.zeros() to initialize a tensor of shape shape , where all elements are either zeros or ones 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def ones ( shape , dtype = tf . int64 ): \"\"\"Creates a tensor of ones with shape=shape Args: shape: the shape of the resulting tensor dtype: the datatype of every element in the resulting tensor Returns: A tensor where all elements are 1 \"\"\" ## Create ones tensor using `tf.ones()` ones = tf . ones ( shape , dtype = dtype ) ## Create a session sess = tf . Session () ## Execute the op in the session to calculate its value ones = sess . run ( ones ) ## Close the session sess . close () ## Return the ones tensor return ones 1 2 ones_tensor = ones ([ 2 , 3 ]) print ( ones_tensor ) 1 2 [[1,1,1], [1,1,1]]","title":"Initialize with zeros &amp; ones"},{"location":"blogs/deep_learning/blog_tf_v1/#building-a-neural-network","text":"","title":"Building a Neural Network"},{"location":"blogs/deep_learning/blog_tf_v1/#building-the-model","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 from tf_utils import load_dataset , random_mini_batches , convert_to_one_hot , predict from tensorflow.python.framework import ops def model ( X_train , Y_train , X_test , Y_test , lr = 1e-3 , num_epochs = 1500 , bs = 32 , verbose = True ): \"\"\" Implements a 3-layer Tensorflow Neural Network: [Linear]->[Relu]->[Linear]->[Relu]->[Linear]-[Softmax] Args: X_train: the train dataset inputs Y_train: the train dataset labels X_test: the test dataset inputs Y_test: the test dataset labels lr: the learnign rate num_epochs: number of epochs bs: batch-size verbose: True if you want to print the process else False Returns: the trained model parameters. \"\"\" ops . reset_default_graph () ## to be able to rerun the model, w/o overwriting the tf.variables tf . set_random_seed ( 217 ) ## to keep consistent results seed = 3 ## to keep consistent results ( n_x , m ) = X_train . shape ## n_x = input size; m = number of training examples n_y = Y_train . shape [ 0 ] ## n_y = output size costs = [] ## to keep track of the costs ## Step-1: Create placeholders of shape = (n_x, n_y) X , Y = create_placeholders ( n_x , n_y ) ## Step-2: Initialize parameters parameters = initialize_parameters () ## Step-3: Forward propagation ## Build the forward propagation the tf graph Z3 = forward_proagation ( X , parameters ) ## Step-4: Cost function ## Add cost function to tf graph cost = compute_cost ( Z3 , Y ) ## Step-5: Backward propagation ## Define the tf optimizer. Use `AdamOptimizer` optimizer = tf . train . AdamOptimizer ( lr ) . minimize ( cost ) ## Step-6: Initialize all variables init = tf . global_variables_initializer () ## Step-7: Start the session to compute the tf graph with tf . Session () as sess : ## Step-7.1: Run the initializer `init` sess . run ( init ) ## Step-7.2: Do the training loop for epoch in range ( num_epchs ): epoch_cost = 0.0 ## Define the cost for each epoch num_batches = m // bs seed += 1 minibatches = random_mini_batches ( X_train , Y_train , bs , seed ) for ( Xb , Yb ) in minibatches : _ , minibatch_cost = sess . run ([ optimizer , cost ], feed_dict = { X : Xb , Y : Yb }) epoch_cost += minibatch_cost epoch_cost /= num_batches ## Step-8: Save the trained model parameters parameters = sess . run ( parameters ) print ( \"parameters have been trained\" ) ## Step-9: How to calculate the correct predictions & accuracy correct_preds = tf . equal ( tf . argmax ( Z3 ), tf . argmax ( Y )) accuracy = tf . reduce_mean ( tf . cast ( correct_preds , \"float\" )) ## Step-10: Calculate the train & test accuracies accuracy_train = accuracy . eval ({ X : X_train , Y : Y_train }) accuracy_test = accuracy . eval ({ X : X_test , Y : Y_test }) return parameters","title":"Building the model"},{"location":"blogs/deep_learning/einops/","text":"Part-1 Welcome to einops We don't write 1 y = x . transpose ( 0 , 2 , 3 , 1 ) We write comprehensible code 1 y = einops . rearrange ( x , \"b c h w -> b h w c\" ) einops supports widely used tensor packages viz. numpy , pytorch , tensorflow , chainer , gluon and extends them. What's in this tutorial? Fundamentals : reordering, composition, and decomposition of tensors. Operations : rearrange , reduce , repeat How much can you do with a single operation? Preparations 1 2 3 import numpy from utils import display_np_arrays_as_images display_np_arrays_as_images () Load a batch of images 1 2 3 4 5 ## there are 6 images of shape 96x96 ## with 3 color channels packed as tensors images = np . load ( \"./resources/tes_images.npy\" , allow_pickle = False ) print ( images . shape , images . dtype ) ## (6, 96, 96, 3), float64 1 2 ## display the 1st image (whole 4d tensor can't be rendered) images [ 0 ] 1 images [ 1 ] We will use three opeartions: rearrange , reduce , repeat 1 from einops import rearrange , reduce , repeat Meet \"rearrange\" rearrange As its name suggests; it rearranges elements. Below, we swap height and width . In other words, below we transpose first two axes/dimensions. 1 rearrange ( images [ 0 ], \"h w c -> w h c\" ) Composition of axes Transposition is very common and useful; but let's move to other operations provided by einops composition using rearrange() : height einops allows seamlessly composing batch and height to a new height dimension. Below we just rendered all images in the 4D tensor by collapsing it to a 3D tensor. 1 rearrange ( images , \"b h w c -> (b h) w c\" ) composition using rearrange() : width einops allows seamlessly composing batch and width to a new width dimension. Below we just rendered all images in the 4D tensor by collapsing it to a 3D tensor. 1 rearrange ( images , \"b h w c -> h (b w) c\" ) Resulting dimensions are computed very simply. Length of any newly computed axes/dimension is a product of its components 1 2 3 ## [6, 96, 96, 3] -> [96, (6*96), 3] a = rearrange ( images , \"b h w c -> h (b w) c\" ) a . shape 1 (96, 576, 3) We can compose more than 2 axes/dimensions. Let's flatten the whole 4D array into a 1D array. The resulting 1D array contains as many elements as the original 4D array. 1 2 3 ## [6, 96, 96, 3] -> [(6*96*96*3)] a = rearrange ( images , \"b h w c -> (b h w c)\" ) a . shape 1 (165888, ) Decomposition of axes Decomposition is the inverse process of composition. It represents an existing axis as a combination of new axes . Several decompositions are possible. Some examples are shown below: Combining composition and decomposition Combining composition & decomposition 1 2 3 4 ## here b1=2, decomposes b=6 into \"b1=2\" and \"b2=3\" ## keeping b = b1*b2 a = rearrange ( images , \"(b1 b2) w h c -> b1 b2 w h c\" , b1 = 2 ) a . shape ## (2, 3, 96, 96, 3) 1 (2, 3, 96, 96, 3) An example Combining composition & decomposition 1 2 3 4 5 6 ## here b1=2, decomposes b=6 into \"b1=2\" and \"b2=3\" ## keeping b = b1*b2 a = rearrange ( images , \"(b1 b2) w h c -> (b1 h) (b2 w) c\" , b1 = 2 ) a . shape ## (2*96, 3*96, 3) a Another combination Combining composition & decomposition 1 2 3 4 5 6 ## here b1=2, decomposes b=6 into \"b1=2\" and \"b2=3\" ## keeping b = b1*b2 a = rearrange ( images , \"(b1 b2) w h c -> (b2 h) (b1 w) c\" , b1 = 2 ) a . shape ## (3*96, 2*96, 3) a Another example: width_to_height Move part of the width dimension to height We should call this width_to_height as the image width shrunk by 2 and height incresed by 2. But all pixels are same!!! 1 2 3 4 a = rearrange ( images , \"b h (w w2) c -> (h w2) (b w) c\" , w2 = 2 ) a . shape ## (96*2, 6*48, 3) a Another example: heigh_to_width Move part of the height dimension to width We should call this height_to_width as the image height shrunk by 2 and width incresed by 2. But all pixels are same!!! 1 2 3 a = rearrange ( images , \"b (h h2) w c -> (b h) (w h2) c\" , h2 = 2 ) a . shape ## (6*48, 96*2, 3) Order of axes matter The order of axes in composition and decomposition is of prime importance. It affects the way data is being transposed. Below examples show the impacts. An example 1 2 3 a = rearrange ( images , \"b h w c -> h (b w) c\" ) ## notice the ordering of (b w) a . shape ## (96, 6*96, 3) a v/s 1 2 3 b = rearrange ( images , \"b h w c -> h (w b) c\" ) ## notice the ordeing of (w b) b . shape ## (96, 96*6, 3) b Though the shapes of both a and b are same but the ordering of pixels are different. RULE : The rule of importance is just as for digits. The leftmost digit is most significant . Neighboring number differ in rightmost axis. What will happen if b1 and b2 are reordered before composing to width (as shown in examples below): 1 2 rearrange ( images , \"(b1 b2) h w c -> h (b1 b2 w) c\" , b1 = 2 ) ## produces \"einops\" rearrange ( images , \"(b1 b2) h w c -> h (b2 b1 w) c\" , b1 = 2 ) ## prodices \"eoipns\" Meet \"reduce\" In einops we don't need to guess what happened (like below) 1 x . mean ( - 1 ) Because we write clearly what happened (as shown below) 1 2 3 import einops.reduce reduce ( x , \"b h w c -> b h w\" , \"mean\" ) If an axis was not present in the output definition --you guessed it -- it was reduced Average over batch Average over batch 1 2 3 u = reduce ( images , \"b h w c -> h w c\" , \"mean\" ) ## reduce using \"mean\" across the \"batch\" axis u . shape ## (96, 96, 3) u The above code is similar to the standard code (without einops ) as shown below 1 2 3 u = images . mean ( axis = 0 ) ## find mean across the \"batch\" dimension u . shape ## (96, 96, 3) u But, the code with einops is much more readable and states the operations clearly. Reducing over multiple axes Example of reducing over several dimensions. Besides \"mean\" , there are also \"min\" , \"max\" , \"sum\" , \"prod\" 1 2 3 u = reduce ( images , \"b h w c -> h w\" , \"min\" ) ## redce across \"batch\" & \"channel\" axes u . shape ## (96, 96) u Mean-pooling Mean pooling with 2x2 kernel Image is split into 2x2 patch and each path is avergaed 1 2 3 u = reduce ( images , \"b (h h2) (w w2) c -> h (b w) c\" , \"mean\" , h2 = 2 , w2 = 2 ) u . shape ## (48, 6*48, 3) u Max-pooling max-pooling with 2x2 kernel Image is split into 2x2 patch and each patch is max-pooled 1 2 3 u = reduce ( images , \"b (h h2) (w w2) c -> h (b w) c\" , \"max\" , h2 = 2 , w2 = 2 ) u . shape ## (49, 6*48, 3) u yet another example 1 2 3 u = reshape ( images , \"(b1 b2) h w c -> (b2 h) (b1 w)\" , \"mean\" , b1 = 2 ) u . shape ## (3*96, 2*96) u Stack & Concatenate 1 2 3 4 5 6 7 ## rearrange can also take care of lists of arrays with the same shapes x = list ( images ) ## Case-0: We can use the \"list-axis\" as 1st axis (\"b\") and rest of the axes stays as usual x0 = rearrange ( x , \"b h w c -> b h w c\" ) x0 . shape ## (6, 96, 96, 3) 1 2 3 4 5 6 7 8 ##----------------------------------------------------------------------------## ## case-1: But the new axis can appear in any place x1 = rearrange ( x , \"b h w c -> h w c b\" ) x1 . shape ## (96, 96, 3, 6) ## This is equivalent to using `numpy.stack` x11 = numpy . stack ( x , axis = 3 ) x11 . shape ## (96, 96, 3, 6) 1 2 3 4 5 6 7 8 ##----------------------------------------------------------------------------## ## Case-2: ....Or we can also concatenate along axes x2 = rearrange ( x , \"b h w c -> h (b w) c\" ) x2 . shape ## (96, 6*96, 3) ## This is equivalent to using `numpy.concatenate` x22 = numpy . concatenate ( x , axis = 1 ) x22 . shape ## (96. 6*96, 3) Addition and removal of axes You can write 1 to create new axis of length 1. There is also a synonym () that does exactly the same It is exactly what numpy.exapand_axis() and torch.unsqueeze() does. 1 2 3 4 5 6 ## both operations does the same as \"numpy.expand_dims()\" or \"torch.unsqueeze()\" u = rearrange ( images , \"b h w c -> b 1 h w 1 c\" ) v = rearrange ( images , \"b h w c -> b () h w () c\" ) u . shape ## (6, 1, 96, 96, 1, 3) v . shape ## (6, 1, 96, 96, 1, 3) The numpy.squeeze() operation is also facilitated by rearrange() as usual. 1 2 3 4 u = rearrange ( images , \"b h w c -> b 1 h w 1 c\" ) ## torch.unsqueeze() v = rearrange ( u , \"b 1 h w 1 c -> b h w c\" ) ## torch.unsqueeze() v . shape ## (6, 96, 96, 3) An example usage Compute max in each image individually and then show a difference 1 2 3 4 x = reduce ( images , \"b h w c -> b () () c\" , max ) x -= images y = rearrange ( x , \"b h w c -> h (b w) c\" ) y . shape ## (96, 6*96, 3) Meet \"repeat\": Repeating elements This is the third operation in einops library Repeat along a new axis . The new axis can be placed anywhere. 1 2 3 4 5 6 7 u = repeat ( images [ 0 ], \"h w c -> h new_axis w c\" , new_axis = 5 ) u . shape ## (96, 5, 96, 3) ## -- OR -- a shortcut v = repeat ( images [ 0 ], \"h w c -> h 5 w c\" ) ## repeats 5 times in the new axis. v . shape ## (96, 5, 96, 3) Repat along an existing axis 1 2 3 ## repeats the width 3 times u = repeat ( images [ 0 ], \"h w c -> h (repeat w) c\" , repeat = 3 ) u . shape ## (96, 3*96, 3) Repeat along multiple existing axes 1 2 u = repeat ( images [ 0 ], \"h w c -> (2 h) (2 w) c\" ) u . shape ## (2*96, 2*96, 3) Order of axes matter as usual. You can repeat each pixel 3 times by changing the order of axes in repeat 1 2 3 ## repeat the pixels along the width dim. 3 times u = repeat ( images [ 0 ], \"h w c -> h (w repeat) c\" , repeat = 3 ) u . shape ## (96, 96*3, 3) NOTE: The repeat operation covers numpy.tile , numpy.repeat and much more. reduce v/s repeat reduce and repeat are opposite of each other. reduce : reduces amount of elements repeat : increases the number of elements. An example of reduce v/s repeat In this example each image is repeated first then reduced over the new_axis to get back the original tensor. 1 2 3 4 5 6 7 repeated = repeat ( images , \"b h w c -> b h new_axis w c\" , new_axis = 2 ) reduced = reduce ( repeated , \"b h new_axis w c -> b h w c\" , \"min\" ) repeated . shape ## (6, 96, 2, 96, 3) reduced . shape ## (6, 96, 96, 3) assert numpy . array_equal ( images , reduced ) ## True Notice that the operation pattern in reduce and repeat are reverse of each other. i.e. in repeat its \"b h w c -> b h new_axis w c\" but in reduce its \"b h new_axis w c -> b h w c\" Some more examples Interwaving pixels of different pictures All letters can be observed in the final image 1 2 u = rearrange ( images , \"(b1 b2) h w c -> (h b1) (w b2) c\" , b1 = 2 ) u . shape ## (2*96, 3*96, 3) Interweaving along vertical for couple of images 1 2 u = rearrange ( images , \"(b1 b2) h w c -> (h b1) (b2 w) c\" , b1 = 2 ) u . shape ## (96*2, 3*96, 3) Interweaving lines for couple of images 1 2 u = reduce ( images , \"(b1 b2) h w c -> h (b2 w) c\" , \"max\" , b1 = 2 ) u . shape ## (96, 3*96, 3) Decomposing color into different axes Here we decompose color dimension into different axes. We also downsample the image. 1 2 u = reduce ( images , \"b (h 2) (w 2) c -> (c h) (b w)\" , \"mean\" ) u . shape ## (3*48, 6*48) Disproportionate resize 1 2 u = reduce ( images , \"b (h 3) (w 4) c -> (h) (b w)\" , \"mean\" ) u . shape ## (96/3, 6*96/4) Split & Reduce Split each image into two halves and compute the mean of the two halves. 1 2 u = reduce ( images , \"b (h1 h2) w c -> h2 (b w)\" , \"mean\" , h1 = 2 ) u . shape ## (96/2, 6*96) Split and Transpose Split into small patches and transpose each patch. 1 2 3 4 ## splitting each image into 96/8 * 96/8 = 12*12 = 144 patches ## each patch is of shape (8, 8) u = rearrange ( images , \"b (h1 h2) (w1 w2) c -> (h1 w2) (b w1 h2) c\" , h2 = 8 , w2 = 8 ) u . shape ## (12*8, 6*12*8, 3) Another Split & Transpose This is crazy 1 2 3 4 u = rearrange ( images , \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\" , h2 = 2 , h3 = 2 , w2 = 2 , w3 = 2 ) u . shape ## (96/(2*2)*2*2, 6*96/(2*2)*2*2, c) = (96, 6*96, 3) Yet another Split & Transpose This is crazy crazy.... 1 2 3 4 u = rearrange ( images , \"(b1 b2) (h1 h2) (w1 w2) c -> (h1 b1 h2) (w1 b2 w2) c\" , h1 = 3 , w1 = 3 , b2 = 3 ) u . shape ## (3*(6/3)*(96/3), 3*3*(96/3), 3) = (192, 288, 3) Arbitrarily Complicated Pattern 1 2 3 4 u = reduce ( images , \"(b1 b2) (h1 h2 h3) (w1 w2 w3) c -> (h1 w1 h3) (b1 w2 h2 w3 b2) c\" , \"mean\" , w1 = 2 , w3 = 2 , h2 = 2 , h3 = 2 , b2 = 2 ) Subtract background & Normalize Subtract background in each image individually and normalize. NOTE: Pay attention to () -- this is a composition of 0 axis (a dummy axis with 1 element) 1 2 3 4 5 6 u = reduce ( images , \"b h w c -> b () () c\" , \"max\" ) ## finding per-image per-channel max u -= images ## subtracting u /= reduce ( u , \"b h w c -> b () () c\" , \"max\" ) ## NORMALIZATION u = rearrange ( u , \"b h w c -> h (b w) c\" ) u . shape ## (96, 6*96, 3) PIXELATE First downscale by averaging then upscale by using the same pattern. 1 2 3 4 5 6 7 8 ## downscale using \"mean\" kernel of size (6, 8) downscaled = reduce ( images , \"b (h h2) (w w2) c -> b h w c\" , \"mean\" , h2 = 6 , w2 = 8 ) upscaled = repeat ( downscaled , \"b h w c -> b (h h2) (w w2) c\" , h2 = 6 , w2 = 8 ) v = rearrange ( upscaled , \"b h w c -> h (b w) c\" ) downscaled . shape ## (6, 96/6, 96/8, 3) upscaled . shape ## (6, (96/6)*6, (96/8)*8, 3) = (6, 96, 96, 3) v . shape ## (96, 6*96, 3) ROTATE 1 2 u = rearrange ( images , \"b h w c -> w (b h) c\" ) ## rotation of (width <-> height) u . shape ## (96, 6*96, 3) Another Example Let's bring the channel dimension as part of the width axis. Also, at the same time downsample the width axis by 2x 1 2 3 4 u = reduce ( images , \"b (h h2) (w w2) c -> (h w2) (b w c)\" , \"mean\" , h2 = 3 , w2 = 3 )","title":"einops tutorial"},{"location":"blogs/deep_learning/einops/#part-1","text":"","title":"Part-1"},{"location":"blogs/deep_learning/einops/#welcome-to-einops","text":"We don't write 1 y = x . transpose ( 0 , 2 , 3 , 1 ) We write comprehensible code 1 y = einops . rearrange ( x , \"b c h w -> b h w c\" ) einops supports widely used tensor packages viz. numpy , pytorch , tensorflow , chainer , gluon and extends them.","title":"Welcome to einops"},{"location":"blogs/deep_learning/einops/#whats-in-this-tutorial","text":"Fundamentals : reordering, composition, and decomposition of tensors. Operations : rearrange , reduce , repeat How much can you do with a single operation?","title":"What's in this tutorial?"},{"location":"blogs/deep_learning/einops/#preparations","text":"1 2 3 import numpy from utils import display_np_arrays_as_images display_np_arrays_as_images ()","title":"Preparations"},{"location":"blogs/deep_learning/einops/#load-a-batch-of-images","text":"1 2 3 4 5 ## there are 6 images of shape 96x96 ## with 3 color channels packed as tensors images = np . load ( \"./resources/tes_images.npy\" , allow_pickle = False ) print ( images . shape , images . dtype ) ## (6, 96, 96, 3), float64 1 2 ## display the 1st image (whole 4d tensor can't be rendered) images [ 0 ] 1 images [ 1 ] We will use three opeartions: rearrange , reduce , repeat 1 from einops import rearrange , reduce , repeat","title":"Load a batch of images"},{"location":"blogs/deep_learning/einops/#meet-rearrange","text":"rearrange As its name suggests; it rearranges elements. Below, we swap height and width . In other words, below we transpose first two axes/dimensions. 1 rearrange ( images [ 0 ], \"h w c -> w h c\" )","title":"Meet \"rearrange\""},{"location":"blogs/deep_learning/einops/#composition-of-axes","text":"Transposition is very common and useful; but let's move to other operations provided by einops composition using rearrange() : height einops allows seamlessly composing batch and height to a new height dimension. Below we just rendered all images in the 4D tensor by collapsing it to a 3D tensor. 1 rearrange ( images , \"b h w c -> (b h) w c\" ) composition using rearrange() : width einops allows seamlessly composing batch and width to a new width dimension. Below we just rendered all images in the 4D tensor by collapsing it to a 3D tensor. 1 rearrange ( images , \"b h w c -> h (b w) c\" ) Resulting dimensions are computed very simply. Length of any newly computed axes/dimension is a product of its components 1 2 3 ## [6, 96, 96, 3] -> [96, (6*96), 3] a = rearrange ( images , \"b h w c -> h (b w) c\" ) a . shape 1 (96, 576, 3) We can compose more than 2 axes/dimensions. Let's flatten the whole 4D array into a 1D array. The resulting 1D array contains as many elements as the original 4D array. 1 2 3 ## [6, 96, 96, 3] -> [(6*96*96*3)] a = rearrange ( images , \"b h w c -> (b h w c)\" ) a . shape 1 (165888, )","title":"Composition of axes"},{"location":"blogs/deep_learning/einops/#decomposition-of-axes","text":"Decomposition is the inverse process of composition. It represents an existing axis as a combination of new axes . Several decompositions are possible. Some examples are shown below: Combining composition and decomposition Combining composition & decomposition 1 2 3 4 ## here b1=2, decomposes b=6 into \"b1=2\" and \"b2=3\" ## keeping b = b1*b2 a = rearrange ( images , \"(b1 b2) w h c -> b1 b2 w h c\" , b1 = 2 ) a . shape ## (2, 3, 96, 96, 3) 1 (2, 3, 96, 96, 3) An example Combining composition & decomposition 1 2 3 4 5 6 ## here b1=2, decomposes b=6 into \"b1=2\" and \"b2=3\" ## keeping b = b1*b2 a = rearrange ( images , \"(b1 b2) w h c -> (b1 h) (b2 w) c\" , b1 = 2 ) a . shape ## (2*96, 3*96, 3) a Another combination Combining composition & decomposition 1 2 3 4 5 6 ## here b1=2, decomposes b=6 into \"b1=2\" and \"b2=3\" ## keeping b = b1*b2 a = rearrange ( images , \"(b1 b2) w h c -> (b2 h) (b1 w) c\" , b1 = 2 ) a . shape ## (3*96, 2*96, 3) a Another example: width_to_height Move part of the width dimension to height We should call this width_to_height as the image width shrunk by 2 and height incresed by 2. But all pixels are same!!! 1 2 3 4 a = rearrange ( images , \"b h (w w2) c -> (h w2) (b w) c\" , w2 = 2 ) a . shape ## (96*2, 6*48, 3) a Another example: heigh_to_width Move part of the height dimension to width We should call this height_to_width as the image height shrunk by 2 and width incresed by 2. But all pixels are same!!! 1 2 3 a = rearrange ( images , \"b (h h2) w c -> (b h) (w h2) c\" , h2 = 2 ) a . shape ## (6*48, 96*2, 3)","title":"Decomposition of axes"},{"location":"blogs/deep_learning/einops/#order-of-axes-matter","text":"The order of axes in composition and decomposition is of prime importance. It affects the way data is being transposed. Below examples show the impacts. An example 1 2 3 a = rearrange ( images , \"b h w c -> h (b w) c\" ) ## notice the ordering of (b w) a . shape ## (96, 6*96, 3) a v/s 1 2 3 b = rearrange ( images , \"b h w c -> h (w b) c\" ) ## notice the ordeing of (w b) b . shape ## (96, 96*6, 3) b Though the shapes of both a and b are same but the ordering of pixels are different. RULE : The rule of importance is just as for digits. The leftmost digit is most significant . Neighboring number differ in rightmost axis. What will happen if b1 and b2 are reordered before composing to width (as shown in examples below): 1 2 rearrange ( images , \"(b1 b2) h w c -> h (b1 b2 w) c\" , b1 = 2 ) ## produces \"einops\" rearrange ( images , \"(b1 b2) h w c -> h (b2 b1 w) c\" , b1 = 2 ) ## prodices \"eoipns\"","title":"Order of axes matter"},{"location":"blogs/deep_learning/einops/#meet-reduce","text":"In einops we don't need to guess what happened (like below) 1 x . mean ( - 1 ) Because we write clearly what happened (as shown below) 1 2 3 import einops.reduce reduce ( x , \"b h w c -> b h w\" , \"mean\" ) If an axis was not present in the output definition --you guessed it -- it was reduced Average over batch Average over batch 1 2 3 u = reduce ( images , \"b h w c -> h w c\" , \"mean\" ) ## reduce using \"mean\" across the \"batch\" axis u . shape ## (96, 96, 3) u The above code is similar to the standard code (without einops ) as shown below 1 2 3 u = images . mean ( axis = 0 ) ## find mean across the \"batch\" dimension u . shape ## (96, 96, 3) u But, the code with einops is much more readable and states the operations clearly. Reducing over multiple axes Example of reducing over several dimensions. Besides \"mean\" , there are also \"min\" , \"max\" , \"sum\" , \"prod\" 1 2 3 u = reduce ( images , \"b h w c -> h w\" , \"min\" ) ## redce across \"batch\" & \"channel\" axes u . shape ## (96, 96) u","title":"Meet \"reduce\""},{"location":"blogs/deep_learning/einops/#mean-pooling","text":"Mean pooling with 2x2 kernel Image is split into 2x2 patch and each path is avergaed 1 2 3 u = reduce ( images , \"b (h h2) (w w2) c -> h (b w) c\" , \"mean\" , h2 = 2 , w2 = 2 ) u . shape ## (48, 6*48, 3) u","title":"Mean-pooling"},{"location":"blogs/deep_learning/einops/#max-pooling","text":"max-pooling with 2x2 kernel Image is split into 2x2 patch and each patch is max-pooled 1 2 3 u = reduce ( images , \"b (h h2) (w w2) c -> h (b w) c\" , \"max\" , h2 = 2 , w2 = 2 ) u . shape ## (49, 6*48, 3) u yet another example 1 2 3 u = reshape ( images , \"(b1 b2) h w c -> (b2 h) (b1 w)\" , \"mean\" , b1 = 2 ) u . shape ## (3*96, 2*96) u","title":"Max-pooling"},{"location":"blogs/deep_learning/einops/#stack-concatenate","text":"1 2 3 4 5 6 7 ## rearrange can also take care of lists of arrays with the same shapes x = list ( images ) ## Case-0: We can use the \"list-axis\" as 1st axis (\"b\") and rest of the axes stays as usual x0 = rearrange ( x , \"b h w c -> b h w c\" ) x0 . shape ## (6, 96, 96, 3) 1 2 3 4 5 6 7 8 ##----------------------------------------------------------------------------## ## case-1: But the new axis can appear in any place x1 = rearrange ( x , \"b h w c -> h w c b\" ) x1 . shape ## (96, 96, 3, 6) ## This is equivalent to using `numpy.stack` x11 = numpy . stack ( x , axis = 3 ) x11 . shape ## (96, 96, 3, 6) 1 2 3 4 5 6 7 8 ##----------------------------------------------------------------------------## ## Case-2: ....Or we can also concatenate along axes x2 = rearrange ( x , \"b h w c -> h (b w) c\" ) x2 . shape ## (96, 6*96, 3) ## This is equivalent to using `numpy.concatenate` x22 = numpy . concatenate ( x , axis = 1 ) x22 . shape ## (96. 6*96, 3)","title":"Stack &amp; Concatenate"},{"location":"blogs/deep_learning/einops/#addition-and-removal-of-axes","text":"You can write 1 to create new axis of length 1. There is also a synonym () that does exactly the same It is exactly what numpy.exapand_axis() and torch.unsqueeze() does. 1 2 3 4 5 6 ## both operations does the same as \"numpy.expand_dims()\" or \"torch.unsqueeze()\" u = rearrange ( images , \"b h w c -> b 1 h w 1 c\" ) v = rearrange ( images , \"b h w c -> b () h w () c\" ) u . shape ## (6, 1, 96, 96, 1, 3) v . shape ## (6, 1, 96, 96, 1, 3) The numpy.squeeze() operation is also facilitated by rearrange() as usual. 1 2 3 4 u = rearrange ( images , \"b h w c -> b 1 h w 1 c\" ) ## torch.unsqueeze() v = rearrange ( u , \"b 1 h w 1 c -> b h w c\" ) ## torch.unsqueeze() v . shape ## (6, 96, 96, 3) An example usage Compute max in each image individually and then show a difference 1 2 3 4 x = reduce ( images , \"b h w c -> b () () c\" , max ) x -= images y = rearrange ( x , \"b h w c -> h (b w) c\" ) y . shape ## (96, 6*96, 3)","title":"Addition and removal of axes"},{"location":"blogs/deep_learning/einops/#meet-repeat-repeating-elements","text":"This is the third operation in einops library Repeat along a new axis . The new axis can be placed anywhere. 1 2 3 4 5 6 7 u = repeat ( images [ 0 ], \"h w c -> h new_axis w c\" , new_axis = 5 ) u . shape ## (96, 5, 96, 3) ## -- OR -- a shortcut v = repeat ( images [ 0 ], \"h w c -> h 5 w c\" ) ## repeats 5 times in the new axis. v . shape ## (96, 5, 96, 3) Repat along an existing axis 1 2 3 ## repeats the width 3 times u = repeat ( images [ 0 ], \"h w c -> h (repeat w) c\" , repeat = 3 ) u . shape ## (96, 3*96, 3) Repeat along multiple existing axes 1 2 u = repeat ( images [ 0 ], \"h w c -> (2 h) (2 w) c\" ) u . shape ## (2*96, 2*96, 3) Order of axes matter as usual. You can repeat each pixel 3 times by changing the order of axes in repeat 1 2 3 ## repeat the pixels along the width dim. 3 times u = repeat ( images [ 0 ], \"h w c -> h (w repeat) c\" , repeat = 3 ) u . shape ## (96, 96*3, 3) NOTE: The repeat operation covers numpy.tile , numpy.repeat and much more.","title":"Meet \"repeat\": Repeating elements"},{"location":"blogs/deep_learning/einops/#reduce-vs-repeat","text":"reduce and repeat are opposite of each other. reduce : reduces amount of elements repeat : increases the number of elements. An example of reduce v/s repeat In this example each image is repeated first then reduced over the new_axis to get back the original tensor. 1 2 3 4 5 6 7 repeated = repeat ( images , \"b h w c -> b h new_axis w c\" , new_axis = 2 ) reduced = reduce ( repeated , \"b h new_axis w c -> b h w c\" , \"min\" ) repeated . shape ## (6, 96, 2, 96, 3) reduced . shape ## (6, 96, 96, 3) assert numpy . array_equal ( images , reduced ) ## True Notice that the operation pattern in reduce and repeat are reverse of each other. i.e. in repeat its \"b h w c -> b h new_axis w c\" but in reduce its \"b h new_axis w c -> b h w c\"","title":"reduce v/s repeat"},{"location":"blogs/deep_learning/einops/#some-more-examples","text":"Interwaving pixels of different pictures All letters can be observed in the final image 1 2 u = rearrange ( images , \"(b1 b2) h w c -> (h b1) (w b2) c\" , b1 = 2 ) u . shape ## (2*96, 3*96, 3) Interweaving along vertical for couple of images 1 2 u = rearrange ( images , \"(b1 b2) h w c -> (h b1) (b2 w) c\" , b1 = 2 ) u . shape ## (96*2, 3*96, 3) Interweaving lines for couple of images 1 2 u = reduce ( images , \"(b1 b2) h w c -> h (b2 w) c\" , \"max\" , b1 = 2 ) u . shape ## (96, 3*96, 3) Decomposing color into different axes Here we decompose color dimension into different axes. We also downsample the image. 1 2 u = reduce ( images , \"b (h 2) (w 2) c -> (c h) (b w)\" , \"mean\" ) u . shape ## (3*48, 6*48) Disproportionate resize 1 2 u = reduce ( images , \"b (h 3) (w 4) c -> (h) (b w)\" , \"mean\" ) u . shape ## (96/3, 6*96/4) Split & Reduce Split each image into two halves and compute the mean of the two halves. 1 2 u = reduce ( images , \"b (h1 h2) w c -> h2 (b w)\" , \"mean\" , h1 = 2 ) u . shape ## (96/2, 6*96) Split and Transpose Split into small patches and transpose each patch. 1 2 3 4 ## splitting each image into 96/8 * 96/8 = 12*12 = 144 patches ## each patch is of shape (8, 8) u = rearrange ( images , \"b (h1 h2) (w1 w2) c -> (h1 w2) (b w1 h2) c\" , h2 = 8 , w2 = 8 ) u . shape ## (12*8, 6*12*8, 3) Another Split & Transpose This is crazy 1 2 3 4 u = rearrange ( images , \"b (h1 h2 h3) (w1 w2 w3) c -> (h1 w2 h3) (b w1 h2 w3) c\" , h2 = 2 , h3 = 2 , w2 = 2 , w3 = 2 ) u . shape ## (96/(2*2)*2*2, 6*96/(2*2)*2*2, c) = (96, 6*96, 3) Yet another Split & Transpose This is crazy crazy.... 1 2 3 4 u = rearrange ( images , \"(b1 b2) (h1 h2) (w1 w2) c -> (h1 b1 h2) (w1 b2 w2) c\" , h1 = 3 , w1 = 3 , b2 = 3 ) u . shape ## (3*(6/3)*(96/3), 3*3*(96/3), 3) = (192, 288, 3) Arbitrarily Complicated Pattern 1 2 3 4 u = reduce ( images , \"(b1 b2) (h1 h2 h3) (w1 w2 w3) c -> (h1 w1 h3) (b1 w2 h2 w3 b2) c\" , \"mean\" , w1 = 2 , w3 = 2 , h2 = 2 , h3 = 2 , b2 = 2 ) Subtract background & Normalize Subtract background in each image individually and normalize. NOTE: Pay attention to () -- this is a composition of 0 axis (a dummy axis with 1 element) 1 2 3 4 5 6 u = reduce ( images , \"b h w c -> b () () c\" , \"max\" ) ## finding per-image per-channel max u -= images ## subtracting u /= reduce ( u , \"b h w c -> b () () c\" , \"max\" ) ## NORMALIZATION u = rearrange ( u , \"b h w c -> h (b w) c\" ) u . shape ## (96, 6*96, 3) PIXELATE First downscale by averaging then upscale by using the same pattern. 1 2 3 4 5 6 7 8 ## downscale using \"mean\" kernel of size (6, 8) downscaled = reduce ( images , \"b (h h2) (w w2) c -> b h w c\" , \"mean\" , h2 = 6 , w2 = 8 ) upscaled = repeat ( downscaled , \"b h w c -> b (h h2) (w w2) c\" , h2 = 6 , w2 = 8 ) v = rearrange ( upscaled , \"b h w c -> h (b w) c\" ) downscaled . shape ## (6, 96/6, 96/8, 3) upscaled . shape ## (6, (96/6)*6, (96/8)*8, 3) = (6, 96, 96, 3) v . shape ## (96, 6*96, 3) ROTATE 1 2 u = rearrange ( images , \"b h w c -> w (b h) c\" ) ## rotation of (width <-> height) u . shape ## (96, 6*96, 3) Another Example Let's bring the channel dimension as part of the width axis. Also, at the same time downsample the width axis by 2x 1 2 3 4 u = reduce ( images , \"b (h h2) (w w2) c -> (h w2) (b w c)\" , \"mean\" , h2 = 3 , w2 = 3 )","title":"Some more examples"},{"location":"blogs/deep_learning/einops2/","text":"Popular Deep Learning Architectures using EINOPS In this section we will be rewriting the building blocks of deep learning in both the traditional PyTorch way as well as using einops library. Imports Firstly, we will import the necessary libraries to be used. 1 2 3 4 5 6 7 8 9 10 11 ## importing necessary libraries import math import numpy as np import torch import torch.nn as nn import torch.nn.functional as F from einops import rearrange , reduce , repeat , asnumpy , parse_shape from einops.layers.torch import Rearrange , Reduce Simple ConvNet Using only PyTorch Here is an implementation of a simple ConvNet using only PyTorch without einops . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ConvNet ( nn . Module ): def __init__ ( self ): super ( ConvNet , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 10 , kernel_size = 5 ) self . conv2 = nn . Conv2d ( 10 , 20 , kernel_size = 5 ) self . conv2_drop = nn . Dropout2d () self . fc1 = nn . Linear ( 320 , 50 ) self . fc2 = nn . Linear ( 20 , 10 ) def forward ( self , x ): x = self . conv1 ( x ) x = F . max_pool2d ( x , 2 ) x = F . relu ( x ) x = self . conv2 ( x ) x = self . conv2_drop ( x ) x = F . max_pool2d ( x , 2 ) x = F . relu ( x ) x = x . view ( - 1 , 320 ) x = self . fc1 ( x ) x = F . relu ( x ) x = F . dropout ( x , training = self . training ) x = self . fc2 ( x ) return F . log_softmax ( x , dim = 1 ) ## Instantiating the ConvNet class conv_net_old = ConvNet () Using EINOPS + PyTorch Implementing the same above ConvNet using einops & PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 conv_net_new = nn . Sequential ( nn . Conv2d ( 1 , 10 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Conv2d ( 10 , 20 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Dropout2d (), Rearrange ( \"b c h w -> b (c h w)\" ), nn . Linear ( 320 , 50 ), nn . ReLU (), nn . Dropout (), nn . Linear ( 50 , 10 ), nn . LogSoftmax ( dim = 1 ) ) Why prefer EINOPS implementation? Following are the reasons to prefer the new implementation: In the original code, if the input is changed and the batch_size is divisible by 16 (which usually is), we will get something senseless after reshaping. The new code using einops explicitly raise ERROR in the above scenario. Hence better!! We won't forget to use the flag self.training with the new implementation. Code is straightforward to read and analyze. nn.Sequential makes printing/saving/passing trivial. And there is no need in your code to load the model (which also has lots of benefits). Don't need logsoftmax ? Now, you can use conv_net_new[-1] . Another reason to prefer nn.Sequential ... And we culd also add inplace ReLU Super-resolution Only PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class SuperResolutionNetOLD ( nn . Module ): def __init__ ( self , upscale_factor ): super ( SuperResolutionNetOLD , self ) . __init__ () self . relu = nn . ReLU () self . conv1 = nn . Conv2d ( 1 , 64 , ( 5 , 5 ), ( 1 , 1 ), ( 2 , 2 )) self . conv2 = nn . Conv2d ( 64 , 64 , ( 3 , 3 ), ( 1 , 1 ), ( 1 , 1 )) self . conv3 = nn . Conv2d ( 64 , 32 , ( 3 , 3 ), ( 1 , 1 ), ( 1 , 1 )) self . conv4 = nn . Conv2d ( 32 , upscale_factor ** 2 , ( 3 , 3 ), ( 1 , 1 ), ( 1 , 1 )) self . pixel_shuffle = nn . PixelShuffle ( upscale_factor ) def forward ( self , x ): x = self . relu ( self . conv1 ( x )) x = self . relu ( self . conv2 ( x )) x = self . relu ( self . conv3 ( x )) x = self . pixel_shuffle ( self . conv4 ( x )) return x Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 def SuperResolutionNetNEW ( upscale_factor ): return nn . Sequential ( nn . Conv2d ( 1 , 64 , kernel_size = 5 , padding = 2 ), nn . ReLU ( inplace = True ), nn . Conv2d ( 64 , 64 , kernel_size = 3 , padding = 1 ), nn . ReLU ( inplace = True ), nn . Conv2d ( 64 , 32 , kernel_size = 3 , padding = 1 ), nn . ReLU ( inplace = True ), nn . Conv2d ( 32 , upscale_factor ** 2 , kernel_size = 3 , padding = 1 ), Rearrange ( \"b (h2 w2) h w -> b (h h2) (w w2)\" , h2 = upscale_factor , w2 = upscale_factor ) ) Improvements over the old implementation No need in special instruction pixel_shuffle (& the result is transferrable b/w the frameworks) Output does not contain a fake axis (& we could do the same for the input) inplace ReLU used now. For high resolution images this becomes critical and saves a lot of memory. and all the benefits of nn.Sequential Gram Matrix / Style Transfer Restyling Graam Matrix for style transfer. Original Code using ONLY PyTorch The original code is already very good. First line shows what kind of input is expected. 1 2 3 4 5 6 def gram_matrix_old ( y ): ( b , c , h , w ) = y . size () features = y . view ( b , c , h * w ) features_t = features . transpose ( 1 , 2 ) gram = features . bmm ( features_t ) / ( c * h * w ) return gram Using EINSUM 1 2 3 def gram_matrix_new ( y ): b , c , h , w = y . shape return torch . einsum ( \"bchw, bdhw -> bcd\" , [ y , y ]) / ( h * w ) Improvements einsum operations should be read like: For each batch & each pair of channels we sum over h and w . The normalization is also changed, because that's how Gram Matrix is defined. Else we should call it Normalized Gram Matrix or alike. Recurrent Models (RNNs) ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RNNModelOLD ( nn . Module ): \"\"\"Container module with an ENCODER, a RECURRENT module & a DECODER module\"\"\" def __init__ ( self , ntoken , ninp , nhid , nlayers , dropout = 0.5 ): super ( RNNModelOLD , self ) . __init__ () self . drop = nn . Dropout ( dropout ) self . encoder = nn . Embedding ( ntoken , ninp ) self . rnn = nn . LSTM ( ninp , nhid , nlayers , dropout = dropout ) self . decoder = nn . Linear ( nhid , ntoken ) def forward ( self , input , hidden ): emb = self . drop ( self . encoder ( input )) output , hidden = self . rnn ( emb , hidden ) output = self . drop ( output ) decoded = self . decoder ( output . view ( output . size ( 0 ) * output . size ( 1 ), output . size ( 2 ))) return decoded . view ( output . size ( 0 ), output . size ( 1 ), decoded . size ( 1 )), hidden Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def RNNModelNEW ( nn . Module ): \"\"\"Container module with an ENCODER, RNN & a DECODER modules.\"\"\" def __init__ ( self , ntoken , ninp , nhid , nlayers , dropout = 0.5 ): super ( RNNModelNEW , self ) . __init__ () self . drop = nn . Dropout ( dropout ) self . encoder = nn . Embedding ( ntoken , ninp ) self . rnn = nn . LSTM ( ninp , nhid , nlayers , dropout = dropout ) self . decoder = nn . Linear ( nhid , ntoken ) def forward ( self , input , hidden ): t , b = input . shape [: 2 ] emb = self . drop ( self . encoder ( input )) output , hidden = self . rnn ( emb , hidden ) output = rearrange ( self . drop ( output ), \"t b nhid -> (t b) nhid\" ) decoded = rearrange ( self . decoder ( output ), \"(t b) token -> t b token\" , t = t , b = b ) return decoded , hidden Improving RNN Only PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class RNNold ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , hidden_dim , output_dim , n_layers , bidirectional , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . rnn = nn . LSTM ( embedding_dim , hidden_dim , num_layers = n_layers , bidirectional = bidirectional , dropout = dropout ) self . fc = nn . Linear ( hidden_dim * 2 , output_dim ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): ## x = [sent_len, batch_size] embedded = self . dropout ( self . embedding ( x )) ## size = [sent_len, batch_size, emb_dim] output , ( hidden , cell ) = self . rnn ( embedded ) ## output.shape = [sent_len, batch_size, hid_dim * num_directions] ## hidden.shape = [num_layers * num_directions, batch_size, hid_dim] ## cell.shape = [num_layers * num_directions, batch_size, hid_dim] ## concat the final dropout (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers ## and apply dropout ## hidden.size = [batch_size, hid_dim * num_directions] hidden = self . dropout ( torch . cat ([ hidden [ - 2 ,:,:], hidden [ - 1 ,:,:]], dim = 1 )) return self . fc ( hidden . squeeze ( 0 )) Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class RNNnew ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , hidden_dim , output_dim , n_layers , bidirectional , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . rnn = nn . LSTM ( embedding_dim , hidden_dim , num_layers = n_layers , bidirectional = bidirectional , dropout = dropout ) self . dropout = nn . Dropout ( dropout ) self . directions = 2 if bidirectional else 1 self . fc = nn . Linear ( hidden_dim * self . directions , output_dim ) def forward ( self , x ): embedded = self . dropout ( self . embedding ( x )) output , ( hidden , cell ) = self . rnn ( embedded ) hidden = rearrange ( hidden , \"(layer dir) b c -> layer b (dir c)\" , dir = self . directions ) ## take the fina layer's hidden return self . fc ( self . dropout ( hidden [ - 1 ])) Channel Shuffle (from ShuffleNet) ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def channel_shuffle_old ( x , groups ): b , c , h , w = x . data . size () channels_per_group = c // groups ## reshape x = x . view ( b , groups , channels_per_group , h , w ) ## transpose ## - contiguous() is required if transpose() is used before view() ## See https://github.com/pytorch/pytorch/issues/764 x = x . transpose ( 1 , 2 ) . contiguous () ## flatten x = x . view ( b , - 1 , h , w ) return x Using EINOPS 1 2 def channel_shuffle_new ( x , groups ): return rearrange ( x , \"b (c1 c2) h w -> b (c2 c1) h w\" , c1 = groups ) ShuffleNet ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 from collections import OrderedDict def channel_shuffle ( x , groups ): b , c , h , w = x . data . size () channels_per_group = c // groups ## reshape x = x . view ( b , groups , channels_per_group , h , w ) ## transpose ## - contiguous() is required if transpose() is used before view() x = x . transpose ( 1 , 2 ) . contiguous () x = x . view ( b , - 1 , h , w ) return x class ShuffleUnitOLD ( nn . Module ): def __init__ ( self , in_channels , out_channels , groups = 3 , grouped_conv = True , combine = \"add\" , ): super ( ShuffleUnitOLD , self ) . __init__ () self . in_channels = in_channels self . out_channels = out_channels self . grouped_conv = grouped_conv self . combine = combine self . groups = groups self . bottleneck_channels = self . out_channels // 4 ## define the type of ShuffleUnit if self . combine == \"add\" : ## shuffleUnit fig-2b self . depthwise_stride = 1 self . _combine_func = self . _add elif self . combine == \"concat\" : ## ShuffleUnit fig-2c self . depthwise_stride = 2 self . _combine_func = self . _concat ## ensure output of the concat has the same channels ## as the original input channels self . out_channels -= self . in_channels else : raise ValueError ( f \"Cannot combine tensors with { self . combine } . \\n \" f \"Only 'add' & 'concat' supported.\" ) ## Use a 1x1 grouped or non-grouped convolution to reduce input channels ## to bottleneck channels, as in ResNet bottleneck module. ## NOTE: do not use group convolution for the first conv1x1 in stage-2 self . first_1x1_groups = self . groups if grouped_conv else 1 self . g_conv_1x1_compress = self . _make_grouped_conv1x1 ( self . in_channels , self . bottleneck_channels , self . first_1x1_groups , batch_norm = True , relu = True , ) ## 3x3 depthwise convolution followed by batch normalization self . depthwise_conv3x3 = conv3x3 ( self . bottleneck_channels , self . bottleneck_channels , stride = self . depthwise_stride , groups = self . bottleneck_channels ) self . bn_after_depthwise = nn . BatchNordm2d ( self . bottleneck_channels ) ## use 1x1 grouped convolution to expand from bottleneck_channels to out_channels self . g_conv_conv_1x1_expand = self . _make_grouped_conv1x1 ( self . bottleneck_channels , self . out_channels , self . groups , batch_norm = True , relu = False ) @staticmethod def _add ( x , out ): ## residual connection return x + out @staticmethod def _concat ( x , out ): ## concat along channel dim return torch . cat (( x , out ), 1 ) def _make_grouped_conv1x1 ( self , in_channels , out_channels , groups , batch_norm = True , relu = False ): modules = OrderedDict () conv = conv1x1 ( in_channels , out_channels , groups = groups ) modules [ 'conv1x1' ] = conv if batch_norm : modules [ 'batch_norm' ] = nn . BatchNorm2d ( out_channels ) if relu : modules [ 'relu' ] = nn . ReLU () if len ( modules ) > 1 : return nn . Sequential ( modules ) else : return conv def forward ( self , x ): ## save for combining later with output residual = x if self . combine == \"concat\" : residual = F . avg_pool2d ( residual , kernel_size = 3 , stride = 2 , padding = 1 ) out = self . g_con_1x1_compress ( x ) out = channel_shuffle ( out , self . groups ) out = self . depthwise_conv3x3 ( out ) out = self . bn_after_depthwise ( out ) out = self . g_conv_1x1_expand ( out ) out = self . _combine_func ( residual , out ) return F . relu ( out ) Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class ShuffleUnitNEW ( nn . Module ): def __init__ ( self , in_channels , out_channels , groups = 3 , grouped_conv = True , combine = \"add\" ): super () . __init__ () first_1x1_groups = groups if grouped_conv else 1 bottleneck_channels = out_channels // 4 self . combine = combine if combine == \"add\" : ## ShuffleUnit fig-2b self . left = Rearrange ( \"...->...\" ) ## identity depthwise_stride = 1 else : ## ShuffleUnit fig-2c self . left = nn . AvgPool2d ( kernel_size = 3 , stride = 2 , padding = 1 ) depthwise_stride = 2 ## ensure output of concat has the same channels as the original output channels out_channels -= in_channels assert out_channels > 0 self . right = nn . Sequential ( ## use a 1x1grouped or non-grouped convolution to reduce ## input channels to bottleneck channels as in ResNet bottleneck module. conv1x1 ( in_channels , bottleneck_channels , groups = first_1x1_groups ), nn . BatchNorm2d ( bottleneck_channels ), nn . ReLU ( inplace = True ), ## channel shuffle Rearrange ( \"b (c1 c2) h w -> b (c2 c1) h w\" , c1 = groups ), ## 3x3 depthwise convolution followed by BatchNorm conv3x3 ( bottleneck_channels , bottleneck_channels , stride = depthwise_stride , groups = bottleneck_channels ), nn . BatchNorm2d ( bottleneck_channels ), ## Use 1x1 grouped convolution to expand from bottleneck_channels to output_channels conv1x1 ( bottleneck_channels , out_channels , groups = groups ), nn . BatchNorm2d ( out_channels ), ) def forward ( self , x ): if self . combine == \"add\" : combined = self . left ( x ) + self . right ( x ) else : combined = torch . cat ([ self . left ( x ), self . right ( x )], dim = 1 ) return F . relu ( combined , inplace = True ) Improvements Rewriting the code helped to identify the following: There is no sense in doing reshuffling and not using groups in the first convolution (indeed in the paper it is not so). However , the result is an equivalent model . It is strage that the first convolution may not be grouped, while the last convolution is always grouped. ( and th's different from the paper ) Also, There is an identity layer for pyTorch introduced here. The last thing to do is to get rid of conv1x1 and conv3x3 (those are not better than the standard implementation) ResNet ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class ResNetOLD ( nn . Module ): def __init__ ( self , block , layers , num_classes = 1000 ): self . inplanes = 64 super ( ResNetOLD , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 64 , kernel_size = 7 , stride = 2 , padding = 3 , bias = False ) self . bn1 = nn . BatchNorm2d ( 64 ) self . relu = nn . ReLU ( inplace = True ) self . maxpool = nn . MaaxPool2d ( kernel_size = 3 , stride = 2 , paadding = 1 ) self . layer1 = self . _make_layer ( block , 64 , layers [ 0 ]) self . layer2 = self . _make_layer ( block , 128 , layers [ 1 ], stride = 2 ) self . layer3 = self . _make_layer ( block , 256 , layers [ 2 ], stride = 2 ) self . layer4 = self . _make_layer ( block , 512 , layers [ 3 ], stride = 2 ) self . avgpool = nn . AvgPool2d ( 7 , stride = 1 ) self . fc = nn . Linear ( 512 * block . expansion , num_classes ) for m in self . modules : if isinstance ( m , nn . Conv2d ): n = m . kernel_size [ 0 ] * m . kernel_size [ 1 ] * m . out_channels m . weight . data . normal_ ( 0 , math . sqrt ( 2. / n )) elif isinstance ( m , nn . BatchNord2d ): m . weight . data . fill_ ( 1 ) m . bias . data . zero_ () def _make_layer ( self , block , planes , blocks , stride = 1 ): downsample = None if stride != 1 or self . inplanes != planes * block . expansion : downsample = nn . Sequential ( nn . Conv2d ( self . inplanes , planes * block . expansion , kernel_size = 1 , stride = stride , bias = False ), nn . BatchNorm2d ( planes * block . expansion ), ) layers = [] layers . append ( block ( self . inplanes , planes , stride , downsample )) self . inplanes = planes * block . expansion for i in range ( 1 , blocks ): layers . append ( block ( self . inplanes , planes )) return nn . Sequential ( * layers ) def forward ( self , x ): x = self . conv1 ( x ) x = self . bn1 ( x ) x = self . relu ( x ) x = self . maxpool ( x ) x = self . layer1 ( x ) x = self . layer2 ( x ) x = self . layer3 ( x ) x = self . layer4 ( x ) x = self . avgpool ( x ) x = x . view ( x . size ( 0 ), - 1 ) x = self . fc ( x ) return x Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def make_layer ( inplanes , planes , block , n_blocks , stride = 1 ): downsample = None if stride != 1 or inplanes != planes * block . expansion : ## output-size won't match input-size; so adjust the residual downsample = nn . Sequential ( nn . Conv2d ( inplanes , planes * block . expansion , kernel_size = 1 , stride = stride , bias = False ), nn . BatchNorm2d ( planes * block . expansion ), ) return nn . Sequential ( block ( inplanes , planes , stride , downsample ), * [ block ( planes * block . expansion , planes ) for _ in range ( 1 , n_blocks )] ) def ResNetNEW ( block , layers , num_classes = 1000 ): e = block . expansion resnet = nn . Sequential ( Rearrange ( \"b c h w -> b c h w\" , c = 3 , h = 224 , w = 224 ), nn . Conv2d ( 3 , 64 , kernel_size = 7 , stride = 2 , padding = 3 , bias = False ), nn . BatchNorm2d ( 64 ), nn . ReLU ( inplace = True ), nn . MaxPool2d ( kernel_size = 3 , stride = 2 , padding = 1 ), make_layer ( 64 , 64 , block , layers [ 0 ], stride = 1 ), make_layer ( 64 * e , 128 , block , layers [ 1 ], stride = 2 ), make_layer ( 128 * e , 256 , block , layers [ 2 ], stride = 2 ), make_layer ( 256 * e , 512 , block , layers [ 3 ], stride = 2 ), ## Combined AvgPool & view in one single operation Reduce ( \"b c h w -> b c\" , \"mean\" ), n . Linear ( 512 * e , num_classes ), ) ## initialization for m in resnet . modules (): if isinstance ( m , nn . Conv2d ): n = m . kernel_size [ 0 ] * m . kernel_size [ 1 ] * m . out_channels m . weight . data . normal_ ( 0 , math . sqrt ( 2. / n )) elif isinstance ( m , nn . BatchNorm2d ): m . weight . data . fill_ ( 1. ) m . bias . data . zero_ () return resnet FastText ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 class FastTextOLD ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , output_dim ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . fc = nn . Linear ( embedding_dim , output_dim ) def forward ( self , x ): embedded = self . embedding ( x ) embedded = embedded . permute ( 1 , 0 , 2 ) pooled = F . avg_pool2d ( embedded , ( embedded . shape [ 1 ], 1 )) . squeeze ( 1 ) return self . fc ( pooled ) Using EINOPS 1 2 3 4 5 6 7 8 def FastTextNEW ( vocab_size , embedding_dim , output_dim ): return nn . Sequential ( Rearrange ( \"t b -> t b\" ), nn . Embedding ( vocab_size , embedding_dim ), Reduce ( \"t b c -> b c\" , \"mean\" ), nn . Linear ( embedding_dim , output_dim ), Rearrange ( \"b c -> b c\" ), ) Here, the first and last operations (highlighted) do nothing and can be removed. But, were added to explicitly added to show expected input and output shape This also gives us the flexibility of changing interface by editing a single line. Should you need to accept inputs of shape (b, t) we just need to change the line to Rearrange(\"b t -> t b\") CNNs for text classification ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class CNNold ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , n_filters , filter_sizes , output_dim , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . conv_0 = nn . Conv2d ( in_channels = 1 , out_channels = n_filters , kernel_size = ( filter_sizes [ 0 ], embedding_dim )) self . conv_1 = nn . Conv2d ( in_channels = 1 , out_channels = n_filters , kernel_size = ( filter_sizes [ 1 ], embedding_dim )) self . conv_2 = nn . Conv2d ( in_channels = 1 , out_channels = n_filters , kernel_size = ( filter_sizes [ 2 ], embedding_dim )) self . fc = nn . Linear ( len ( filter_sizes ) * n_filters , output_dim ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): x = x . permute ( 1 , 0 ) embedded = self . embedding ( x ) embedded = embedded . unsqueeze ( dim = 1 ) conved_0 = F . relu ( self . conv_0 ( embedded ) . squeeze ( dim = 3 )) conved_1 = F . relu ( self . conv_1 ( embedded ) . squeeze ( dim = 3 )) conved_2 = F . relu ( self . conv_2 ( embedded ) . squeeze ( dim = 3 )) pooled_0 = F . max_pool1d ( conved_0 , conved_0 . shape [ 2 ]) . squeeze ( dim = 2 ) pooled_1 = F . max_pool1d ( conved_1 , conved_1 . shape [ 2 ]) . squeeze ( dim = 2 ) pooled_2 = F . max_pool1d ( conved_2 , conved_2 . shape [ 2 ]) . squeeze ( dim = 2 ) cat = self . dropout ( torch . cat (( pooled_0 , pooled_1 , pooled_2 ), dim = 1 )) return self . fc ( cat ) Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class CNNnew ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , n_filters , filter_sizes , output_dim , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . convs = nn . ModuleList ([ nn . Conv1d ( embedding_dim , n_filters , kernel_size = size ) for size in filter_sizes ]) self . fc = nn . Linear ( len ( filter_sizes ) * n_filters , output_dim ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): x = rearrange ( x , \"t b -> t b\" ) emb = rearrange ( self . embedding ( x ), \"t b c -> b c t\" ) pooled = [ reduce ( conv ( emb ), \"b c t -> b c\" ) for conv in self . convs ] concatenated = rearrange ( pooled , \"filter b c -> b (filter c)\" ) return self . fc ( self . dropout ( F . relu ( concatenated ))) Discussion Original code misuses nn.Conv2d while nn.Conv1d is the right choice. New code can work with any number of filter_sizes and won't fail. First line in the new code does nothing, but was just added for simplicity & clarity of shapes. Highway Convolutions ONLY PyTorch 1 2 3 4 5 6 class HighwayConv1dOLD ( nn . Conv1d ): def forward ( self , inputs ): L = super ( HIghwayCon1dOLD , self ) . forward ( inputs ) H1 , H2 = torch . chunk ( L , 2 , dim = 1 ) ## chunk at the feature dimension torch . sigmoid_ ( H1 ) return H1 * H2 + ( 1.0 - H1 ) * inputs Using EINOPS 1 2 3 4 5 6 class HighwayConv1dNEW ( nn . Conv1d ): def forward ( self , inputs ): L = super () . forward ( inputs ) H1 , H2 = rearrange ( L , \"b (split c) t -> split b c t\" , split = 2 ) torch . sigmoid_ ( H1 ) return H1 * H2 + ( 1.0 - H1 ) * inputs Simple Attention ONLY PyTorch 1 2 3 4 5 6 7 8 9 class Attention ( nn . Module ): def __init__ ( self ): super ( Attention , self ) . __init__ () def forward ( self , K , Q , V ): A = torch . bmm ( K . transpose (( 1 , 2 ), Q ) / np . sqrt ( Q . shape [ 1 ]) A = F . softmax ( A , dim = 1 ) R = torch . bmm ( V , A ) return torch . cat (( R , Q ), dim = 1 ) Using EINOPS 1 2 3 4 5 6 def attention ( K , Q , V ): _ , n_channels , _ = K . shape A = torch . einsum ( \"bct,bcl->btl\" , [ K , Q ]) A = F . softmax ( A * n_channels ** ( - 0.5 ), dim = 1 ) R = torch . einsum ( \"bct,btl->bcl\" , [ V , A ]) return torch . cat (( R , Q ), dim = 1 ) Multi-head Attention ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ScaledDotProductAttention ( nn . Module ): \"\"\"Scaled Dot Product Attention\"\"\" def __init__ ( self , temperature , attn_dropout = 0.1 ): super () . __init__ () self . temperature = temperature self . dropout = nn . Dropout ( attn_dropout ) self . softmax = nn . Softmax ( dim = 2 ) def forward ( self , q , k , v , mask = None ): attn = torch . bmm ( q , k . transpose ( 1 , 2 )) attn /= self . temperature if mask is not None : attn = attn . masked_fill ( mask , - np . inf ) attn = self . softmax ( attn ) attn = self . dropout ( attn ) output = torch . bmm ( attn , v ) return output , attn class MultiHeadAttentionOLD ( nn . Module ): \"\"\"Multi Head Attention Module\"\"\" def __init__ ( self , n_head , d_model , d_k , d_v , dropout = 0.1 ): super () . __init__ () self . d_k = d_k self . d_v = d_v self . n_head = n_head self . w_qs = nn . Linear ( d_model , n_head * d_k ) self . w_ks = nn . Linear ( d_model , n_head * d_k ) self . w_vs = nn . Linear ( d_model , n_head * d_v ) nn . init . normal_ ( self . w_qs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_k ))) nn . init . normal_ ( self . w_ks . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_k ))) nn . init . normal_ ( self . w_vs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_v ))) self . attention = ScaledDotProductAttention ( temperature = d_k ** 0.5 ) self . layer_norm = nn . LayerNorm ( d_model ) self . fc = nn . Linear ( n_head * d_v , d_model ) nn . init . xavier_normal_ ( self . fc . weight ) self . dropout = nn . Dropout ( dropout ) def forward ( self , q , k , v , mask = None ): d_k = self . d_k d_v = self . d_v n_head = self . n_head sz_b , len_q , _ = q . size () sz_b , len_k , _ = k . size () sz_b , len_v , _ = v . size () residual = q q = self . w_qs ( q ) . view ( sz_b , len_q , n_head , d_k ) k = self . w_ks ( k ) . view ( sz_b , len_k , n_head , d_k ) v = self . w_vs ( v ) . view ( sz_b , len_v , n_head , d_v ) q = q . permute ( 2 , 0 , 1 , 3 ) . contiguous () . view ( - 1 , len_q , d_k ) ## (n*b, len_q, d_k) k = k . permute ( 2 , 0 , 1 , 3 ) . contiguous () . view ( - 1 , len_k , d_k ) ## (n*b, len_k, d_k) v = v . permute ( 2 , 0 , 1 , 3 ) . contiguous () . view ( - 1 , len_v , d_v ) ## (n*b, len_v, d_v) mask = mask . repeat ( n_head , 1 , 1 ) ## (n*b, ...) output , attn = self . attention ( q , k , v , mask = mask ) output = output . view ( n_head , sz_b , len_q , d_v ) output = output . permute ( 1 , 2 , 0 , 3 ) . contiguous () . view ( sz_b , len_q , - 1 ) ## (b, len_q, n*d_v) output = self . dropout ( self . fc ( output )) output = self . layer_norm ( output + residual ) return output , attn Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class MultiHeadAttentionNEW ( nn . Module ): def __init__ ( self , n_heads , d_model , d_k , d_v , dropout = 0.1 ): super () . __init__ () self . n_heads = n_heads self . w_qs = nn . Linear ( d_model , n_heads * d_k ) self . w_ks = nn . Linear ( d_model , n_heads * d_k ) self . w_vs = nn . Linear ( d_model , n_heads * d_v ) nn . init . normal_ ( self . w_qs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d - model + d_k ))) nn . init . normal_ ( self . w_ks . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_k ))) nn . init . normal_ ( self . w_vs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_v ))) self . fc = nn . Linear ( n_heads * d_v , d_model ) nn . init . xavier_normal_ ( self . fc . weight ) self . dropout = nn . Dropout ( dropout ) self . layer_norm = nn . LayerNorm ( d_model ) def forward ( self , q , k , v , mask = None ): residual = q References http://einops.rocks/pytorch-examples.html \u21a9 https://github.com/arogozhnikov/einops \u21a9","title":"einops examples"},{"location":"blogs/deep_learning/einops2/#popular-deep-learning-architectures-using-einops","text":"In this section we will be rewriting the building blocks of deep learning in both the traditional PyTorch way as well as using einops library.","title":"Popular Deep Learning Architectures using EINOPS"},{"location":"blogs/deep_learning/einops2/#imports","text":"Firstly, we will import the necessary libraries to be used. 1 2 3 4 5 6 7 8 9 10 11 ## importing necessary libraries import math import numpy as np import torch import torch.nn as nn import torch.nn.functional as F from einops import rearrange , reduce , repeat , asnumpy , parse_shape from einops.layers.torch import Rearrange , Reduce","title":"Imports"},{"location":"blogs/deep_learning/einops2/#simple-convnet","text":"Using only PyTorch Here is an implementation of a simple ConvNet using only PyTorch without einops . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class ConvNet ( nn . Module ): def __init__ ( self ): super ( ConvNet , self ) . __init__ () self . conv1 = nn . Conv2d ( 1 , 10 , kernel_size = 5 ) self . conv2 = nn . Conv2d ( 10 , 20 , kernel_size = 5 ) self . conv2_drop = nn . Dropout2d () self . fc1 = nn . Linear ( 320 , 50 ) self . fc2 = nn . Linear ( 20 , 10 ) def forward ( self , x ): x = self . conv1 ( x ) x = F . max_pool2d ( x , 2 ) x = F . relu ( x ) x = self . conv2 ( x ) x = self . conv2_drop ( x ) x = F . max_pool2d ( x , 2 ) x = F . relu ( x ) x = x . view ( - 1 , 320 ) x = self . fc1 ( x ) x = F . relu ( x ) x = F . dropout ( x , training = self . training ) x = self . fc2 ( x ) return F . log_softmax ( x , dim = 1 ) ## Instantiating the ConvNet class conv_net_old = ConvNet () Using EINOPS + PyTorch Implementing the same above ConvNet using einops & PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 conv_net_new = nn . Sequential ( nn . Conv2d ( 1 , 10 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Conv2d ( 10 , 20 , kernel_size = 5 ), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Dropout2d (), Rearrange ( \"b c h w -> b (c h w)\" ), nn . Linear ( 320 , 50 ), nn . ReLU (), nn . Dropout (), nn . Linear ( 50 , 10 ), nn . LogSoftmax ( dim = 1 ) ) Why prefer EINOPS implementation? Following are the reasons to prefer the new implementation: In the original code, if the input is changed and the batch_size is divisible by 16 (which usually is), we will get something senseless after reshaping. The new code using einops explicitly raise ERROR in the above scenario. Hence better!! We won't forget to use the flag self.training with the new implementation. Code is straightforward to read and analyze. nn.Sequential makes printing/saving/passing trivial. And there is no need in your code to load the model (which also has lots of benefits). Don't need logsoftmax ? Now, you can use conv_net_new[-1] . Another reason to prefer nn.Sequential ... And we culd also add inplace ReLU","title":"Simple ConvNet"},{"location":"blogs/deep_learning/einops2/#super-resolution","text":"Only PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class SuperResolutionNetOLD ( nn . Module ): def __init__ ( self , upscale_factor ): super ( SuperResolutionNetOLD , self ) . __init__ () self . relu = nn . ReLU () self . conv1 = nn . Conv2d ( 1 , 64 , ( 5 , 5 ), ( 1 , 1 ), ( 2 , 2 )) self . conv2 = nn . Conv2d ( 64 , 64 , ( 3 , 3 ), ( 1 , 1 ), ( 1 , 1 )) self . conv3 = nn . Conv2d ( 64 , 32 , ( 3 , 3 ), ( 1 , 1 ), ( 1 , 1 )) self . conv4 = nn . Conv2d ( 32 , upscale_factor ** 2 , ( 3 , 3 ), ( 1 , 1 ), ( 1 , 1 )) self . pixel_shuffle = nn . PixelShuffle ( upscale_factor ) def forward ( self , x ): x = self . relu ( self . conv1 ( x )) x = self . relu ( self . conv2 ( x )) x = self . relu ( self . conv3 ( x )) x = self . pixel_shuffle ( self . conv4 ( x )) return x Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 def SuperResolutionNetNEW ( upscale_factor ): return nn . Sequential ( nn . Conv2d ( 1 , 64 , kernel_size = 5 , padding = 2 ), nn . ReLU ( inplace = True ), nn . Conv2d ( 64 , 64 , kernel_size = 3 , padding = 1 ), nn . ReLU ( inplace = True ), nn . Conv2d ( 64 , 32 , kernel_size = 3 , padding = 1 ), nn . ReLU ( inplace = True ), nn . Conv2d ( 32 , upscale_factor ** 2 , kernel_size = 3 , padding = 1 ), Rearrange ( \"b (h2 w2) h w -> b (h h2) (w w2)\" , h2 = upscale_factor , w2 = upscale_factor ) ) Improvements over the old implementation No need in special instruction pixel_shuffle (& the result is transferrable b/w the frameworks) Output does not contain a fake axis (& we could do the same for the input) inplace ReLU used now. For high resolution images this becomes critical and saves a lot of memory. and all the benefits of nn.Sequential","title":"Super-resolution"},{"location":"blogs/deep_learning/einops2/#gram-matrix-style-transfer","text":"Restyling Graam Matrix for style transfer. Original Code using ONLY PyTorch The original code is already very good. First line shows what kind of input is expected. 1 2 3 4 5 6 def gram_matrix_old ( y ): ( b , c , h , w ) = y . size () features = y . view ( b , c , h * w ) features_t = features . transpose ( 1 , 2 ) gram = features . bmm ( features_t ) / ( c * h * w ) return gram Using EINSUM 1 2 3 def gram_matrix_new ( y ): b , c , h , w = y . shape return torch . einsum ( \"bchw, bdhw -> bcd\" , [ y , y ]) / ( h * w ) Improvements einsum operations should be read like: For each batch & each pair of channels we sum over h and w . The normalization is also changed, because that's how Gram Matrix is defined. Else we should call it Normalized Gram Matrix or alike.","title":"Gram Matrix / Style Transfer"},{"location":"blogs/deep_learning/einops2/#recurrent-models-rnns","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RNNModelOLD ( nn . Module ): \"\"\"Container module with an ENCODER, a RECURRENT module & a DECODER module\"\"\" def __init__ ( self , ntoken , ninp , nhid , nlayers , dropout = 0.5 ): super ( RNNModelOLD , self ) . __init__ () self . drop = nn . Dropout ( dropout ) self . encoder = nn . Embedding ( ntoken , ninp ) self . rnn = nn . LSTM ( ninp , nhid , nlayers , dropout = dropout ) self . decoder = nn . Linear ( nhid , ntoken ) def forward ( self , input , hidden ): emb = self . drop ( self . encoder ( input )) output , hidden = self . rnn ( emb , hidden ) output = self . drop ( output ) decoded = self . decoder ( output . view ( output . size ( 0 ) * output . size ( 1 ), output . size ( 2 ))) return decoded . view ( output . size ( 0 ), output . size ( 1 ), decoded . size ( 1 )), hidden Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def RNNModelNEW ( nn . Module ): \"\"\"Container module with an ENCODER, RNN & a DECODER modules.\"\"\" def __init__ ( self , ntoken , ninp , nhid , nlayers , dropout = 0.5 ): super ( RNNModelNEW , self ) . __init__ () self . drop = nn . Dropout ( dropout ) self . encoder = nn . Embedding ( ntoken , ninp ) self . rnn = nn . LSTM ( ninp , nhid , nlayers , dropout = dropout ) self . decoder = nn . Linear ( nhid , ntoken ) def forward ( self , input , hidden ): t , b = input . shape [: 2 ] emb = self . drop ( self . encoder ( input )) output , hidden = self . rnn ( emb , hidden ) output = rearrange ( self . drop ( output ), \"t b nhid -> (t b) nhid\" ) decoded = rearrange ( self . decoder ( output ), \"(t b) token -> t b token\" , t = t , b = b ) return decoded , hidden","title":"Recurrent Models (RNNs)"},{"location":"blogs/deep_learning/einops2/#improving-rnn","text":"Only PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class RNNold ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , hidden_dim , output_dim , n_layers , bidirectional , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . rnn = nn . LSTM ( embedding_dim , hidden_dim , num_layers = n_layers , bidirectional = bidirectional , dropout = dropout ) self . fc = nn . Linear ( hidden_dim * 2 , output_dim ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): ## x = [sent_len, batch_size] embedded = self . dropout ( self . embedding ( x )) ## size = [sent_len, batch_size, emb_dim] output , ( hidden , cell ) = self . rnn ( embedded ) ## output.shape = [sent_len, batch_size, hid_dim * num_directions] ## hidden.shape = [num_layers * num_directions, batch_size, hid_dim] ## cell.shape = [num_layers * num_directions, batch_size, hid_dim] ## concat the final dropout (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers ## and apply dropout ## hidden.size = [batch_size, hid_dim * num_directions] hidden = self . dropout ( torch . cat ([ hidden [ - 2 ,:,:], hidden [ - 1 ,:,:]], dim = 1 )) return self . fc ( hidden . squeeze ( 0 )) Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class RNNnew ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , hidden_dim , output_dim , n_layers , bidirectional , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . rnn = nn . LSTM ( embedding_dim , hidden_dim , num_layers = n_layers , bidirectional = bidirectional , dropout = dropout ) self . dropout = nn . Dropout ( dropout ) self . directions = 2 if bidirectional else 1 self . fc = nn . Linear ( hidden_dim * self . directions , output_dim ) def forward ( self , x ): embedded = self . dropout ( self . embedding ( x )) output , ( hidden , cell ) = self . rnn ( embedded ) hidden = rearrange ( hidden , \"(layer dir) b c -> layer b (dir c)\" , dir = self . directions ) ## take the fina layer's hidden return self . fc ( self . dropout ( hidden [ - 1 ]))","title":"Improving RNN"},{"location":"blogs/deep_learning/einops2/#channel-shuffle-from-shufflenet","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def channel_shuffle_old ( x , groups ): b , c , h , w = x . data . size () channels_per_group = c // groups ## reshape x = x . view ( b , groups , channels_per_group , h , w ) ## transpose ## - contiguous() is required if transpose() is used before view() ## See https://github.com/pytorch/pytorch/issues/764 x = x . transpose ( 1 , 2 ) . contiguous () ## flatten x = x . view ( b , - 1 , h , w ) return x Using EINOPS 1 2 def channel_shuffle_new ( x , groups ): return rearrange ( x , \"b (c1 c2) h w -> b (c2 c1) h w\" , c1 = groups )","title":"Channel Shuffle (from ShuffleNet)"},{"location":"blogs/deep_learning/einops2/#shufflenet","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 from collections import OrderedDict def channel_shuffle ( x , groups ): b , c , h , w = x . data . size () channels_per_group = c // groups ## reshape x = x . view ( b , groups , channels_per_group , h , w ) ## transpose ## - contiguous() is required if transpose() is used before view() x = x . transpose ( 1 , 2 ) . contiguous () x = x . view ( b , - 1 , h , w ) return x class ShuffleUnitOLD ( nn . Module ): def __init__ ( self , in_channels , out_channels , groups = 3 , grouped_conv = True , combine = \"add\" , ): super ( ShuffleUnitOLD , self ) . __init__ () self . in_channels = in_channels self . out_channels = out_channels self . grouped_conv = grouped_conv self . combine = combine self . groups = groups self . bottleneck_channels = self . out_channels // 4 ## define the type of ShuffleUnit if self . combine == \"add\" : ## shuffleUnit fig-2b self . depthwise_stride = 1 self . _combine_func = self . _add elif self . combine == \"concat\" : ## ShuffleUnit fig-2c self . depthwise_stride = 2 self . _combine_func = self . _concat ## ensure output of the concat has the same channels ## as the original input channels self . out_channels -= self . in_channels else : raise ValueError ( f \"Cannot combine tensors with { self . combine } . \\n \" f \"Only 'add' & 'concat' supported.\" ) ## Use a 1x1 grouped or non-grouped convolution to reduce input channels ## to bottleneck channels, as in ResNet bottleneck module. ## NOTE: do not use group convolution for the first conv1x1 in stage-2 self . first_1x1_groups = self . groups if grouped_conv else 1 self . g_conv_1x1_compress = self . _make_grouped_conv1x1 ( self . in_channels , self . bottleneck_channels , self . first_1x1_groups , batch_norm = True , relu = True , ) ## 3x3 depthwise convolution followed by batch normalization self . depthwise_conv3x3 = conv3x3 ( self . bottleneck_channels , self . bottleneck_channels , stride = self . depthwise_stride , groups = self . bottleneck_channels ) self . bn_after_depthwise = nn . BatchNordm2d ( self . bottleneck_channels ) ## use 1x1 grouped convolution to expand from bottleneck_channels to out_channels self . g_conv_conv_1x1_expand = self . _make_grouped_conv1x1 ( self . bottleneck_channels , self . out_channels , self . groups , batch_norm = True , relu = False ) @staticmethod def _add ( x , out ): ## residual connection return x + out @staticmethod def _concat ( x , out ): ## concat along channel dim return torch . cat (( x , out ), 1 ) def _make_grouped_conv1x1 ( self , in_channels , out_channels , groups , batch_norm = True , relu = False ): modules = OrderedDict () conv = conv1x1 ( in_channels , out_channels , groups = groups ) modules [ 'conv1x1' ] = conv if batch_norm : modules [ 'batch_norm' ] = nn . BatchNorm2d ( out_channels ) if relu : modules [ 'relu' ] = nn . ReLU () if len ( modules ) > 1 : return nn . Sequential ( modules ) else : return conv def forward ( self , x ): ## save for combining later with output residual = x if self . combine == \"concat\" : residual = F . avg_pool2d ( residual , kernel_size = 3 , stride = 2 , padding = 1 ) out = self . g_con_1x1_compress ( x ) out = channel_shuffle ( out , self . groups ) out = self . depthwise_conv3x3 ( out ) out = self . bn_after_depthwise ( out ) out = self . g_conv_1x1_expand ( out ) out = self . _combine_func ( residual , out ) return F . relu ( out ) Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class ShuffleUnitNEW ( nn . Module ): def __init__ ( self , in_channels , out_channels , groups = 3 , grouped_conv = True , combine = \"add\" ): super () . __init__ () first_1x1_groups = groups if grouped_conv else 1 bottleneck_channels = out_channels // 4 self . combine = combine if combine == \"add\" : ## ShuffleUnit fig-2b self . left = Rearrange ( \"...->...\" ) ## identity depthwise_stride = 1 else : ## ShuffleUnit fig-2c self . left = nn . AvgPool2d ( kernel_size = 3 , stride = 2 , padding = 1 ) depthwise_stride = 2 ## ensure output of concat has the same channels as the original output channels out_channels -= in_channels assert out_channels > 0 self . right = nn . Sequential ( ## use a 1x1grouped or non-grouped convolution to reduce ## input channels to bottleneck channels as in ResNet bottleneck module. conv1x1 ( in_channels , bottleneck_channels , groups = first_1x1_groups ), nn . BatchNorm2d ( bottleneck_channels ), nn . ReLU ( inplace = True ), ## channel shuffle Rearrange ( \"b (c1 c2) h w -> b (c2 c1) h w\" , c1 = groups ), ## 3x3 depthwise convolution followed by BatchNorm conv3x3 ( bottleneck_channels , bottleneck_channels , stride = depthwise_stride , groups = bottleneck_channels ), nn . BatchNorm2d ( bottleneck_channels ), ## Use 1x1 grouped convolution to expand from bottleneck_channels to output_channels conv1x1 ( bottleneck_channels , out_channels , groups = groups ), nn . BatchNorm2d ( out_channels ), ) def forward ( self , x ): if self . combine == \"add\" : combined = self . left ( x ) + self . right ( x ) else : combined = torch . cat ([ self . left ( x ), self . right ( x )], dim = 1 ) return F . relu ( combined , inplace = True ) Improvements Rewriting the code helped to identify the following: There is no sense in doing reshuffling and not using groups in the first convolution (indeed in the paper it is not so). However , the result is an equivalent model . It is strage that the first convolution may not be grouped, while the last convolution is always grouped. ( and th's different from the paper ) Also, There is an identity layer for pyTorch introduced here. The last thing to do is to get rid of conv1x1 and conv3x3 (those are not better than the standard implementation)","title":"ShuffleNet"},{"location":"blogs/deep_learning/einops2/#resnet","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class ResNetOLD ( nn . Module ): def __init__ ( self , block , layers , num_classes = 1000 ): self . inplanes = 64 super ( ResNetOLD , self ) . __init__ () self . conv1 = nn . Conv2d ( 3 , 64 , kernel_size = 7 , stride = 2 , padding = 3 , bias = False ) self . bn1 = nn . BatchNorm2d ( 64 ) self . relu = nn . ReLU ( inplace = True ) self . maxpool = nn . MaaxPool2d ( kernel_size = 3 , stride = 2 , paadding = 1 ) self . layer1 = self . _make_layer ( block , 64 , layers [ 0 ]) self . layer2 = self . _make_layer ( block , 128 , layers [ 1 ], stride = 2 ) self . layer3 = self . _make_layer ( block , 256 , layers [ 2 ], stride = 2 ) self . layer4 = self . _make_layer ( block , 512 , layers [ 3 ], stride = 2 ) self . avgpool = nn . AvgPool2d ( 7 , stride = 1 ) self . fc = nn . Linear ( 512 * block . expansion , num_classes ) for m in self . modules : if isinstance ( m , nn . Conv2d ): n = m . kernel_size [ 0 ] * m . kernel_size [ 1 ] * m . out_channels m . weight . data . normal_ ( 0 , math . sqrt ( 2. / n )) elif isinstance ( m , nn . BatchNord2d ): m . weight . data . fill_ ( 1 ) m . bias . data . zero_ () def _make_layer ( self , block , planes , blocks , stride = 1 ): downsample = None if stride != 1 or self . inplanes != planes * block . expansion : downsample = nn . Sequential ( nn . Conv2d ( self . inplanes , planes * block . expansion , kernel_size = 1 , stride = stride , bias = False ), nn . BatchNorm2d ( planes * block . expansion ), ) layers = [] layers . append ( block ( self . inplanes , planes , stride , downsample )) self . inplanes = planes * block . expansion for i in range ( 1 , blocks ): layers . append ( block ( self . inplanes , planes )) return nn . Sequential ( * layers ) def forward ( self , x ): x = self . conv1 ( x ) x = self . bn1 ( x ) x = self . relu ( x ) x = self . maxpool ( x ) x = self . layer1 ( x ) x = self . layer2 ( x ) x = self . layer3 ( x ) x = self . layer4 ( x ) x = self . avgpool ( x ) x = x . view ( x . size ( 0 ), - 1 ) x = self . fc ( x ) return x Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def make_layer ( inplanes , planes , block , n_blocks , stride = 1 ): downsample = None if stride != 1 or inplanes != planes * block . expansion : ## output-size won't match input-size; so adjust the residual downsample = nn . Sequential ( nn . Conv2d ( inplanes , planes * block . expansion , kernel_size = 1 , stride = stride , bias = False ), nn . BatchNorm2d ( planes * block . expansion ), ) return nn . Sequential ( block ( inplanes , planes , stride , downsample ), * [ block ( planes * block . expansion , planes ) for _ in range ( 1 , n_blocks )] ) def ResNetNEW ( block , layers , num_classes = 1000 ): e = block . expansion resnet = nn . Sequential ( Rearrange ( \"b c h w -> b c h w\" , c = 3 , h = 224 , w = 224 ), nn . Conv2d ( 3 , 64 , kernel_size = 7 , stride = 2 , padding = 3 , bias = False ), nn . BatchNorm2d ( 64 ), nn . ReLU ( inplace = True ), nn . MaxPool2d ( kernel_size = 3 , stride = 2 , padding = 1 ), make_layer ( 64 , 64 , block , layers [ 0 ], stride = 1 ), make_layer ( 64 * e , 128 , block , layers [ 1 ], stride = 2 ), make_layer ( 128 * e , 256 , block , layers [ 2 ], stride = 2 ), make_layer ( 256 * e , 512 , block , layers [ 3 ], stride = 2 ), ## Combined AvgPool & view in one single operation Reduce ( \"b c h w -> b c\" , \"mean\" ), n . Linear ( 512 * e , num_classes ), ) ## initialization for m in resnet . modules (): if isinstance ( m , nn . Conv2d ): n = m . kernel_size [ 0 ] * m . kernel_size [ 1 ] * m . out_channels m . weight . data . normal_ ( 0 , math . sqrt ( 2. / n )) elif isinstance ( m , nn . BatchNorm2d ): m . weight . data . fill_ ( 1. ) m . bias . data . zero_ () return resnet","title":"ResNet"},{"location":"blogs/deep_learning/einops2/#fasttext","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 class FastTextOLD ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , output_dim ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . fc = nn . Linear ( embedding_dim , output_dim ) def forward ( self , x ): embedded = self . embedding ( x ) embedded = embedded . permute ( 1 , 0 , 2 ) pooled = F . avg_pool2d ( embedded , ( embedded . shape [ 1 ], 1 )) . squeeze ( 1 ) return self . fc ( pooled ) Using EINOPS 1 2 3 4 5 6 7 8 def FastTextNEW ( vocab_size , embedding_dim , output_dim ): return nn . Sequential ( Rearrange ( \"t b -> t b\" ), nn . Embedding ( vocab_size , embedding_dim ), Reduce ( \"t b c -> b c\" , \"mean\" ), nn . Linear ( embedding_dim , output_dim ), Rearrange ( \"b c -> b c\" ), ) Here, the first and last operations (highlighted) do nothing and can be removed. But, were added to explicitly added to show expected input and output shape This also gives us the flexibility of changing interface by editing a single line. Should you need to accept inputs of shape (b, t) we just need to change the line to Rearrange(\"b t -> t b\")","title":"FastText"},{"location":"blogs/deep_learning/einops2/#cnns-for-text-classification","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class CNNold ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , n_filters , filter_sizes , output_dim , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . conv_0 = nn . Conv2d ( in_channels = 1 , out_channels = n_filters , kernel_size = ( filter_sizes [ 0 ], embedding_dim )) self . conv_1 = nn . Conv2d ( in_channels = 1 , out_channels = n_filters , kernel_size = ( filter_sizes [ 1 ], embedding_dim )) self . conv_2 = nn . Conv2d ( in_channels = 1 , out_channels = n_filters , kernel_size = ( filter_sizes [ 2 ], embedding_dim )) self . fc = nn . Linear ( len ( filter_sizes ) * n_filters , output_dim ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): x = x . permute ( 1 , 0 ) embedded = self . embedding ( x ) embedded = embedded . unsqueeze ( dim = 1 ) conved_0 = F . relu ( self . conv_0 ( embedded ) . squeeze ( dim = 3 )) conved_1 = F . relu ( self . conv_1 ( embedded ) . squeeze ( dim = 3 )) conved_2 = F . relu ( self . conv_2 ( embedded ) . squeeze ( dim = 3 )) pooled_0 = F . max_pool1d ( conved_0 , conved_0 . shape [ 2 ]) . squeeze ( dim = 2 ) pooled_1 = F . max_pool1d ( conved_1 , conved_1 . shape [ 2 ]) . squeeze ( dim = 2 ) pooled_2 = F . max_pool1d ( conved_2 , conved_2 . shape [ 2 ]) . squeeze ( dim = 2 ) cat = self . dropout ( torch . cat (( pooled_0 , pooled_1 , pooled_2 ), dim = 1 )) return self . fc ( cat ) Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class CNNnew ( nn . Module ): def __init__ ( self , vocab_size , embedding_dim , n_filters , filter_sizes , output_dim , dropout ): super () . __init__ () self . embedding = nn . Embedding ( vocab_size , embedding_dim ) self . convs = nn . ModuleList ([ nn . Conv1d ( embedding_dim , n_filters , kernel_size = size ) for size in filter_sizes ]) self . fc = nn . Linear ( len ( filter_sizes ) * n_filters , output_dim ) self . dropout = nn . Dropout ( dropout ) def forward ( self , x ): x = rearrange ( x , \"t b -> t b\" ) emb = rearrange ( self . embedding ( x ), \"t b c -> b c t\" ) pooled = [ reduce ( conv ( emb ), \"b c t -> b c\" ) for conv in self . convs ] concatenated = rearrange ( pooled , \"filter b c -> b (filter c)\" ) return self . fc ( self . dropout ( F . relu ( concatenated ))) Discussion Original code misuses nn.Conv2d while nn.Conv1d is the right choice. New code can work with any number of filter_sizes and won't fail. First line in the new code does nothing, but was just added for simplicity & clarity of shapes.","title":"CNNs for text classification"},{"location":"blogs/deep_learning/einops2/#highway-convolutions","text":"ONLY PyTorch 1 2 3 4 5 6 class HighwayConv1dOLD ( nn . Conv1d ): def forward ( self , inputs ): L = super ( HIghwayCon1dOLD , self ) . forward ( inputs ) H1 , H2 = torch . chunk ( L , 2 , dim = 1 ) ## chunk at the feature dimension torch . sigmoid_ ( H1 ) return H1 * H2 + ( 1.0 - H1 ) * inputs Using EINOPS 1 2 3 4 5 6 class HighwayConv1dNEW ( nn . Conv1d ): def forward ( self , inputs ): L = super () . forward ( inputs ) H1 , H2 = rearrange ( L , \"b (split c) t -> split b c t\" , split = 2 ) torch . sigmoid_ ( H1 ) return H1 * H2 + ( 1.0 - H1 ) * inputs","title":"Highway Convolutions"},{"location":"blogs/deep_learning/einops2/#simple-attention","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 class Attention ( nn . Module ): def __init__ ( self ): super ( Attention , self ) . __init__ () def forward ( self , K , Q , V ): A = torch . bmm ( K . transpose (( 1 , 2 ), Q ) / np . sqrt ( Q . shape [ 1 ]) A = F . softmax ( A , dim = 1 ) R = torch . bmm ( V , A ) return torch . cat (( R , Q ), dim = 1 ) Using EINOPS 1 2 3 4 5 6 def attention ( K , Q , V ): _ , n_channels , _ = K . shape A = torch . einsum ( \"bct,bcl->btl\" , [ K , Q ]) A = F . softmax ( A * n_channels ** ( - 0.5 ), dim = 1 ) R = torch . einsum ( \"bct,btl->bcl\" , [ V , A ]) return torch . cat (( R , Q ), dim = 1 )","title":"Simple Attention"},{"location":"blogs/deep_learning/einops2/#multi-head-attention","text":"ONLY PyTorch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ScaledDotProductAttention ( nn . Module ): \"\"\"Scaled Dot Product Attention\"\"\" def __init__ ( self , temperature , attn_dropout = 0.1 ): super () . __init__ () self . temperature = temperature self . dropout = nn . Dropout ( attn_dropout ) self . softmax = nn . Softmax ( dim = 2 ) def forward ( self , q , k , v , mask = None ): attn = torch . bmm ( q , k . transpose ( 1 , 2 )) attn /= self . temperature if mask is not None : attn = attn . masked_fill ( mask , - np . inf ) attn = self . softmax ( attn ) attn = self . dropout ( attn ) output = torch . bmm ( attn , v ) return output , attn class MultiHeadAttentionOLD ( nn . Module ): \"\"\"Multi Head Attention Module\"\"\" def __init__ ( self , n_head , d_model , d_k , d_v , dropout = 0.1 ): super () . __init__ () self . d_k = d_k self . d_v = d_v self . n_head = n_head self . w_qs = nn . Linear ( d_model , n_head * d_k ) self . w_ks = nn . Linear ( d_model , n_head * d_k ) self . w_vs = nn . Linear ( d_model , n_head * d_v ) nn . init . normal_ ( self . w_qs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_k ))) nn . init . normal_ ( self . w_ks . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_k ))) nn . init . normal_ ( self . w_vs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_v ))) self . attention = ScaledDotProductAttention ( temperature = d_k ** 0.5 ) self . layer_norm = nn . LayerNorm ( d_model ) self . fc = nn . Linear ( n_head * d_v , d_model ) nn . init . xavier_normal_ ( self . fc . weight ) self . dropout = nn . Dropout ( dropout ) def forward ( self , q , k , v , mask = None ): d_k = self . d_k d_v = self . d_v n_head = self . n_head sz_b , len_q , _ = q . size () sz_b , len_k , _ = k . size () sz_b , len_v , _ = v . size () residual = q q = self . w_qs ( q ) . view ( sz_b , len_q , n_head , d_k ) k = self . w_ks ( k ) . view ( sz_b , len_k , n_head , d_k ) v = self . w_vs ( v ) . view ( sz_b , len_v , n_head , d_v ) q = q . permute ( 2 , 0 , 1 , 3 ) . contiguous () . view ( - 1 , len_q , d_k ) ## (n*b, len_q, d_k) k = k . permute ( 2 , 0 , 1 , 3 ) . contiguous () . view ( - 1 , len_k , d_k ) ## (n*b, len_k, d_k) v = v . permute ( 2 , 0 , 1 , 3 ) . contiguous () . view ( - 1 , len_v , d_v ) ## (n*b, len_v, d_v) mask = mask . repeat ( n_head , 1 , 1 ) ## (n*b, ...) output , attn = self . attention ( q , k , v , mask = mask ) output = output . view ( n_head , sz_b , len_q , d_v ) output = output . permute ( 1 , 2 , 0 , 3 ) . contiguous () . view ( sz_b , len_q , - 1 ) ## (b, len_q, n*d_v) output = self . dropout ( self . fc ( output )) output = self . layer_norm ( output + residual ) return output , attn Using EINOPS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class MultiHeadAttentionNEW ( nn . Module ): def __init__ ( self , n_heads , d_model , d_k , d_v , dropout = 0.1 ): super () . __init__ () self . n_heads = n_heads self . w_qs = nn . Linear ( d_model , n_heads * d_k ) self . w_ks = nn . Linear ( d_model , n_heads * d_k ) self . w_vs = nn . Linear ( d_model , n_heads * d_v ) nn . init . normal_ ( self . w_qs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d - model + d_k ))) nn . init . normal_ ( self . w_ks . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_k ))) nn . init . normal_ ( self . w_vs . weight , mean = 0 , std = np . sqrt ( 2.0 / ( d_model + d_v ))) self . fc = nn . Linear ( n_heads * d_v , d_model ) nn . init . xavier_normal_ ( self . fc . weight ) self . dropout = nn . Dropout ( dropout ) self . layer_norm = nn . LayerNorm ( d_model ) def forward ( self , q , k , v , mask = None ): residual = q","title":"Multi-head Attention"},{"location":"blogs/deep_learning/einops2/#references","text":"http://einops.rocks/pytorch-examples.html \u21a9 https://github.com/arogozhnikov/einops \u21a9","title":"References"},{"location":"blogs/lightning/about/","text":"","title":"About"},{"location":"blogs/lightning/tut_1/","text":"","title":"Tutorial-1"},{"location":"blogs/lightning/tut_2/","text":"","title":"Tutorial-2"},{"location":"blogs/lightning/tut_3/","text":"","title":"Tutorial-3"},{"location":"blogs/lightning/tut_4/","text":"","title":"Tutorial-4"},{"location":"blogs/lightning/tut_5/","text":"","title":"Tutorial-5"},{"location":"blogs/physics/blog_01282021/","text":"Electromagnetic Spectrum, properties of material medium & its effects. Electromagnetic Spectrum Electromagnetic Spectrum The different parts of the electromagnetic spectrum have very different effects upon interaction with matter. Starting with low frequency radio waves , the human body is quite transparent ( you can listen to your portable radio inside your home since the waves pass freely through the walls of your house and even through the person beside you! ) As you move upward through microwaves and infrared to visible light , you absorb more and more strongly. In the lower ultraviolet range, all the UV from the sun is absorbed in a thin outer layer of your skin. As you move further up into the x-ray region of the spectrum, you become transparent again, because most of the mechanisms for absorption are gone. You then absorb only a small fraction of the radiation, but that absorption involves the more violent ionization events . Each portion of the electromagnetic spectrum has quantum energies appropriate for the excitation of certain types of physical processes. The energy levels for all physical processes at the atomic and molecular levels are quantized, and if there are no available quantized energy levels with spacings which match the quantum energy of the incident radiation, then the material will be transparent to that radiation , and it will pass through. If electromagnetic energy is absorbed, but cannot eject electrons from the atoms of the material, then it is classified as non-ionizing radiation, and will typically just heat the material. Microwaves Microwaves The quantum energy of microwave photons is in the range 0.00001 to 0.001 eV which is in the range of energies separating the quantum states of molecular rotation and torsion . The interaction of microwaves with matter other than metallic conductors ** will be to rotate molecules and produce heat as result of that molecular motion. Conductors will strongly absorb microwaves and any lower frequencies because they will cause electric currents which will heat the material. Most matter, including the human body, is largely transparent to microwaves. High intensity microwaves, as in a microwave oven where they pass back and forth through the food millions of times, will heat the material by producing molecular rotations and torsions. Since the quantum energies are a million times lower than those of x-rays, they cannot produce ionization and the characteristic types of radiation damage associated with ionizing radiation. Infrared Infrared The quantum energy of infrared photons is in the range 0.001 to 1.7 eV which is in the range of energies separating the quantum states of molecular vibrations. Infrared is absorbed more strongly than microwaves, but less strongly than visible light. The result of infrared absorption is heating of the tissue since it increases molecular vibrational activity. Infrared radiation does penetrate the skin further than visible light and can thus be used for photographic imaging of subcutaneous blood vessels. Visible Light Visible Light The primary mechanism for the absorption of visible light photons is the elevation of electrons to higher energy levels. There are many available states, so visible light is absorbed strongly. With a strong light source, red light can be transmitted through the hand or a fold of skin, showing that the red end of the spectrum is not absorbed as strongly as the violet end. While exposure to visible light causes heating, it does not cause ionization with its risks. You may be heated by the sun through a car windshield, but you will not be sunburned - that is an effect of the higher frequency uv part of sunlight which is blocked by the glass of the windshield. Ultraviolet Ultraviolet The near ultraviolet is absorbed very strongly in the surface layer of the skin by electron transitions . As you go to higher energies, the ionization energies for many molecules are reached and the more dangerous photoionization processes take place. Sunburn is primarily an effect of uv, and ionization produces the risk of skin cancer . The ozone layer in the upper atmosphere is important for human health because it absorbs most of the harmful ultraviolet radiation from the sun before it reaches the surface. The higher frequencies in the ultraviolet are ionizing radiation and can produce harmful physiological effects ranging from sunburn to skin cancer . Health concerns for UV exposure are mostly for the range 290-330 nm in wavelength, the range called UVB . According to Scotto, et al , the most effective biological wavelength for producing skin burns is 297 nm . Their research indicates that the biological effects increase logarithmically within the UVB range, with 330 nm being only 0.1% as effective as 297 nm for biological effects. So it is clearly important to control exposure to UVB. X-ray X-men First Header Second Header Since the quantum energies of x-ray photons are much too high to be absorbed in electron transitions between states for most atoms, they can interact with an electron only by knocking it completely out of the atom. That is, all x-rays are classified as ionizing radiation . This can occur by giving all of the energy to an electron ( photoionization ) or by giving part of the energy to the electron and the remainder to a lower energy photon ( Compton Scattering ). At sufficiently high energies, the x-ray photon can create an electron positron pair. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 28/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References: http://hyperphysics.phy-astr.gsu.edu/hbase/mod3.html \u21a9 http://hyperphysics.phy-astr.gsu.edu/hbase/mod2.html \u21a9 https://physics.stackexchange.com/questions/300551/how-can-wifi-penetrate-through-walls-when-visible-light-cant \u21a9 https://physics.stackexchange.com/questions/1836/why-is-air-invisible \u21a9 https://physics.stackexchange.com/questions/7437/why-is-glass-transparent \u21a9","title":"Electromagnetic Spectrum, properties of material medium & its effects"},{"location":"blogs/physics/blog_01282021/#electromagnetic-spectrum-properties-of-material-medium-its-effects","text":"","title":"Electromagnetic Spectrum, properties of material medium &amp; its effects."},{"location":"blogs/physics/blog_01282021/#electromagnetic-spectrum","text":"Electromagnetic Spectrum The different parts of the electromagnetic spectrum have very different effects upon interaction with matter. Starting with low frequency radio waves , the human body is quite transparent ( you can listen to your portable radio inside your home since the waves pass freely through the walls of your house and even through the person beside you! ) As you move upward through microwaves and infrared to visible light , you absorb more and more strongly. In the lower ultraviolet range, all the UV from the sun is absorbed in a thin outer layer of your skin. As you move further up into the x-ray region of the spectrum, you become transparent again, because most of the mechanisms for absorption are gone. You then absorb only a small fraction of the radiation, but that absorption involves the more violent ionization events . Each portion of the electromagnetic spectrum has quantum energies appropriate for the excitation of certain types of physical processes. The energy levels for all physical processes at the atomic and molecular levels are quantized, and if there are no available quantized energy levels with spacings which match the quantum energy of the incident radiation, then the material will be transparent to that radiation , and it will pass through. If electromagnetic energy is absorbed, but cannot eject electrons from the atoms of the material, then it is classified as non-ionizing radiation, and will typically just heat the material.","title":"Electromagnetic Spectrum"},{"location":"blogs/physics/blog_01282021/#microwaves","text":"Microwaves The quantum energy of microwave photons is in the range 0.00001 to 0.001 eV which is in the range of energies separating the quantum states of molecular rotation and torsion . The interaction of microwaves with matter other than metallic conductors ** will be to rotate molecules and produce heat as result of that molecular motion. Conductors will strongly absorb microwaves and any lower frequencies because they will cause electric currents which will heat the material. Most matter, including the human body, is largely transparent to microwaves. High intensity microwaves, as in a microwave oven where they pass back and forth through the food millions of times, will heat the material by producing molecular rotations and torsions. Since the quantum energies are a million times lower than those of x-rays, they cannot produce ionization and the characteristic types of radiation damage associated with ionizing radiation.","title":"Microwaves"},{"location":"blogs/physics/blog_01282021/#infrared","text":"Infrared The quantum energy of infrared photons is in the range 0.001 to 1.7 eV which is in the range of energies separating the quantum states of molecular vibrations. Infrared is absorbed more strongly than microwaves, but less strongly than visible light. The result of infrared absorption is heating of the tissue since it increases molecular vibrational activity. Infrared radiation does penetrate the skin further than visible light and can thus be used for photographic imaging of subcutaneous blood vessels.","title":"Infrared"},{"location":"blogs/physics/blog_01282021/#visible-light","text":"Visible Light The primary mechanism for the absorption of visible light photons is the elevation of electrons to higher energy levels. There are many available states, so visible light is absorbed strongly. With a strong light source, red light can be transmitted through the hand or a fold of skin, showing that the red end of the spectrum is not absorbed as strongly as the violet end. While exposure to visible light causes heating, it does not cause ionization with its risks. You may be heated by the sun through a car windshield, but you will not be sunburned - that is an effect of the higher frequency uv part of sunlight which is blocked by the glass of the windshield.","title":"Visible Light"},{"location":"blogs/physics/blog_01282021/#ultraviolet","text":"Ultraviolet The near ultraviolet is absorbed very strongly in the surface layer of the skin by electron transitions . As you go to higher energies, the ionization energies for many molecules are reached and the more dangerous photoionization processes take place. Sunburn is primarily an effect of uv, and ionization produces the risk of skin cancer . The ozone layer in the upper atmosphere is important for human health because it absorbs most of the harmful ultraviolet radiation from the sun before it reaches the surface. The higher frequencies in the ultraviolet are ionizing radiation and can produce harmful physiological effects ranging from sunburn to skin cancer . Health concerns for UV exposure are mostly for the range 290-330 nm in wavelength, the range called UVB . According to Scotto, et al , the most effective biological wavelength for producing skin burns is 297 nm . Their research indicates that the biological effects increase logarithmically within the UVB range, with 330 nm being only 0.1% as effective as 297 nm for biological effects. So it is clearly important to control exposure to UVB.","title":"Ultraviolet"},{"location":"blogs/physics/blog_01282021/#x-ray","text":"X-men First Header Second Header Since the quantum energies of x-ray photons are much too high to be absorbed in electron transitions between states for most atoms, they can interact with an electron only by knocking it completely out of the atom. That is, all x-rays are classified as ionizing radiation . This can occur by giving all of the energy to an electron ( photoionization ) or by giving part of the energy to the electron and the remainder to a lower energy photon ( Compton Scattering ). At sufficiently high energies, the x-ray photon can create an electron positron pair. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 28/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"X-ray"},{"location":"blogs/physics/blog_01282021/#references","text":"http://hyperphysics.phy-astr.gsu.edu/hbase/mod3.html \u21a9 http://hyperphysics.phy-astr.gsu.edu/hbase/mod2.html \u21a9 https://physics.stackexchange.com/questions/300551/how-can-wifi-penetrate-through-walls-when-visible-light-cant \u21a9 https://physics.stackexchange.com/questions/1836/why-is-air-invisible \u21a9 https://physics.stackexchange.com/questions/7437/why-is-glass-transparent \u21a9","title":"References:"},{"location":"blogs/prob/intro/","text":"Probablity Theory A key concept in the field of pattern recognition is that of uncertainity . It arrises through: noise on measurements finite size of datasets. Probability theory provides a consistent framework for the quantification and manipulation of uncertainity and forms one of the central foundations of Pattern Recognition. When combined with Decision Theory , it allows us to make optimal predictions given all the informtion available to us, even though that information may be incomplete or ambiguous. Example: Red/Blue boxes The setup Imagine we have two boxes red_box and blue_box . Each box contains different number of fruits oranges and apples . 1 2 3 4 5 6 red_box: - apples: 2 - oranges: 6 blue_box: - apples: 3 - oranges: 1 The Experiment Now, we do the following steps: Select a box : Randomly pick one of the boxes (either red_box or blue_box ) Pick a fruit : Then, randomly select an item of fruit for the box. Replace the fruit : Having observed the type of the picked fruit ( apple or orange ), now, replace it in the box from which it came. Repeat steps 1-to-3 multiple times. The Pre-conditions / Assumptions Now, let's suppose in doing the above experiment, we pick the red_box 40% of the times and the blue_box 60% of the times. Also, assume that that when we remove an item of fruit from a box, we are equally likely to select any of the pices of fruits in the box. The Theory In this experiemnt: the identity of the box to be chosen is a random variable \\(B\\) which can take two possible values r and b (corresponding to red or blue boxes). Similarly, the identity of fruit is also a random variable \\(F\\) and it can take either of the values a and o (corresponding to apple an dorange respectively). Definition: The Probability of an event is defined as the fraction of times, that event occurs out of the total number of trials (in the limit that the total number of trials goes to infinity). All probabilities must lie in the interval [0, 1] Thus , the probability of selecting the red_box is \\(4/10\\) and that of the blue_box is \\(6/10\\) . \\[ p(B=r) = 4/10 \\] \\[ p(B=b) = 6/10 \\]","title":"Introduction"},{"location":"blogs/prob/intro/#probablity-theory","text":"A key concept in the field of pattern recognition is that of uncertainity . It arrises through: noise on measurements finite size of datasets. Probability theory provides a consistent framework for the quantification and manipulation of uncertainity and forms one of the central foundations of Pattern Recognition. When combined with Decision Theory , it allows us to make optimal predictions given all the informtion available to us, even though that information may be incomplete or ambiguous.","title":"Probablity Theory"},{"location":"blogs/prob/intro/#example-redblue-boxes","text":"","title":"Example: Red/Blue boxes"},{"location":"blogs/prob/intro/#the-setup","text":"Imagine we have two boxes red_box and blue_box . Each box contains different number of fruits oranges and apples . 1 2 3 4 5 6 red_box: - apples: 2 - oranges: 6 blue_box: - apples: 3 - oranges: 1","title":"The setup"},{"location":"blogs/prob/intro/#the-experiment","text":"Now, we do the following steps: Select a box : Randomly pick one of the boxes (either red_box or blue_box ) Pick a fruit : Then, randomly select an item of fruit for the box. Replace the fruit : Having observed the type of the picked fruit ( apple or orange ), now, replace it in the box from which it came. Repeat steps 1-to-3 multiple times.","title":"The Experiment"},{"location":"blogs/prob/intro/#the-pre-conditions-assumptions","text":"Now, let's suppose in doing the above experiment, we pick the red_box 40% of the times and the blue_box 60% of the times. Also, assume that that when we remove an item of fruit from a box, we are equally likely to select any of the pices of fruits in the box.","title":"The Pre-conditions / Assumptions"},{"location":"blogs/prob/intro/#the-theory","text":"In this experiemnt: the identity of the box to be chosen is a random variable \\(B\\) which can take two possible values r and b (corresponding to red or blue boxes). Similarly, the identity of fruit is also a random variable \\(F\\) and it can take either of the values a and o (corresponding to apple an dorange respectively). Definition: The Probability of an event is defined as the fraction of times, that event occurs out of the total number of trials (in the limit that the total number of trials goes to infinity). All probabilities must lie in the interval [0, 1] Thus , the probability of selecting the red_box is \\(4/10\\) and that of the blue_box is \\(6/10\\) . \\[ p(B=r) = 4/10 \\] \\[ p(B=b) = 6/10 \\]","title":"The Theory"},{"location":"gists/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"gists/python_snippets/","text":"Python Snippets 1: MappingProxyType Immutable Mappings The mapping types provided by the standard library are all mutable; but you may need to gurantee that a user cannot change a mapping by mistake. Since Python 3.3 the types module provides a wrapper class MappingProxyType which, given a mapping returns a mappingproxy instance that is read-only but a dynamic-view of the original mapping. This means that the original mapping can be seen through mappingproxy but changes cannot be made through it. 1 2 3 4 5 6 7 8 9 10 11 12 13 from types import MappingProxyType d = { 1 : \"A\" } d_proxy = MappingProxyType ( d ) ## creating a proxy for the original dict d ## d_proxy = {1:\"A\"} print ( d_proxy [ 1 ]) ## \"A\" d_proxy [ 2 ] = \"X\" ## TypeERROR. mappingproxy does not support item assignment d [ 2 ] = \"B\" ## OKAY. The original dictionary is still mutable print ( d_proxy ) ## The proxy has a dynamic view of the original dict. ## So, it refelects the change ## {1:\"A\", 2:\"B\"} 2: Set operators Set Operators 1 2 3 4 5 6 7 8 9 10 11 **operator: method: desciption:** `s.isdisjoint(z)` `s` and `z` are disjoint (i.e. have no elements in common) `e in s` `s.__contains__(e)` element `e` is a subset of `s` set `s <= z` `s.__le__(z)` `s` is a **subset** of `z` set `s.issubset(it)` `s` is a **subset** of the set built from the iterable `it` `s < z` `s.__lt__(z)` `s` is a **PROPER-subset** of `z` set `s >= z` `s.__ge__(z)` `s` is a **superset** of `z` set `s.issuperset(it)` `s` is a **superset** of the set built from iterable `it` `s > z` `s.__gt__(z)` `s` is a **PROPER-superset** of the set `z` 3: set v/s frozenset Set v/s Frozenset 1 2 3 4 5 6 7 8 9 **operator: set: frozenset: description:** `s.add(e)` \u2705 Add element `e` to set `s` `s.clear()` \u2705 Remove all elements from set `s` `s.copy()` \u2705 \u2705 Shallow copy of set/frozenset `s` `s.discard(e)` \u2705 Remove element `e` from set `s` IF it is present `s.__iter__()` \u2705 \u2705 Get iterator over set/frozenset `s` `s.__len__()` \u2705 \u2705 `len(s)` `s.pop()` \u2705 Remove and return an element from `s` ; raising `keyError` if `s` is empty `s.remove(e)` \u2705 Remive element `e` from set `s` ; raise `KeyError` if `e not in s`","title":"\ud83d\udc0dPython_Snippets"},{"location":"gists/python_snippets/#python-snippets","text":"","title":"Python Snippets"},{"location":"gists/python_snippets/#1-mappingproxytype","text":"Immutable Mappings The mapping types provided by the standard library are all mutable; but you may need to gurantee that a user cannot change a mapping by mistake. Since Python 3.3 the types module provides a wrapper class MappingProxyType which, given a mapping returns a mappingproxy instance that is read-only but a dynamic-view of the original mapping. This means that the original mapping can be seen through mappingproxy but changes cannot be made through it. 1 2 3 4 5 6 7 8 9 10 11 12 13 from types import MappingProxyType d = { 1 : \"A\" } d_proxy = MappingProxyType ( d ) ## creating a proxy for the original dict d ## d_proxy = {1:\"A\"} print ( d_proxy [ 1 ]) ## \"A\" d_proxy [ 2 ] = \"X\" ## TypeERROR. mappingproxy does not support item assignment d [ 2 ] = \"B\" ## OKAY. The original dictionary is still mutable print ( d_proxy ) ## The proxy has a dynamic view of the original dict. ## So, it refelects the change ## {1:\"A\", 2:\"B\"}","title":"1: MappingProxyType"},{"location":"gists/python_snippets/#2-set-operators","text":"Set Operators 1 2 3 4 5 6 7 8 9 10 11 **operator: method: desciption:** `s.isdisjoint(z)` `s` and `z` are disjoint (i.e. have no elements in common) `e in s` `s.__contains__(e)` element `e` is a subset of `s` set `s <= z` `s.__le__(z)` `s` is a **subset** of `z` set `s.issubset(it)` `s` is a **subset** of the set built from the iterable `it` `s < z` `s.__lt__(z)` `s` is a **PROPER-subset** of `z` set `s >= z` `s.__ge__(z)` `s` is a **superset** of `z` set `s.issuperset(it)` `s` is a **superset** of the set built from iterable `it` `s > z` `s.__gt__(z)` `s` is a **PROPER-superset** of the set `z`","title":"2: Set operators"},{"location":"gists/python_snippets/#3-set-vs-frozenset","text":"Set v/s Frozenset 1 2 3 4 5 6 7 8 9 **operator: set: frozenset: description:** `s.add(e)` \u2705 Add element `e` to set `s` `s.clear()` \u2705 Remove all elements from set `s` `s.copy()` \u2705 \u2705 Shallow copy of set/frozenset `s` `s.discard(e)` \u2705 Remove element `e` from set `s` IF it is present `s.__iter__()` \u2705 \u2705 Get iterator over set/frozenset `s` `s.__len__()` \u2705 \u2705 `len(s)` `s.pop()` \u2705 Remove and return an element from `s` ; raising `keyError` if `s` is empty `s.remove(e)` \u2705 Remive element `e` from set `s` ; raise `KeyError` if `e not in s`","title":"3: set v/s frozenset"},{"location":"gists/lightning/api/configure_optimizers/","text":"pl.LightningModule.configure_optimizers() Code Snippets 1 2 3 4 5 6 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-44 ## ## ! pl.LightningModule.configure_optimizers() ## Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"configure_optimizers()"},{"location":"gists/lightning/api/configure_optimizers/#pllightningmoduleconfigure_optimizers","text":"","title":"pl.LightningModule.configure_optimizers()"},{"location":"gists/lightning/api/configure_optimizers/#code-snippets","text":"1 2 3 4 5 6 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-44 ## ## ! pl.LightningModule.configure_optimizers() ## Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/configure_optimizers/#references","text":"","title":"References"},{"location":"gists/lightning/api/forward/","text":"pl.LightningModule.forward() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-46 ## ## ! pl.LightningModule.forward(*args, **kwargs) ## \"\"\" Same as 'torch.nn.Module.forward()' However in Lightning; we want it to define the operations we want to use it during prediction. \"\"\" ################################################################################################### ################################################################################################### # example: if we were using this model as a feature extractor. import torch import pytorch_lightning as pl class FlashModel ( pl . LightningModule ): def forward ( self , x ): feature_maps = self . convnet ( x ) return feature_maps def training_step ( self , batch , batch_idx ): x , y = batch feature_maps = self ( x ) ## ! <-- calls forward() method logits = self . classifier ( feature_maps ) ## TODO: DO something ... return loss ###################### # splitting it this way allows the model to be used as a feature extractor model = FlashModel () inputs = server . get_request () results = model ( inputs ) server . write_results ( results ) ######################################################################################## ######################################################################################## # Using vanilla \"torch.nn.Module\" only. # ! So use \"pl.LightningModule.forward()\" instead of \"torch.nn.Module.forward()\" class Model ( torch . nn . Module ): def forward ( self , batch ): x , y = batch feature_maps = self . convnet ( x ) logits = self . classifier ( feature_maps ) return logits ######################################################################################## ######################################################################################## Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"forward()"},{"location":"gists/lightning/api/forward/#pllightningmoduleforward","text":"","title":"pl.LightningModule.forward()"},{"location":"gists/lightning/api/forward/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-46 ## ## ! pl.LightningModule.forward(*args, **kwargs) ## \"\"\" Same as 'torch.nn.Module.forward()' However in Lightning; we want it to define the operations we want to use it during prediction. \"\"\" ################################################################################################### ################################################################################################### # example: if we were using this model as a feature extractor. import torch import pytorch_lightning as pl class FlashModel ( pl . LightningModule ): def forward ( self , x ): feature_maps = self . convnet ( x ) return feature_maps def training_step ( self , batch , batch_idx ): x , y = batch feature_maps = self ( x ) ## ! <-- calls forward() method logits = self . classifier ( feature_maps ) ## TODO: DO something ... return loss ###################### # splitting it this way allows the model to be used as a feature extractor model = FlashModel () inputs = server . get_request () results = model ( inputs ) server . write_results ( results ) ######################################################################################## ######################################################################################## # Using vanilla \"torch.nn.Module\" only. # ! So use \"pl.LightningModule.forward()\" instead of \"torch.nn.Module.forward()\" class Model ( torch . nn . Module ): def forward ( self , batch ): x , y = batch feature_maps = self . convnet ( x ) logits = self . classifier ( feature_maps ) return logits ######################################################################################## ######################################################################################## Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/forward/#references","text":"","title":"References"},{"location":"gists/lightning/api/freeze/","text":"pl.LightningModule.freeze() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.freeze() ## \"\"\" Freezes all parameters for inference. Return: None \"\"\" ################################################################################################### from lightning.api.forward import FlashModel import pytorch_lightning as pl model = FlashModel () model . freeze () ## ! <<- this freezes all model parameters. ################################################################################################### Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"freeze()"},{"location":"gists/lightning/api/freeze/#pllightningmodulefreeze","text":"","title":"pl.LightningModule.freeze()"},{"location":"gists/lightning/api/freeze/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.freeze() ## \"\"\" Freezes all parameters for inference. Return: None \"\"\" ################################################################################################### from lightning.api.forward import FlashModel import pytorch_lightning as pl model = FlashModel () model . freeze () ## ! <<- this freezes all model parameters. ################################################################################################### Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/freeze/#references","text":"","title":"References"},{"location":"gists/lightning/api/log/","text":"pl.LightningModule.log() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.log() ## \"\"\"Log a (key, value) Args: name ([type]): [description] value ([type]): [description] prog_bar ([type]): [description] logger ([type]): [description] on_step ([type]): [description] on_epoch ([type]): [description] reduce_fx ([type]): [description] tbptt_reduce_fx ([type]): [description] tbptt_pad_token ([type]): [description] enable_graph ([type]): [description] sync_dist ([type]): [description] sync_dist_op ([type]): [description] sync_dist_group ([type]): [description] \"\"\" Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"log()"},{"location":"gists/lightning/api/log/#pllightningmodulelog","text":"","title":"pl.LightningModule.log()"},{"location":"gists/lightning/api/log/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-47 ## ## ! pl.LightningModule.log() ## \"\"\"Log a (key, value) Args: name ([type]): [description] value ([type]): [description] prog_bar ([type]): [description] logger ([type]): [description] on_step ([type]): [description] on_epoch ([type]): [description] reduce_fx ([type]): [description] tbptt_reduce_fx ([type]): [description] tbptt_pad_token ([type]): [description] enable_graph ([type]): [description] sync_dist ([type]): [description] sync_dist_op ([type]): [description] sync_dist_group ([type]): [description] \"\"\" Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/log/#references","text":"","title":"References"},{"location":"gists/lightning/api/test_step/","text":"pl.LightningModule.test_step() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-50 ## ## ! pl.LightningModule.test_step() ## \"\"\" Operates on a single batch of data from the test set. In this step you would normally generate examples or calculate anything of interest such as accuracy. \"\"\" import torch import torchvision import pytorch_lightning as pl # The pseudocode for these calls test_outs = [] for test_batch in test_data : out = test_step ( test_batch ) test_outs . append ( out ) test_epoch_end ( test_outs ) ## if we have one test dataloader def test_step ( self , batch , batch_idx ): pass # if we have multiple test dataloaders def test_step ( self , batch , batch_idx , dataloader_idx ): pass ################################################################################ # Examples: case-1 [a single test dataset] def test_set ( self , batch , batch_idx ): x , y = batch # implement your own out = self ( x ) loss = self . loss ( out , y ) #log 6 example images or generated text or whatever sample_images = x [: 6 ] grid = torchvision . utils . make_grid ( sample_images ) self . logger . experiment . add_image ( \"example_images\" , grid , 0 ) # calculate accuracy labels_hat = torch . argmax ( out , dim = 1 ) test_acc = torch . sum ( y == labels_hat ) . item () / ( len ( y ) * 1.0 ) # log the outputs self . log_dict ({ \"test_loss\" : loss , \"test_acc\" : test_acc }) ################################################################################ # If we pass in multiple test datasets def test_set ( self , batch , batch_idx , dataloader_idx ): \"\"\" dataloader_idx ->> tells which dataset to use during test iterations \"\"\" # TODO: do whatever you want # TODO: ... pass ################################################################################ # NOTE: If you don't need to validate then you don't need to implement this method. # NOTE: When the test_step() is called; the model has been put in EVAL mode and all gradients have been disbaled. # At the end of the test epoch, the model goes back to the training mode and the gradients are enabled. ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"test_step()"},{"location":"gists/lightning/api/test_step/#pllightningmoduletest_step","text":"","title":"pl.LightningModule.test_step()"},{"location":"gists/lightning/api/test_step/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-50 ## ## ! pl.LightningModule.test_step() ## \"\"\" Operates on a single batch of data from the test set. In this step you would normally generate examples or calculate anything of interest such as accuracy. \"\"\" import torch import torchvision import pytorch_lightning as pl # The pseudocode for these calls test_outs = [] for test_batch in test_data : out = test_step ( test_batch ) test_outs . append ( out ) test_epoch_end ( test_outs ) ## if we have one test dataloader def test_step ( self , batch , batch_idx ): pass # if we have multiple test dataloaders def test_step ( self , batch , batch_idx , dataloader_idx ): pass ################################################################################ # Examples: case-1 [a single test dataset] def test_set ( self , batch , batch_idx ): x , y = batch # implement your own out = self ( x ) loss = self . loss ( out , y ) #log 6 example images or generated text or whatever sample_images = x [: 6 ] grid = torchvision . utils . make_grid ( sample_images ) self . logger . experiment . add_image ( \"example_images\" , grid , 0 ) # calculate accuracy labels_hat = torch . argmax ( out , dim = 1 ) test_acc = torch . sum ( y == labels_hat ) . item () / ( len ( y ) * 1.0 ) # log the outputs self . log_dict ({ \"test_loss\" : loss , \"test_acc\" : test_acc }) ################################################################################ # If we pass in multiple test datasets def test_set ( self , batch , batch_idx , dataloader_idx ): \"\"\" dataloader_idx ->> tells which dataset to use during test iterations \"\"\" # TODO: do whatever you want # TODO: ... pass ################################################################################ # NOTE: If you don't need to validate then you don't need to implement this method. # NOTE: When the test_step() is called; the model has been put in EVAL mode and all gradients have been disbaled. # At the end of the test epoch, the model goes back to the training mode and the gradients are enabled. ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/test_step/#references","text":"","title":"References"},{"location":"gists/lightning/api/training_step/","text":"pl.LightningModule.training_step() Code Snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-55 ## ## ! pl.LightningModule.training_step() ## \"\"\" Here we compute and return the training loss and some additional metrics. In this step you would normally do the forward pass and compute the loss for the batch. We can also do fancier things like multiple forward passes or something model specific. Parameters: batch (Tensor | (Tensor,...) | [Tensor, ...]) ->> The output of the dataloader batch_idx (int) ->> integer displaying the index of this batch optimizer_idx (int) ->> when using multiple optimizers this argument will also be present hiddens (Tensor) ->> Passed if `truncated_bptt_steps > 0` Returns: Any of Tensor (or) ->> The loss tensor dict (or) ->> A dictionary. Can include any keys but MUST include the key \"loss\" None ->> Training will skip to the next batch \"\"\" ## NOTE: The loss value shown in the progress bar is SMOOTHED (i.e. averaged) over its previous values. ## NOTE: So, it differs from the actual lossreturned in training/validation step import torch import pytorch_lightning as pl ################################################################################ class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx ): x , y , z = batch out = self . encoder ( x ) loss = self . loss ( out , x ) return loss ################################################################################ ## ! If we are using MULTIPLE OPTIMIZERS class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx , optimizer_idx ): if optimizer_idx == 0 : ## TODO: do training with encoder pass elif optimizer_idx == 1 : # TODO: DO training with decoder pass ################################################################################ ## ! Truncated BPTT class FlashModel ( pl . LightningModule ): def __init__ ( self , lstm ): super () . __init__ () self . lstm = lstm def training_step ( self , batch , batch_idx , hiddens ): # ! 'hiddens' are the hidden states from the previous truncated backprop step # ... out , hiddens = self . lstm ( data , hiddens ) loss = self . loss ( out , data ) # ... return { \"loss\" : loss , \"hiddens\" : hiddens } ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"training_step()"},{"location":"gists/lightning/api/training_step/#pllightningmoduletraining_step","text":"","title":"pl.LightningModule.training_step()"},{"location":"gists/lightning/api/training_step/#code-snippets","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 ## 7.4 [LightningModule API] ## 7.4.1 [Methods] ## Page-55 ## ## ! pl.LightningModule.training_step() ## \"\"\" Here we compute and return the training loss and some additional metrics. In this step you would normally do the forward pass and compute the loss for the batch. We can also do fancier things like multiple forward passes or something model specific. Parameters: batch (Tensor | (Tensor,...) | [Tensor, ...]) ->> The output of the dataloader batch_idx (int) ->> integer displaying the index of this batch optimizer_idx (int) ->> when using multiple optimizers this argument will also be present hiddens (Tensor) ->> Passed if `truncated_bptt_steps > 0` Returns: Any of Tensor (or) ->> The loss tensor dict (or) ->> A dictionary. Can include any keys but MUST include the key \"loss\" None ->> Training will skip to the next batch \"\"\" ## NOTE: The loss value shown in the progress bar is SMOOTHED (i.e. averaged) over its previous values. ## NOTE: So, it differs from the actual lossreturned in training/validation step import torch import pytorch_lightning as pl ################################################################################ class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx ): x , y , z = batch out = self . encoder ( x ) loss = self . loss ( out , x ) return loss ################################################################################ ## ! If we are using MULTIPLE OPTIMIZERS class FlashModel ( pl . LightningModule ): def __init__ ( self , encoder , decoder ): super () . __init__ () self . encoder = encoder self . decoder = decoder def training_step ( self , batch , batch_idx , optimizer_idx ): if optimizer_idx == 0 : ## TODO: do training with encoder pass elif optimizer_idx == 1 : # TODO: DO training with decoder pass ################################################################################ ## ! Truncated BPTT class FlashModel ( pl . LightningModule ): def __init__ ( self , lstm ): super () . __init__ () self . lstm = lstm def training_step ( self , batch , batch_idx , hiddens ): # ! 'hiddens' are the hidden states from the previous truncated backprop step # ... out , hiddens = self . lstm ( data , hiddens ) loss = self . loss ( out , data ) # ... return { \"loss\" : loss , \"hiddens\" : hiddens } ################################################################################ Author Disclaimer Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Code Snippets"},{"location":"gists/lightning/api/training_step/#references","text":"","title":"References"},{"location":"hobbies/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"notes/about/","text":".video-wrapper { position: relative; display: block; height: 0; padding: 0; overflow: hidden; padding-bottom: 56.25%; } .video-wrapper > iframe { position: absolute; top: 0; bottom: 0; left: 0; width: 100%; height: 100%; border: 0; } Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. 1 2 3 4 5 def bubble_sort ( items ): for i in range ( len ( items )): for j in range ( len ( items ) - 1 - i ): if items [ j ] > items [ j + 1 ]: items [ j ], items [ j + 1 ] = items [ j + 1 ], items [ j ] Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Pied Piper Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Submit C 1 2 3 4 5 6 #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } C++ 1 2 3 4 5 6 #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Welcome to MkDocs For full documentation visit mkdocs.org . Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C . 1 2 nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout 1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Deployment 1 git add . && git commit -m \"update\" && git push -u origin main && mkdocs gh-deploy --force Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod \u21a9","title":"About"},{"location":"notes/about/#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org . Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C . 1 2 nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Welcome to MkDocs"},{"location":"notes/about/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"notes/about/#project-layout","text":"1 2 3 4 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"notes/about/#deployment","text":"1 git add . && git commit -m \"update\" && git push -u origin main && mkdocs gh-deploy --force Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod \u21a9","title":"Deployment"},{"location":"notes/CS224N/cs224n_lecture1/","text":"Lecture #1 Word Meaning Denotational Semantics Distributional Semantics Localist Representation (like one-hot vectors ) Distributed Representation (like word-vectors ) NLTK example: synonyms of word good 1 2 3 4 5 6 7 8 9 10 11 ## Word Meaning from nltk.corpus import wordnet as wn poses = { \"n\" : \"noun\" , \"v\" : \"verb\" , \"s\" : \"adj (s)\" , \"a\" : \"adj\" , \"r\" : \"adv\" } for synset in wn . synsets ( \"good\" ): print ( f \" { poses [ synset . pos ()] } : { '' . join ([ l . name () for l in synset . lemmas ()]) } \" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u276f python 01_word_meaning.py noun: good noun: goodgoodness noun: goodgoodness noun: commoditytrade_goodgood adj: good adj (s): fullgood adj: good adj (s): estimablegoodhonorablerespectable adj (s): beneficialgood adj (s): good adj (s): goodjustupright adj (s): adeptexpertgoodpracticedproficientskillfulskilful adj (s): good adj (s): deargoodnear adj (s): dependablegoodsafesecure adj (s): goodrightripe adj (s): goodwell adj (s): effectivegoodin_effectin_force adj (s): good adj (s): goodserious adj (s): goodsound adj (s): goodsalutary adj (s): goodhonest adj (s): goodundecomposedunspoiledunspoilt adj (s): good adv: wellgood adv: thoroughlysoundlygood Problems with toolkits like WordNet Great as a resource but missing nuance Example: proficent is listed as a synonym for good ; but it is correct only in some contexts. Missing new meaning of words Example: new slang words etc like wicked , badass , nifty etc. IMPOSSIBLE to keep up-to-date Very Subjective Requires human labour to curate and maintain Can't compute accurate word-similarity. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 02/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references. References","title":"Lecture 1"},{"location":"notes/CS224N/cs224n_lecture1/#lecture-1","text":"","title":"Lecture #1"},{"location":"notes/CS224N/cs224n_lecture1/#word-meaning","text":"Denotational Semantics Distributional Semantics Localist Representation (like one-hot vectors ) Distributed Representation (like word-vectors ) NLTK example: synonyms of word good 1 2 3 4 5 6 7 8 9 10 11 ## Word Meaning from nltk.corpus import wordnet as wn poses = { \"n\" : \"noun\" , \"v\" : \"verb\" , \"s\" : \"adj (s)\" , \"a\" : \"adj\" , \"r\" : \"adv\" } for synset in wn . synsets ( \"good\" ): print ( f \" { poses [ synset . pos ()] } : { '' . join ([ l . name () for l in synset . lemmas ()]) } \" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u276f python 01_word_meaning.py noun: good noun: goodgoodness noun: goodgoodness noun: commoditytrade_goodgood adj: good adj (s): fullgood adj: good adj (s): estimablegoodhonorablerespectable adj (s): beneficialgood adj (s): good adj (s): goodjustupright adj (s): adeptexpertgoodpracticedproficientskillfulskilful adj (s): good adj (s): deargoodnear adj (s): dependablegoodsafesecure adj (s): goodrightripe adj (s): goodwell adj (s): effectivegoodin_effectin_force adj (s): good adj (s): goodserious adj (s): goodsound adj (s): goodsalutary adj (s): goodhonest adj (s): goodundecomposedunspoiledunspoilt adj (s): good adv: wellgood adv: thoroughlysoundlygood Problems with toolkits like WordNet Great as a resource but missing nuance Example: proficent is listed as a synonym for good ; but it is correct only in some contexts. Missing new meaning of words Example: new slang words etc like wicked , badass , nifty etc. IMPOSSIBLE to keep up-to-date Very Subjective Requires human labour to curate and maintain Can't compute accurate word-similarity. Author Disclaimer Author: Vinay Kumar (@imflash217) Date: 02/February/2021 The contents of this article were originally published at the references below. I have assembled it for my own understanding. Feel free to reuse and tag along the references.","title":"Word Meaning"},{"location":"notes/CS224N/cs224n_lecture1/#references","text":"","title":"References"},{"location":"notes/ECE542/ece542_hw1a/","text":"Homework 1a Author: Vinay Kumar (@imflash217) | Date: 31/January/2021 Q1 Q1 Given a vector \\(v \\in R^n\\) and square matrices \\(A, B \\in R^{n\\times n}\\) ; show that: \\(v^T v\\) = trace( \\(vv^T\\) ) trace(AB) = trace(BA) Q1 Solution Let \\(v = [v_1, v_2, \\cdots, v_n]^T\\) be a column vector of size \\((n,1)\\) - [ ] Then, $v^T v = $","title":"HW1a"},{"location":"notes/ECE542/ece542_hw1a/#homework-1a","text":"Author: Vinay Kumar (@imflash217) | Date: 31/January/2021","title":"Homework 1a"},{"location":"notes/ECE542/ece542_hw1a/#q1","text":"Q1 Given a vector \\(v \\in R^n\\) and square matrices \\(A, B \\in R^{n\\times n}\\) ; show that: \\(v^T v\\) = trace( \\(vv^T\\) ) trace(AB) = trace(BA) Q1 Solution Let \\(v = [v_1, v_2, \\cdots, v_n]^T\\) be a column vector of size \\((n,1)\\) - [ ] Then, $v^T v = $","title":"Q1"},{"location":"notes/ECE542/ece542_lecture1/","text":"Lecture #1 Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 AI v/s ML v/s DL (Venn Diagram) One-hot-encoding Loss Function Training v/s Evaluation Error Model Selection Hyperparams Overfitting v/s Underfitting Generalization Gap Model Capacity K-fold Cross Validation Leave-one-out Cross Validation What is Machine Learning? It is a field that aims to extract relationships and structures in the data. Example: How to map data to annotations? Loss Function We need a measure to see how well our system is doing at learning. This measure is called Loss Function Sum-of-Squared-Error (SSE): \\(2^2\\) \\(\\sum_{i}\\normalize{(y_i - f(x_i)}_2^2\\) Training The process of teaching our system to minimize errors is called as Training . Evaluation The process of determining the performance of our trained system over an unseen dataset is called as Evaluation . Unsupervised Learning Generative Models (GAN, AE, RBM) Latent Variable Modeling (PCA, AE) Clustering [special case of] Cross Validation If there are many point on the graph of CV( \\(\\theta\\) ) with similar values near the minimum; we choose the most parsimonious model that has a CV value within the standard deviation from the best model \\(\\theta^*\\) . In other words; we pick the first \\(\\theta\\) for which the CV value satisfies \\(CV(\\theta) < CV(\\theta^*) + std(CV(\\theta^*))\\) Benefits of this process: It decreases the possibility of choose an underfit or slightly ovefit model than what is required. Provides better Guarantees.","title":"Lecture 1"},{"location":"notes/ECE542/ece542_lecture1/#lecture-1","text":"Author: Vinay Kumar (@imflash217) | Date: 30/January/2021 AI v/s ML v/s DL (Venn Diagram) One-hot-encoding Loss Function Training v/s Evaluation Error Model Selection Hyperparams Overfitting v/s Underfitting Generalization Gap Model Capacity K-fold Cross Validation Leave-one-out Cross Validation What is Machine Learning? It is a field that aims to extract relationships and structures in the data. Example: How to map data to annotations? Loss Function We need a measure to see how well our system is doing at learning. This measure is called Loss Function Sum-of-Squared-Error (SSE): \\(2^2\\) \\(\\sum_{i}\\normalize{(y_i - f(x_i)}_2^2\\) Training The process of teaching our system to minimize errors is called as Training . Evaluation The process of determining the performance of our trained system over an unseen dataset is called as Evaluation . Unsupervised Learning Generative Models (GAN, AE, RBM) Latent Variable Modeling (PCA, AE) Clustering [special case of] Cross Validation If there are many point on the graph of CV( \\(\\theta\\) ) with similar values near the minimum; we choose the most parsimonious model that has a CV value within the standard deviation from the best model \\(\\theta^*\\) . In other words; we pick the first \\(\\theta\\) for which the CV value satisfies \\(CV(\\theta) < CV(\\theta^*) + std(CV(\\theta^*))\\) Benefits of this process: It decreases the possibility of choose an underfit or slightly ovefit model than what is required. Provides better Guarantees.","title":"Lecture #1"},{"location":"paper_reviews/about/","text":"ArXiv paper Slides","title":"About"},{"location":"paper_reviews/about/#arxiv-paper","text":"","title":"ArXiv paper"},{"location":"paper_reviews/about/#slides","text":"","title":"Slides"},{"location":"paper_reviews/dter/","text":"","title":"Dter"},{"location":"projects/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"publications/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"About"},{"location":"publications/interspeech_2014/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Interspeech 2014"},{"location":"publications/odyssey_2014/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Odyssey 2014"},{"location":"python/context_managers/","text":"Context Managers A context manager is a Python object that provides extra contextual information to an action. This extra contextual information takes the form of running a callable upon initiating the context using the with statement; as well as running a callable upon completing all the code inside the with block. For eg: 1 2 with open ( \"file.txt\" ) as f : contents = f . read () Anyone familiar with this pattern knows that invoking open in this fashion ensures that f 's close() will be called at some point. There are two ways to implement this functionality ourselves: using class using @contextmanager decorator Ctx Manager using CLASS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 class CustomOpen : def __init__ ( self , filename ): self . file = open ( filename ) def __enter__ ( self ): return self . file def __exit__ ( self , ctx_type , ctx_vale , ctx_traceback ): self . file . close () ################################################################### with CustomOPen ( \"file.txt\" ) as f : contents = f . read () This is just a regular class with two extra methods __enter__() and __exit__() . Implementation of __enter__ and __exit__ are essential for its usage in with statement. Following are the three steps of functionality of with statement: Firstly, CustomOpen is initantiated Then its __enter__() method is called and whatever __enter__() returns is assigned to f in as f part of the statement. When the contents of the with block is finished executing, then, __exit__() method is called. Ctx Managers using GENERATORS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## implementing a smilar context manager as above ## uisng a decorator from contextlib import contextmanager @contextmanager def custom_open ( filename ): f = open ( filename ) try : yield f finally : f . close () ######################################################### with custom_open ( \"file.txt\" ) as f : contents = f . read () This works in exactly the same manner as the CLASS version: The custom_open function executes until it reaches the yield statement. The control was given back to the with statement which assigns whatever was yield ed to f in the as f part of the with statement. The finally block is executed at the end of the with statement.","title":"Context Managers"},{"location":"python/context_managers/#context-managers","text":"A context manager is a Python object that provides extra contextual information to an action. This extra contextual information takes the form of running a callable upon initiating the context using the with statement; as well as running a callable upon completing all the code inside the with block. For eg: 1 2 with open ( \"file.txt\" ) as f : contents = f . read () Anyone familiar with this pattern knows that invoking open in this fashion ensures that f 's close() will be called at some point. There are two ways to implement this functionality ourselves: using class using @contextmanager decorator","title":"Context Managers"},{"location":"python/context_managers/#ctx-manager-using-class","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 class CustomOpen : def __init__ ( self , filename ): self . file = open ( filename ) def __enter__ ( self ): return self . file def __exit__ ( self , ctx_type , ctx_vale , ctx_traceback ): self . file . close () ################################################################### with CustomOPen ( \"file.txt\" ) as f : contents = f . read () This is just a regular class with two extra methods __enter__() and __exit__() . Implementation of __enter__ and __exit__ are essential for its usage in with statement. Following are the three steps of functionality of with statement: Firstly, CustomOpen is initantiated Then its __enter__() method is called and whatever __enter__() returns is assigned to f in as f part of the statement. When the contents of the with block is finished executing, then, __exit__() method is called.","title":"Ctx Manager using CLASS"},{"location":"python/context_managers/#ctx-managers-using-generators","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## implementing a smilar context manager as above ## uisng a decorator from contextlib import contextmanager @contextmanager def custom_open ( filename ): f = open ( filename ) try : yield f finally : f . close () ######################################################### with custom_open ( \"file.txt\" ) as f : contents = f . read () This works in exactly the same manner as the CLASS version: The custom_open function executes until it reaches the yield statement. The control was given back to the with statement which assigns whatever was yield ed to f in the as f part of the with statement. The finally block is executed at the end of the with statement.","title":"Ctx Managers using GENERATORS"},{"location":"python/decorators/","text":"Decorators 101 A decorator is a callable that takes another function as argument (the decorated func.) The decorator may perform some processing with the decorated function, and return it or replaces it with another function or callable object. Both these code snippet shas the same effect: 1 2 3 @decorate def target (): print ( \"running target()\" ) v/s 1 2 3 4 5 ## this code snippet has the same effect as the above one (using @decorate decorator) def target (): print ( \"running target()\" ) target = decorate ( target ) Decorators are just syntactic sugar. We can always call a decorator like any regular callable, passing another function (as shown in 2 nd snippet above). Decorators have the power to replace the decorated-function with a different one. Decorators are executed immediately when a module is loaded. When does Python executs decorators? A key feature of decorators is that they run right after the decorated function is defined. This happens usually at the import time (i.e. when the module is loaded). An example 1 2 ## registration.py module registry = []","title":"Decorators & Closures"},{"location":"python/decorators/#decorators-101","text":"A decorator is a callable that takes another function as argument (the decorated func.) The decorator may perform some processing with the decorated function, and return it or replaces it with another function or callable object. Both these code snippet shas the same effect: 1 2 3 @decorate def target (): print ( \"running target()\" ) v/s 1 2 3 4 5 ## this code snippet has the same effect as the above one (using @decorate decorator) def target (): print ( \"running target()\" ) target = decorate ( target ) Decorators are just syntactic sugar. We can always call a decorator like any regular callable, passing another function (as shown in 2 nd snippet above). Decorators have the power to replace the decorated-function with a different one. Decorators are executed immediately when a module is loaded.","title":"Decorators 101"},{"location":"python/decorators/#when-does-python-executs-decorators","text":"A key feature of decorators is that they run right after the decorated function is defined. This happens usually at the import time (i.e. when the module is loaded). An example 1 2 ## registration.py module registry = []","title":"When does Python executs decorators?"},{"location":"python/design_patterns/","text":"STRATEGY Pattern 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 from abc import ABC , abstractmethod from collections import namedtuple Customer = namedtuple ( \"Customer\" , \"name fidelity\" ) class LineItem : def __init__ ( self , product , quantity , price ): self . product = product self . quantity = quantity self . price = price def total ( self ): return self . price * self . quantity class Order : \"\"\"This is the CONTEXT part of the Strategy-Pattern\"\"\" def __init__ ( self , customer , cart , promotion = None ): self . customer = customer self . cart = list ( cart ) self . promotion = promotion def total ( self ): if not hasattr ( self , \"__total\" ): self . __total = sum ( item . total () for item in self . cart ) return self . __total def due ( self ): if self . promotion is None : discount = 0 else : discount = self . promotion . discount ( self ) return self . total () - discount def __repr__ ( self ): fmt = \"< Order total = {:.2f} ; DUE = {:.2f} >\" return fmt . format ( self . total (), self . due ()) class Promotion ( ABC ): \"\"\" The STRATEGY part of the Strategy-pattern An Abstract Base Class \"\"\" @abstractmethod def discount ( self , order ): \"\"\"Return discount as a positive dollar amount\"\"\" class FidelityPromot ( Promotion ): \"\"\" First CONCRETE implementation of STRATEGY ABC 5% disount for customer with 1000 or more fidelity points \"\"\" def discount ( self , order ): return order . total () * 0.05 if order . customer . fidelity >= 1000 else 0 class BulkPromo ( Promotion ): \"\"\" Second CONCRETE implementation of the Strategy-pattern 10% discount for each line-item with 20 or more units \"\"\" def discount ( self , order ): discount = 0 for item in order . cart : if item . quantity >= 20 : discount += item . total () * 0.1 return discount class LargeOrderPromo ( Promotion ): \"\"\" Third CONCRETE implementation of the Strategy-pattern 7% discount for orders with 10 or more distinct items \"\"\" def discount ( self , order ): distinct_items = { item . product for item in order . cart } if len ( distinct_items ) >= 10 : return order . total () * 0.07 return 0 Example Usage Sample usage of Order class with different promotions applied 1 2 3 4 5 6 joe = Customer ( \"John Doe\" , 0 ) ann = Customer ( \"Ann Smith\" , 1100 ) cart = [ LineItem ( \"banana\" , 4 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 ), LineItem ( \"watermelon\" , 5 , 5.0 )] 1 2 Order ( joe , cart , FidelityPromo ()) ## < Order total = 42.00; DUE = 42.00 > Order ( ann , cart , FidelityPromo ()) ## < Order total = 42.00; DUE = 39.90 > Few more example usage with differnt cart types 1 2 3 4 banana_cart = [ LineItem ( \"banana\" , 30 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 )] Order ( joe , banana_cart , BulkItemPromo ()) ## < Order total = 30.00; DUE = 28.50 > 1 2 3 4 long_order = [ LineItem ( str ( item_code ), 1 , 1.0 ) for item_code in range ( 10 )] Order ( joe , long_order , LargeOrderPromo ()) ## < Order total = 10.00; DUE = 9.30 > Order ( joe , cart , LargeOrderPromo ()) ## < Order total = 42.00; DUE = 42.00 > Function-oriented STRATEGY Pattern Each concrete implementation of the Strategy Pattern in above code is a class with a single method discount() . Furthermore, the strategy instances have no state (i.e. no instance attributes). They look a lot like plain functions. So, below we re-write the concrete implementations of the Strategy Pattern as plain function . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 from collections import namedtuple Customer = namedtuple ( \"Customer\" , \"name fidelity\" ) class LineItem : def __init__ ( self , product , quantity , price ): self . product = product self . quantity = quantity self . price = price def total ( self ): return self . price * self . quantity class Order : \"\"\"The CONTEXT\"\"\" def __init__ ( self , customer , cart , promotion = None ): self . customer = customer self . cart = list ( cart ) self . promotion = promotion def total ( self ): if not hasattr ( self , \"__total\" ): self . __total = sum ( item . total () for item in self . cart ) return self . __total def due ( self ): discount = 0 if self . promotion : discount = self . promotion ( self ) return self . total () - discount def __repr__ ( self ): fmt = \"<Order total = {:.2f} ; DUE = {:.2f} >\" fmt . format ( self . total (), self . due ()) ######################################################################################## ## Redesign of the concrete-implementations of STRATEGY PATTERN as functions def fidelity_promot ( order ): \"\"\"5% discount for customers with >= 1000 fidelity points\"\"\" return order . total () * 0.05 if order . customer . fidelity >= 1000 else 0 def bulk_item_promo ( order ): \"\"\"10% discount for each LineItem with >= 20 units in cart\"\"\" discount = 0 for item in oder . cart : if item . quantity >= 20 : discount += item . total () * 0.1 return discount def large_order_promo ( order ): \"\"\"7% discount for orders with >= 10 distinct items\"\"\" distinct_items = set ( item . product for item in order . cart ) if len ( distinct_items ) >= 10 : return order . total () * 0.07 return 0 Example Usage Smaple usage examples of Order class with promotion Strategy as functions 1 2 3 4 5 6 joe = Customer ( \"John Doe\" , 0 ) ann = Customer ( \"Ann Smith\" , 1100 ) cart = [ LineItem ( \"banana\" , 4 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 ), LineItem ( \"watermelon\" , 5 , 5.0 )] 1 2 Order ( joe , cart , fidelity_promo ) ## < Order total = 42.00; DUE = 42.00 > Order ( ann , cart , fidelity_promo ) ## < Order total = 42.00; DUE = 39.90 > Another Example 1 2 3 banana_cart = [ LineItem ( \"banana\" , 30 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 )] Order ( joe , banana_cart , bulk_item_promo ) ## < Order total = 30.00; DUE = 28.50 > Yet another Example 1 2 3 4 long_order = [ LineItem ( str ( item_id ), 1 , 1.0 ) for item_id in range ( 10 )] Order ( joe , long_order , large_order_promo ) ## < Order total = 10.00; DUE = 9.30 > Order ( joe , cart , large_order_promo ) ## < Order total = 42.00; DUE = 42.00 > STRATEGY objects often make good FLYWEIGHTS A FLYWIGHT is a shared object that cane be use din multiple contexts simulatenously. Sharing is encouraged to reduce the creation of a new concrete strategy object when the same strategy is applied over and over again in different contexts (i.e. with every new Order instance) If the strategies have no internal state (often the case); then use plain old functions else adapt to use class version. A function is more lightweight than an user-defined class A plain functions is also a_shared_ object that can be used in multiple contexts simulateneously. Choosing the best Strategy Given the same customers and carts from above examples; we now add additional tests. 1 2 3 Order ( joe , long_order , best_promo ) ## < Order total = 10.00; DUE = 9.30 > ## case-1 Order ( joe , banana_cart , best_promo ) ## < Order total = 30.00; DUE = 28.50 > ## case-2 Order ( ann , cart , best_promo ) ## < Order total = 42.00; DUE = 39.90 > ## case-3 case-1: best_promo selected the large_order_promo for customer joe case-2: best_promo selected the bulk_item_promo for customer joe (for ordering lots of bananas) case-3: best_promo selected the fidelity_promo for ann 's loyalty. Below is the implementation of best_promo 1 2 3 4 5 6 all_promos = [ fidelity_promo , bulk_item_promo , large_order_promo ] def best_promo ( order ): \"\"\"Selects the best discount avaailable. Only one discount applicable\"\"\" best_discount = max ( promo ( order ) for promo in all_promos ) return best_discount Finding Strategies in a module 1 2 3 4 5 6 7 8 9 ## Method-1 ## using globals() all_promos = [ globals ()[ name ] for name in globals () if name . endswith ( \"_promo\" ) and name != \"best_promo\" ] def best_promo ( order ): best_discount = max ( promo ( order ) for order in all_promos ) return best_discount But a more flexible way to handle this is using inbuilt inspect module and storing all the promos functions in a file promotions.py . This works regardless of the names given to promos. 1 2 3 4 5 6 7 ## Method-2 ## using modules to store the promos separately all_promos = [ func for name , func in inspect . getmembers ( promotions , inspect . isfunction )] def best_promo ( order ): best_discount = max ( promo ( order ) for promo in all_promos ) return best_discount Both the methods have pros & cons. Choose as you see fit. We could add more stringent tests to filter the functions, by inspecting their arguments for instance. A more elegant solution would be use a decorator . (we will study this in later blogs) References https://github.com/gennad/Design-Patterns-in-Python \u21a9","title":"Design Patterns"},{"location":"python/design_patterns/#strategy-pattern","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 from abc import ABC , abstractmethod from collections import namedtuple Customer = namedtuple ( \"Customer\" , \"name fidelity\" ) class LineItem : def __init__ ( self , product , quantity , price ): self . product = product self . quantity = quantity self . price = price def total ( self ): return self . price * self . quantity class Order : \"\"\"This is the CONTEXT part of the Strategy-Pattern\"\"\" def __init__ ( self , customer , cart , promotion = None ): self . customer = customer self . cart = list ( cart ) self . promotion = promotion def total ( self ): if not hasattr ( self , \"__total\" ): self . __total = sum ( item . total () for item in self . cart ) return self . __total def due ( self ): if self . promotion is None : discount = 0 else : discount = self . promotion . discount ( self ) return self . total () - discount def __repr__ ( self ): fmt = \"< Order total = {:.2f} ; DUE = {:.2f} >\" return fmt . format ( self . total (), self . due ()) class Promotion ( ABC ): \"\"\" The STRATEGY part of the Strategy-pattern An Abstract Base Class \"\"\" @abstractmethod def discount ( self , order ): \"\"\"Return discount as a positive dollar amount\"\"\" class FidelityPromot ( Promotion ): \"\"\" First CONCRETE implementation of STRATEGY ABC 5% disount for customer with 1000 or more fidelity points \"\"\" def discount ( self , order ): return order . total () * 0.05 if order . customer . fidelity >= 1000 else 0 class BulkPromo ( Promotion ): \"\"\" Second CONCRETE implementation of the Strategy-pattern 10% discount for each line-item with 20 or more units \"\"\" def discount ( self , order ): discount = 0 for item in order . cart : if item . quantity >= 20 : discount += item . total () * 0.1 return discount class LargeOrderPromo ( Promotion ): \"\"\" Third CONCRETE implementation of the Strategy-pattern 7% discount for orders with 10 or more distinct items \"\"\" def discount ( self , order ): distinct_items = { item . product for item in order . cart } if len ( distinct_items ) >= 10 : return order . total () * 0.07 return 0 Example Usage Sample usage of Order class with different promotions applied 1 2 3 4 5 6 joe = Customer ( \"John Doe\" , 0 ) ann = Customer ( \"Ann Smith\" , 1100 ) cart = [ LineItem ( \"banana\" , 4 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 ), LineItem ( \"watermelon\" , 5 , 5.0 )] 1 2 Order ( joe , cart , FidelityPromo ()) ## < Order total = 42.00; DUE = 42.00 > Order ( ann , cart , FidelityPromo ()) ## < Order total = 42.00; DUE = 39.90 > Few more example usage with differnt cart types 1 2 3 4 banana_cart = [ LineItem ( \"banana\" , 30 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 )] Order ( joe , banana_cart , BulkItemPromo ()) ## < Order total = 30.00; DUE = 28.50 > 1 2 3 4 long_order = [ LineItem ( str ( item_code ), 1 , 1.0 ) for item_code in range ( 10 )] Order ( joe , long_order , LargeOrderPromo ()) ## < Order total = 10.00; DUE = 9.30 > Order ( joe , cart , LargeOrderPromo ()) ## < Order total = 42.00; DUE = 42.00 >","title":"STRATEGY Pattern"},{"location":"python/design_patterns/#function-oriented-strategy-pattern","text":"Each concrete implementation of the Strategy Pattern in above code is a class with a single method discount() . Furthermore, the strategy instances have no state (i.e. no instance attributes). They look a lot like plain functions. So, below we re-write the concrete implementations of the Strategy Pattern as plain function . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 from collections import namedtuple Customer = namedtuple ( \"Customer\" , \"name fidelity\" ) class LineItem : def __init__ ( self , product , quantity , price ): self . product = product self . quantity = quantity self . price = price def total ( self ): return self . price * self . quantity class Order : \"\"\"The CONTEXT\"\"\" def __init__ ( self , customer , cart , promotion = None ): self . customer = customer self . cart = list ( cart ) self . promotion = promotion def total ( self ): if not hasattr ( self , \"__total\" ): self . __total = sum ( item . total () for item in self . cart ) return self . __total def due ( self ): discount = 0 if self . promotion : discount = self . promotion ( self ) return self . total () - discount def __repr__ ( self ): fmt = \"<Order total = {:.2f} ; DUE = {:.2f} >\" fmt . format ( self . total (), self . due ()) ######################################################################################## ## Redesign of the concrete-implementations of STRATEGY PATTERN as functions def fidelity_promot ( order ): \"\"\"5% discount for customers with >= 1000 fidelity points\"\"\" return order . total () * 0.05 if order . customer . fidelity >= 1000 else 0 def bulk_item_promo ( order ): \"\"\"10% discount for each LineItem with >= 20 units in cart\"\"\" discount = 0 for item in oder . cart : if item . quantity >= 20 : discount += item . total () * 0.1 return discount def large_order_promo ( order ): \"\"\"7% discount for orders with >= 10 distinct items\"\"\" distinct_items = set ( item . product for item in order . cart ) if len ( distinct_items ) >= 10 : return order . total () * 0.07 return 0 Example Usage Smaple usage examples of Order class with promotion Strategy as functions 1 2 3 4 5 6 joe = Customer ( \"John Doe\" , 0 ) ann = Customer ( \"Ann Smith\" , 1100 ) cart = [ LineItem ( \"banana\" , 4 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 ), LineItem ( \"watermelon\" , 5 , 5.0 )] 1 2 Order ( joe , cart , fidelity_promo ) ## < Order total = 42.00; DUE = 42.00 > Order ( ann , cart , fidelity_promo ) ## < Order total = 42.00; DUE = 39.90 > Another Example 1 2 3 banana_cart = [ LineItem ( \"banana\" , 30 , 0.5 ), LineItem ( \"apple\" , 10 , 1.5 )] Order ( joe , banana_cart , bulk_item_promo ) ## < Order total = 30.00; DUE = 28.50 > Yet another Example 1 2 3 4 long_order = [ LineItem ( str ( item_id ), 1 , 1.0 ) for item_id in range ( 10 )] Order ( joe , long_order , large_order_promo ) ## < Order total = 10.00; DUE = 9.30 > Order ( joe , cart , large_order_promo ) ## < Order total = 42.00; DUE = 42.00 > STRATEGY objects often make good FLYWEIGHTS A FLYWIGHT is a shared object that cane be use din multiple contexts simulatenously. Sharing is encouraged to reduce the creation of a new concrete strategy object when the same strategy is applied over and over again in different contexts (i.e. with every new Order instance) If the strategies have no internal state (often the case); then use plain old functions else adapt to use class version. A function is more lightweight than an user-defined class A plain functions is also a_shared_ object that can be used in multiple contexts simulateneously.","title":"Function-oriented STRATEGY Pattern"},{"location":"python/design_patterns/#choosing-the-best-strategy","text":"Given the same customers and carts from above examples; we now add additional tests. 1 2 3 Order ( joe , long_order , best_promo ) ## < Order total = 10.00; DUE = 9.30 > ## case-1 Order ( joe , banana_cart , best_promo ) ## < Order total = 30.00; DUE = 28.50 > ## case-2 Order ( ann , cart , best_promo ) ## < Order total = 42.00; DUE = 39.90 > ## case-3 case-1: best_promo selected the large_order_promo for customer joe case-2: best_promo selected the bulk_item_promo for customer joe (for ordering lots of bananas) case-3: best_promo selected the fidelity_promo for ann 's loyalty. Below is the implementation of best_promo 1 2 3 4 5 6 all_promos = [ fidelity_promo , bulk_item_promo , large_order_promo ] def best_promo ( order ): \"\"\"Selects the best discount avaailable. Only one discount applicable\"\"\" best_discount = max ( promo ( order ) for promo in all_promos ) return best_discount","title":"Choosing the best Strategy"},{"location":"python/design_patterns/#finding-strategies-in-a-module","text":"1 2 3 4 5 6 7 8 9 ## Method-1 ## using globals() all_promos = [ globals ()[ name ] for name in globals () if name . endswith ( \"_promo\" ) and name != \"best_promo\" ] def best_promo ( order ): best_discount = max ( promo ( order ) for order in all_promos ) return best_discount But a more flexible way to handle this is using inbuilt inspect module and storing all the promos functions in a file promotions.py . This works regardless of the names given to promos. 1 2 3 4 5 6 7 ## Method-2 ## using modules to store the promos separately all_promos = [ func for name , func in inspect . getmembers ( promotions , inspect . isfunction )] def best_promo ( order ): best_discount = max ( promo ( order ) for promo in all_promos ) return best_discount Both the methods have pros & cons. Choose as you see fit. We could add more stringent tests to filter the functions, by inspecting their arguments for instance. A more elegant solution would be use a decorator . (we will study this in later blogs)","title":"Finding Strategies in a module"},{"location":"python/design_patterns/#references","text":"https://github.com/gennad/Design-Patterns-in-Python \u21a9","title":"References"},{"location":"python/hashing/","text":"Hashing in Python Reduce Map & Reduce ZIP","title":"Hashing"},{"location":"python/hashing/#hashing-in-python","text":"","title":"Hashing in Python"},{"location":"python/hashing/#reduce","text":"","title":"Reduce"},{"location":"python/hashing/#map-reduce","text":"","title":"Map &amp; Reduce"},{"location":"python/hashing/#zip","text":"","title":"ZIP"},{"location":"python/protocols/","text":"In the context of Object Oriented Programming, a protocol is an informal interface that is defined only in the documentation, not in code . Sequence Protocol For eg., the sequence protocol in Python entails just the __len__() and __getitem__() methods. Any class Spam that uses those methods can be used as a sequence . Whether Spam is a subclass of this or that is irrelevant; all that matters is that it provides the necessary methods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import collections Card = collections . namedtuple ( \"Card\" , [ \"rank\" , \"suit\" ]) class FrenchDeck : ranks = [ str ( i ) for i in range ( 2 , 11 )] + str ( \"JQKA\" ) suits = \"spades, diamonds, clubs, hearts\" . split ( \", \" ) def __init__ ( self ): self . _cards = [ Card ( rank , suit ) for rank in ranks for suit in suits ] def __len__ ( self ): ## necessary for usage as a SEQUENCE return len ( self . _cards ) def __getitem__ ( self , idx ): ## necessary for usage as a SEQUENCE return self . _cards [ idx ] Because protocols are informal and un-enforced, you can get away with just implementing the part of the protocol that is necessary for your usage. For example, to support only iteration we just need to implement the __getitem__() method; we don't need to implement __len__() .","title":"Protocols"},{"location":"python/protocols/#sequence-protocol","text":"For eg., the sequence protocol in Python entails just the __len__() and __getitem__() methods. Any class Spam that uses those methods can be used as a sequence . Whether Spam is a subclass of this or that is irrelevant; all that matters is that it provides the necessary methods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import collections Card = collections . namedtuple ( \"Card\" , [ \"rank\" , \"suit\" ]) class FrenchDeck : ranks = [ str ( i ) for i in range ( 2 , 11 )] + str ( \"JQKA\" ) suits = \"spades, diamonds, clubs, hearts\" . split ( \", \" ) def __init__ ( self ): self . _cards = [ Card ( rank , suit ) for rank in ranks for suit in suits ] def __len__ ( self ): ## necessary for usage as a SEQUENCE return len ( self . _cards ) def __getitem__ ( self , idx ): ## necessary for usage as a SEQUENCE return self . _cards [ idx ] Because protocols are informal and un-enforced, you can get away with just implementing the part of the protocol that is necessary for your usage. For example, to support only iteration we just need to implement the __getitem__() method; we don't need to implement __len__() .","title":"Sequence Protocol"},{"location":"python/pythonic_object/","text":"Lets start by introducing a Vector class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 from array import array import math class Vector2D : typecode = \"d\" def __init__ ( self , x , y ): self . x = float ( x ) self . y = float ( y ) def __iter__ ( self ): return ( i for i in ( self . x , self . y )) def __repr__ ( self ): class_name = type ( self ) . __name__ return \" {} ( {!r} , {!r} )\" . format ( class_name , * self ) def __str__ ( self ): return str ( tuple ( self )) def __bytes__ ( self ): return ( bytes ([ ord ( self . typecode )]) + bytes ( array ( self . typecode , self ))) def __eq__ ( self , other ): return tuple ( self ) == tuple ( other ) def __abs__ ( self ): return math . hypot ( self . x , self . y ) def __bool__ ( self ): return bool ( abs ( self )) An alternative constructor Since in above example, we export a Vector2D as bytes; we also need a method to imports a vector2D from binary sequence. Looking at the standard library for inspiration, we see that array.array has a class method frombytes() . Lets adopt this nomenclature in our Vector2D class. 1 2 3 4 5 6 7 8 ## adding a import method from a binary sequence ## inside Vector2D class definition @classmethod def frombytes ( cls , octets ): typecode = chr ( octets [ 0 ]) memv = memoryview ( octets [ 1 :]) . cast ( typecode ) return cls ( * memv ) @classmethod v/s @staticmethod @classmethod : It is used to define a method that operates on class ; not on instances . It receives the class itself as the 1 st argument (eg. cls in above code) instead of an instance (eg. self ) Most commonly used as alternate constructors (eg. frombytes in above code) Note: (in the above frombyytes() ) how the last line in frombytes() uses cls argument by invoking it to build a new instance ( cls(*memv) ) By convention the 1 st argument of the @classmethod should be named cls (but Python does not care about the name though) @staticmethod A static method is just like a plain old function that happens to live inside the body of a class instead of being defind outside the class. It does not have access to internal state variables of the class or the instance. It is kept inside the class definition to provide easy access to related functions/method, so the user have access to all necessary method for a class within itself instead of finding it elsewhere. An example: 1 2 3 4 5 6 7 8 class Demo : @classmethod def klassmeth ( * args ): return * args @staticmethod def statmeth ( * args ): return * args 1 2 3 4 5 6 ## no matter how it is invoked, Demo.klassmethod always receives Demo class as its 1st argument Demo . klassmeth () ## (<class \"__main__.Demo\">,) Demo . klassmeth ( \"spam\" ) ## (<class \"__main__.Demo\">, \"spam\") Demo . statmeth () ## () Demo . statmeth ( \"spam\" ) ## (\"spam\") Formatted displays int type supports b (for base=2 integers) and x (for base=16 integers). float type implements f (for fixed-points) and % (for a percentage display). 1 2 3 4 5 6 7 8 format ( 42 , \"b\" ) ## \"101010\" format ( 42 , \"x\" ) ## \"2a\" format ( 2 / 3 , 'f' ) ## 0.666667 format ( 2 / 3 , \".3f\" ) ## 0.667 format ( 2 / 3 , \"%\" ) ## 66.666667% format ( 2 / 3 , \".2%\" ) ## 66.67% The Format Specifier Mini Language is extensible because each class gets to interpret the format_spec argument as it likes. 1 2 3 4 from datetime import datetime now = datetime . now () format ( now , \"%H:%M:%S\" ) ## \"18:49:05\" print ( \"Its now {:%I:%M %p}\" ) ## \"Its now 06:49 PM\" If a class has no __format__() method, the method inherited from object return str(my_object) .","title":"A Pythonic Object"},{"location":"python/pythonic_object/#an-alternative-constructor","text":"Since in above example, we export a Vector2D as bytes; we also need a method to imports a vector2D from binary sequence. Looking at the standard library for inspiration, we see that array.array has a class method frombytes() . Lets adopt this nomenclature in our Vector2D class. 1 2 3 4 5 6 7 8 ## adding a import method from a binary sequence ## inside Vector2D class definition @classmethod def frombytes ( cls , octets ): typecode = chr ( octets [ 0 ]) memv = memoryview ( octets [ 1 :]) . cast ( typecode ) return cls ( * memv )","title":"An alternative constructor"},{"location":"python/pythonic_object/#classmethod-vs-staticmethod","text":"@classmethod : It is used to define a method that operates on class ; not on instances . It receives the class itself as the 1 st argument (eg. cls in above code) instead of an instance (eg. self ) Most commonly used as alternate constructors (eg. frombytes in above code) Note: (in the above frombyytes() ) how the last line in frombytes() uses cls argument by invoking it to build a new instance ( cls(*memv) ) By convention the 1 st argument of the @classmethod should be named cls (but Python does not care about the name though) @staticmethod A static method is just like a plain old function that happens to live inside the body of a class instead of being defind outside the class. It does not have access to internal state variables of the class or the instance. It is kept inside the class definition to provide easy access to related functions/method, so the user have access to all necessary method for a class within itself instead of finding it elsewhere. An example: 1 2 3 4 5 6 7 8 class Demo : @classmethod def klassmeth ( * args ): return * args @staticmethod def statmeth ( * args ): return * args 1 2 3 4 5 6 ## no matter how it is invoked, Demo.klassmethod always receives Demo class as its 1st argument Demo . klassmeth () ## (<class \"__main__.Demo\">,) Demo . klassmeth ( \"spam\" ) ## (<class \"__main__.Demo\">, \"spam\") Demo . statmeth () ## () Demo . statmeth ( \"spam\" ) ## (\"spam\")","title":"@classmethod v/s @staticmethod"},{"location":"python/pythonic_object/#formatted-displays","text":"int type supports b (for base=2 integers) and x (for base=16 integers). float type implements f (for fixed-points) and % (for a percentage display). 1 2 3 4 5 6 7 8 format ( 42 , \"b\" ) ## \"101010\" format ( 42 , \"x\" ) ## \"2a\" format ( 2 / 3 , 'f' ) ## 0.666667 format ( 2 / 3 , \".3f\" ) ## 0.667 format ( 2 / 3 , \"%\" ) ## 66.666667% format ( 2 / 3 , \".2%\" ) ## 66.67% The Format Specifier Mini Language is extensible because each class gets to interpret the format_spec argument as it likes. 1 2 3 4 from datetime import datetime now = datetime . now () format ( now , \"%H:%M:%S\" ) ## \"18:49:05\" print ( \"Its now {:%I:%M %p}\" ) ## \"Its now 06:49 PM\" If a class has no __format__() method, the method inherited from object return str(my_object) .","title":"Formatted displays"},{"location":"python/cookbook_dabeaz/ch01/","text":"1.1: Unpacking a sequence into separate variables Problem You have a N-element tuple or sequence that you would like to unpack into a collection of N variables. Solution Any sequence or iterable can be unpacked into variables using a simple assignment operation. The only requirement is that the the number of variables and structure of the sequence must match . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##---------------------------------------------------------- p = ( 4 , 5 ) ## create a tuple x , y = p ## unpack the tuple into variables 'x' & 'y'. ## x=4; y=5 ##---------------------------------------------------------- data = [ \"ACME\" , 50 , 91.1 , ( 2021 , 10 , 07 )] name , shares , price , date = data ## unpack the list ## name=\"ACME\"; shares=50 ## price=91.1; date=(2021,10,07) ## another way to unpack the nested iterable or container ## name=\"ACME\"; shares=50; price=91.1; ## year = 2021; month=10; day=07 name , shares , price , ( year , month , day ) = data If there is a mismatch in the number of elements; you will get an ERROR. 1 2 p = ( 4 , 5 ) x , y , z = p 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> ValueError: need more than 2 values to unpack Discussion Unpacking actually works with any object that happens to be iterable (tuples, lists, dicts, str, files, iteratirs, generators...) 1.2: Unpacking elements from iterables of arbitrary length Problem You need to unpack N elements from an iterable ; but the iterable may be longer than N elements (causing a too many values to unpack exception) Solution 1.3 Keeping last N items Problem You want to keep a limited history of last few items seen during iteration. Solution Keeping a limited history is a perfect use for collections.deque 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \"\"\" Performs a simple text match on a sequence of lines and yields the matching line & previous N lines of context when found \"\"\" from collections import deque def search ( lines , pattern , history = 5 ): previous_lines = deque ( maxlen = history ) for line in lines : if pattern in line : yield line , previous_lines previous_lines . append ( line ) ##-----------------------------------------------------------## ## Example use ona file if __name__ == \"__main__\" : with open ( \"somefile.txt\" , \"r\" ) as f : for line , prev_lines in search ( f , \"my_pattern\" ): for x in lines : print ( x , end = \"\" ) print ( line , end = \"\" ) print ( \"--\" * 10 ) 1.5: Priority Queue Problem You want to implement a queue that sorts items by a given priority & always returns the item with highest priority on each pop operation. Solution The following class uses heapq module to implement a simple priority queue 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import heapq class PriorityQueue : def __init__ ( self ): self . _queue = [] self . _idx = 0 def __repr__ ( self ): return self . _queue def push ( self , item , priority ): ## because heappop returns the 1st item in the queue ## (which has the smallest priority); ## So, we need to invert the priority as (-priority) ## Thus, we get the item with highest priority on pop heapq . heappush ( self . _queue , ( - priority , self . _idx , item )) self . _idx += 1 def pop ( self ): \"\"\" Returns item with HIGHEST priority in the priority queue \"\"\" result = heapq . heappop ( self . _queue ) ## a tuple of type (-priority, idx, item) return result [ - 1 ] ## \"item\" from above line Here is an example of how we might use the above PriorityQueue class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Item : def __init__ ( self , name ): self . name = name def __repr__ ( self ): return f \"Item( { self . name } )\" ##-----------------------------------------------------------## q = PriorityQueue () ## Create a priority-queue object q . push ( Item ( \"foo\" ), priority = 1 ) ## push an Item(\"foo\") with priority=1 q . push ( Item ( \"bar\" ), priority = 5 ) ## push an Item(\"bar\") with priority=5 q . push ( Item ( \"spam\" ), priority = 4 ) ## push an Item(\"spam\") with priority=4 q . push ( Item ( \"grok\" ), priority = 1 ) ## push an Item(\"grok\") with priority=1 q . pop () ## Item(\"bar\") q . pop () ## Item(\"spam\") q . pop () ## Item(\"foo\") q . pop () ## Item(\"grok\") In the above example note that the items with same priority ( Item(\"foo\") and Item(\"grok\") ) are returned in the same order as they were inserted into the queue. Discussion The core of this recipe concerns with the use of heapq module. The methods heapq.heappush() and heapq.heappop() insert and remove items from self._queue in such a way that the first tem in the list has the smallest priority . The heappop() method always returns the smallest item; so that is the key idea to make our PriorityQueue pop correct items. In this recipe the queue consists of tuple (-priority, idx, item) . The priority value is negated to get the queue to sort items from highest priority to lowest priority . This is opposite from normal heap ordering; which sorts items from smallest to highest value. The role of the idx value is to properly order items with the same priority level. By keeping a constantly increasing index, the items will be sorted according to the order in which they were inserted. However, the idx also serves an important role in making the comparision work for items with the smae priority level. To elaborate on this, the instances of Item can't be ordered. 1 2 3 4 5 6 7 ## Item class objects cannot be compared; ## because we have not implemented __eq__, __le__ etc...methods to support it a = Item ( \"foo\" ) b = Item ( \"bar\" ) a < b ## ERROR. ## because \"Item\" object cannot be compared. 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> TypeError: unorderable types: Item () < Item () But, if you make (priority, item) tuple and compare them, then it works fine as long as the priorities are different. 1 2 3 4 5 6 7 ## tuples (priority, item) with different priorities. ## Comparision works fine a = ( 1 , Item ( \"foo\" )) b = ( 2 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because priority: 1 < 2 So, to handle the case of same priority value; the idx is used. The idx is always increasing and unique; so there is no chance of collision as shown below 1 2 3 4 5 6 7 ## Tuples (priority, idx, item) with same priorities but unique idx. ## Comparision works fine a = ( 1 , 7 , Item ( \"foo\" )) b = ( 1 , 8 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because idx: 7 < 8 1.6: collections.defaultdict Mapping Keys to multiple values in Dictionary You want to make a dictionary that maps keys to more than one value (so called multdict ) Solution A dictionary is a mapping where each key is mapped to a single value. If you want to map keys to multiple values ; you need to store multiple values in another container (like list or set or other container types ) 1 2 3 4 5 6 7 d = { \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 ], } e = { \"a\" : { 1 , 2 , 3 }, \"b\" : { 4 , 5 }, } 1. Use a list if you want to preserve the insertion-order of items. 2. Use a set if you want to eliminate duplicates . To easily construct such dictionaries, you can use collections.defaultdict . A feature of defaultdict is that it automatically initializes the first value so you can simply focus on adding items. 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( list ) ## use \"list\" as a constructor to initialize values map for new keys d [ \"a\" ] . append ( 1 ) ## d = {\"a\":[1]} d [ \"a\" ] . append ( 2 ) ## d = {\"a\":[1,2]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5,5]} duplication of 5 is allowed in list 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( set ) ## use \"set\" as a constructor to initialize values map for new keys d [ \"a\" ] . add ( 1 ) ## d = {\"a\": {1}} d [ \"a\" ] . add ( 2 ) ## d = {\"a\": {1,2}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} duplicates NOT allowed in \"set\" NOTE : One caution with defaultdict is that it will automatically create dictionary entries for keys accessed later on ( even if they aren't found in the dictionary ) i.e. instead of throwing KeyError for keys that are not found, it adds that key to the dictinary and maps its value to the empty constructor ( list or set etc. as above). If you want to avoid this behavior, its better to use usual dict() with setdefault() . This process is a bit messy and hard-to-read as shown below; but provides user-control to handle edge cases. 1 2 3 4 d = {} ## a regular dictionary d . setdefault ( \"a\" , []) . append ( 1 ) ## d = {\"a\": [1]} d . setdefault ( \"a\" , []) . append ( 2 ) ## d = {\"a\": [1,2]} d . setdefault ( \"b\" , []) . append ( 5 ) ## d = {\"a\": [1,2], \"b\": [5]} Discussion In principle, constructing a multivariate dictionary is simple. However, initialization of the first value can be messy if you try to do it yourself. Below two code-snippets show this tradeoff. 1 2 3 4 5 6 7 8 9 10 11 12 d = {} for key , value in pairs : if key not in d : d [ key ] = [] d [ key ] . append ( value ) ##--------------- v/s -----------------## from collections import defaultdict d = defaultdict () for key , value in items : d [ key ] . append ( value ) 1.9: Finding commonalities in two dictionaries Problem You have two dictionaries and you want to find what they have in common (like same keys , same values etc.) Solution Consider two dictionaries 1 2 a = { \"x\" : 1 , \"y\" : 2 , \"z\" : 3 } b = { \"w\" : 10 , \"x\" : 11 , \"y\" : 2 } To find out what the two dictionaries have in common, simply perform the common set operations using the keys() and values() methods. For example: 1 2 ## finding keys in common a . keys () & b . keys () ##{\"x\", \"y\"} 1 2 ## finding keys in a, that are not in b a . keys () - b . keys () ## {\"z\"} 1 2 ## finding (key, value) pair in common a . items () & b . items () ## {(\"y\", 2)} These kinds of operations can also be used to alter or filter dictionary contents. For, example, suppose you want to make a new dictionary with selected keys removed. Below is a sample code using a dictionary comprehension 1 2 ## make a new dictionary with certain keys removed c = { key : a [ key ] for key in a . keys () - { \"z\" , \"w\" }} ## {\"x\":1, \"y\":2} Discussion A dictionary is a mapping between a set of keys and values The .keys() method on a dict returns keys-view object of the dict. This keys-view object support common set operations like join , intersection , difference etc. These set operations are supported because it is guranteed that the keys of a dict are uniquely hashable. The .items() method on a dict returns items-view object consisting of (key, value) pairs. This items-view object also supports common set operations as above. The .values() method on the dict returns a values-view object consisting of values of the dict. BUT, this values-view object DOES-NOT SUPPORT common set operations because the values of a dict are not guranteed to be unique . Although, if necessary we can always convert this values-view object into a set and then perform required set-operations as usual. 1.10: Removing duplicates from a Sequence (maintaining order) Problem You want to remove duplicates from the sequence while maintaining order Solution If the values in a sequence are hashable, then we solve this problem by using set and generator 1 2 3 4 5 6 7 8 9 10 11 12 13 def dedupe ( items ): seen = set () for x in items : if x not in seen : yield x seen . add ( x ) ##----------------------------------## a = [ 1 , 5 , 2 , 1 , 9 , 1 , 5 , 10 ] list ( dedupe ( a )) ## [1, 5, 2, 9, 10] ## NOTE: above the order of the items in the output list is maintained according to the input \"a\" But this above solution is valid only if the items in the sequence are hashable . For sequences, which have unhashable items (like dict ), the below solution works: 1 2 3 4 5 6 7 def dedupe_unhashable ( items , key = None ): seen = set () for item in items : val = item if key is None else key ( item ) if val not in seen : yield item seen . add ( item ) Here, the purpose of the key argument is to specify a function that converts sequence items into hashable type for the purpose of duplicate detection . For example: 1 2 3 4 5 a = [{ \"x\" : 1 , \"y\" : 2 }, { \"x\" : 1 , \"y\" : 3 }, { \"X\" : 1 , \"y\" : 2 }, { \"x\" : 2 , \"y\" : 4 } ] 1 list ( dedupe_unhashable ( a , key = lambda d : ( d [ \"x\" ], d [ \"y\" ]))) 1 2 3 [{ \"x\" :1, \"y\" :2 } , { \"x\" :1, \"y\" :3 } , { \"x\" :2, \"y\" :4 }] 1 list ( dedupe_unhashable ( a , key = lambda d : ( d [ \"x\" ]))) 1 2 [{ \"x\" :1, \"y\" :2 } , { \"x\" :2, \"y\" :4 }] This solution will work for any kind of data structure and a key function that returns a hashable value 1.12: Frequency of items in a Sequence Problem You have a sequence of hashable items asn you would want ot count the frequency of each item in the sequence. Solution Use collections.Counter Suppose we are give a list of strings words as shown below and we want to find the frequency of each word in the list 1 2 3 4 5 6 words = [ 'look' , 'into' , 'my' , 'eyes' , 'look' , 'into' , 'my' , 'eyes' , 'the' , 'eyes' , 'the' , 'eyes' , 'the' , 'eyes' , 'not' , 'around' , 'the' , 'eyes' , \"don't\" , 'look' , 'around' , 'the' , 'eyes' , 'look' , 'into' , 'my' , 'eyes' , \"you're\" , 'under' ] 1 2 3 4 5 from collections import Counter word_counts = Counter ( words ) top_three = word_counts . most_common ( 3 ) ## returns the 3 most common items print ( top_three ) ## [('eyes', 8), ('the', 5), ('look', 4)] The Counter class has a method most_common() which returns the topn \"n\" most common items in the sequence. Discussion As input, the Counter object can be fed any sequence of hashable items. The Counter object is basically just a dictionary that holds the unique items in the input sequence as its keys and their resepective counts as its values . If you want to increment the count manually , simply use addition op. 1 2 3 morewords = [ 'why' , 'are' , 'you' , 'not' , 'looking' , 'in' , 'my' , 'eyes' ] for word in morewords : word_counts [ word ] += 1 Alternative, you can also use update method on the Counter object to update the counter object. 1 word_counts . update ( morewords ) ## does the same work as the above addiotion op. The Counter object also supports common mathematical operations like sum , difference etc. 1 2 3 4 5 6 7 8 9 10 11 12 from collections import Counter words = [ \"hello\" , \"world\" , \"hello\" , \"world\" , \"earth\" ] morewords = [ \"hello\" , \"vinay\" , \"earth\" ] a = Counter ( words ) ## {\"hello\":2, \"world\":2, \"earth\":1} b = Counter ( morewords ) ## {\"hello\":1, \"vinay\":1, \"earth\":1} ## adding the two counter objects together a + b ## {\"hello\":3, \"world\":2, \"earth\":2, \"vinay\":1} ## subtracting the two counter objects a - b ## {\"hello\":1, \"world\":2, \"vinay\":1} 1.13: Sorting a List of dicts by a common key Problem You have a list of dictionaries and you would like to sort the items according to one or more of the dict values Solution Sorting this type of structure is easy using operator module's itemgetter() function. Let's say you've queried a database table to get a listing of the members on your website, and you receive the following data structure in return. 1 2 3 4 5 6 rows = [ { 'fname' : 'Brian' , 'lname' : 'Jones' , 'uid' : 1003 }, { 'fname' : 'David' , 'lname' : 'Beazley' , 'uid' : 1002 }, { 'fname' : 'John' , 'lname' : 'Cleese' , 'uid' : 1001 }, { 'fname' : 'Big' , 'lname' : 'Jones' , 'uid' : 1004 } ] It is fairly easy to output these rows ordered by any of the fields common to all of the rows in the dict. For example: 1 2 3 4 from operator import itemgetter rows_by_fname = sorted ( rows , key = itemgetter ( \"fname\" )) rows_by_uid = sorted ( rows , key = itemgetter ( \"uid\" )) 1 print ( rows_by_fname ) 1 2 3 4 [{'fname': 'Big', 'uid': 1004, 'lname': 'Jones'}, {'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'}, {'fname': 'David', 'uid': 1002, 'lname': 'Beazley'}, {'fname': 'John', 'uid': 1001, 'lname': 'Cleese'}] 1 print ( rows_by_uid ) 1 2 3 4 [{'fname': 'John', 'uid': 1001, 'lname': 'Cleese'}, {'fname': 'David', 'uid': 1002, 'lname': 'Beazley'}, {'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'}, {'fname': 'Big', 'uid': 1004, 'lname': 'Jones'}] The itemgetter() function also accepts multiple keys as arguments 1 2 rows_by_lfname = sorted ( rows , key = itemgetter ( \"lname\" , \"fname\" )) print ( rows_by_lfname ) 1 2 3 4 [{'fname': 'David', 'uid': 1002, 'lname': 'Beazley'}, {'fname': 'John', 'uid': 1001, 'lname': 'Cleese'}, {'fname': 'Big', 'uid': 1004, 'lname': 'Jones'}, {'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'}] Discussion In this example, rows is passed to the built-in sorted() function which accepts a keyword argument key . The key argument is expected to be a callable that accepts a single item from rows as input and returns a single value that is used as a basis for sorting. The itemgetter() is just such a callable. The operator.itemgetter() function takes as argument the lookup indices which is used to extract the desired values from the records in the rows . It can be a dictionary key name, a numeric list element, or any value that can be fed to the object's __getitem__() method. If you give multiple indices to itemgetter() , the callable it produces will return a tuple with all the indexed elements into it; which is then passed to the sorted() function. This is important if you want to simulatenously sort on multiple fields (as shown in above example rows_by_lfname , ie.e sorting by lname first then by fname ). The functionality of itemgetter() is sometimes replaced by lambda expressions, 1 2 rows_by_fanme = sorted ( rows , key = lambda r : r [ \"fname\" ]) rows_by_lfname = sorted ( rows , key = lambda r : ( r [ \"lname\" ], r [ \"fname\" ])) But itemgetter() is faster than lambda expressions. Note that this technique can also be used for other functions that does their operations which require key callable function such as min() , max() etc. 1 2 3 from operator import itemgetter min ( rows , key = itemgetter ( \"uid\" )) ## {'fname': 'John', 'lname': 'Cleese', 'uid': 1001} max ( rows , key = itemgetter ( \"uid\" )) ## {'fname': 'Big', 'lname': 'Jones', 'uid': 1004} 1.14: Sorting objects w/o native comparision support Problem You want to sort objects of the same class; but they don't natively support comparision operation. Solution The built-in sorted() function takes a key argument that can be passed a callable that will return a value in the object that sorted() will use to compare the objects. For example, if you have sequence of User instances and you want to sort the items in the sequence using their used_id attribute; you would supply a callable that will take a User instance as input and return the user_id of that input which can then be used by sorted() function as a key to sort the instances in the sequence. This is illustrated in the below code. 1 2 3 4 5 6 7 8 9 10 11 12 class User : def __init__ ( self , user_id ): self . user_id = user_id def __repr__ ( self ): return f \"User( { self . user_id } )\" ## ---------------------------------------------- ## users = [ User ( 23 ), User ( 1 ), User ( 9 )] sorted ( users , key = lambda u : u . user_id ) ## [User(1), User(9), User(23)] Instead of using lambda , you can use a faster operator.attrgetter() function 1 2 from operator import attrgetter sorted ( users , key = attrgetter ( \"user_id\" )) ## [user(1), User(9), User(23)] Discussion The choice of whether to use lambda or operator.attrgetter() is personal, but operator.attrgetter() is a bit faster and supports multiple attribute indexing as shown below. Suppose the User class has two attributes user_id and user_name and we want to sort sequence of User instances based on both these attributes; then we can use operator.attrgetter() very easily. 1 2 3 4 from operator import attrgetter ## assume that \"User\" class has two attributes \"user_id\" and \"user_name\" sorted ( users , key = attrgetter ( \"user_id\" , \"user_name\" )) This behavior of attrgetter() is analogous to itemgetter() function (used for dictionaries ) Similar to itemgetter() , we can use attrgetter() for other comparision operations that require a key attribute such as min() , max() etc. 1 2 min ( users , key = attrgetter ( \"user_id\" )) max ( users , key = attrgetter ( \"user_id\" ))","title":"1. Data Structures & Algorithms"},{"location":"python/cookbook_dabeaz/ch01/#11-unpacking-a-sequence-into-separate-variables","text":"Problem You have a N-element tuple or sequence that you would like to unpack into a collection of N variables. Solution Any sequence or iterable can be unpacked into variables using a simple assignment operation. The only requirement is that the the number of variables and structure of the sequence must match . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ##---------------------------------------------------------- p = ( 4 , 5 ) ## create a tuple x , y = p ## unpack the tuple into variables 'x' & 'y'. ## x=4; y=5 ##---------------------------------------------------------- data = [ \"ACME\" , 50 , 91.1 , ( 2021 , 10 , 07 )] name , shares , price , date = data ## unpack the list ## name=\"ACME\"; shares=50 ## price=91.1; date=(2021,10,07) ## another way to unpack the nested iterable or container ## name=\"ACME\"; shares=50; price=91.1; ## year = 2021; month=10; day=07 name , shares , price , ( year , month , day ) = data If there is a mismatch in the number of elements; you will get an ERROR. 1 2 p = ( 4 , 5 ) x , y , z = p 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> ValueError: need more than 2 values to unpack Discussion Unpacking actually works with any object that happens to be iterable (tuples, lists, dicts, str, files, iteratirs, generators...)","title":"1.1: Unpacking a sequence into separate variables"},{"location":"python/cookbook_dabeaz/ch01/#12-unpacking-elements-from-iterables-of-arbitrary-length","text":"Problem You need to unpack N elements from an iterable ; but the iterable may be longer than N elements (causing a too many values to unpack exception) Solution","title":"1.2: Unpacking elements from iterables of arbitrary length"},{"location":"python/cookbook_dabeaz/ch01/#13-keeping-last-n-items","text":"Problem You want to keep a limited history of last few items seen during iteration. Solution Keeping a limited history is a perfect use for collections.deque 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \"\"\" Performs a simple text match on a sequence of lines and yields the matching line & previous N lines of context when found \"\"\" from collections import deque def search ( lines , pattern , history = 5 ): previous_lines = deque ( maxlen = history ) for line in lines : if pattern in line : yield line , previous_lines previous_lines . append ( line ) ##-----------------------------------------------------------## ## Example use ona file if __name__ == \"__main__\" : with open ( \"somefile.txt\" , \"r\" ) as f : for line , prev_lines in search ( f , \"my_pattern\" ): for x in lines : print ( x , end = \"\" ) print ( line , end = \"\" ) print ( \"--\" * 10 )","title":"1.3 Keeping last N items"},{"location":"python/cookbook_dabeaz/ch01/#15-priority-queue","text":"Problem You want to implement a queue that sorts items by a given priority & always returns the item with highest priority on each pop operation. Solution The following class uses heapq module to implement a simple priority queue 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import heapq class PriorityQueue : def __init__ ( self ): self . _queue = [] self . _idx = 0 def __repr__ ( self ): return self . _queue def push ( self , item , priority ): ## because heappop returns the 1st item in the queue ## (which has the smallest priority); ## So, we need to invert the priority as (-priority) ## Thus, we get the item with highest priority on pop heapq . heappush ( self . _queue , ( - priority , self . _idx , item )) self . _idx += 1 def pop ( self ): \"\"\" Returns item with HIGHEST priority in the priority queue \"\"\" result = heapq . heappop ( self . _queue ) ## a tuple of type (-priority, idx, item) return result [ - 1 ] ## \"item\" from above line Here is an example of how we might use the above PriorityQueue class 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Item : def __init__ ( self , name ): self . name = name def __repr__ ( self ): return f \"Item( { self . name } )\" ##-----------------------------------------------------------## q = PriorityQueue () ## Create a priority-queue object q . push ( Item ( \"foo\" ), priority = 1 ) ## push an Item(\"foo\") with priority=1 q . push ( Item ( \"bar\" ), priority = 5 ) ## push an Item(\"bar\") with priority=5 q . push ( Item ( \"spam\" ), priority = 4 ) ## push an Item(\"spam\") with priority=4 q . push ( Item ( \"grok\" ), priority = 1 ) ## push an Item(\"grok\") with priority=1 q . pop () ## Item(\"bar\") q . pop () ## Item(\"spam\") q . pop () ## Item(\"foo\") q . pop () ## Item(\"grok\") In the above example note that the items with same priority ( Item(\"foo\") and Item(\"grok\") ) are returned in the same order as they were inserted into the queue. Discussion The core of this recipe concerns with the use of heapq module. The methods heapq.heappush() and heapq.heappop() insert and remove items from self._queue in such a way that the first tem in the list has the smallest priority . The heappop() method always returns the smallest item; so that is the key idea to make our PriorityQueue pop correct items. In this recipe the queue consists of tuple (-priority, idx, item) . The priority value is negated to get the queue to sort items from highest priority to lowest priority . This is opposite from normal heap ordering; which sorts items from smallest to highest value. The role of the idx value is to properly order items with the same priority level. By keeping a constantly increasing index, the items will be sorted according to the order in which they were inserted. However, the idx also serves an important role in making the comparision work for items with the smae priority level. To elaborate on this, the instances of Item can't be ordered. 1 2 3 4 5 6 7 ## Item class objects cannot be compared; ## because we have not implemented __eq__, __le__ etc...methods to support it a = Item ( \"foo\" ) b = Item ( \"bar\" ) a < b ## ERROR. ## because \"Item\" object cannot be compared. 1 2 3 Traceback ( most recent call last ) : File \"<stdin>\" , line 1 , in <module> TypeError: unorderable types: Item () < Item () But, if you make (priority, item) tuple and compare them, then it works fine as long as the priorities are different. 1 2 3 4 5 6 7 ## tuples (priority, item) with different priorities. ## Comparision works fine a = ( 1 , Item ( \"foo\" )) b = ( 2 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because priority: 1 < 2 So, to handle the case of same priority value; the idx is used. The idx is always increasing and unique; so there is no chance of collision as shown below 1 2 3 4 5 6 7 ## Tuples (priority, idx, item) with same priorities but unique idx. ## Comparision works fine a = ( 1 , 7 , Item ( \"foo\" )) b = ( 1 , 8 , Item ( \"bar\" )) a < b ## Returns \"True\" ## because idx: 7 < 8","title":"1.5: Priority Queue"},{"location":"python/cookbook_dabeaz/ch01/#16-collectionsdefaultdict","text":"Mapping Keys to multiple values in Dictionary You want to make a dictionary that maps keys to more than one value (so called multdict ) Solution A dictionary is a mapping where each key is mapped to a single value. If you want to map keys to multiple values ; you need to store multiple values in another container (like list or set or other container types ) 1 2 3 4 5 6 7 d = { \"a\" : [ 1 , 2 , 3 ], \"b\" : [ 4 , 5 ], } e = { \"a\" : { 1 , 2 , 3 }, \"b\" : { 4 , 5 }, } 1. Use a list if you want to preserve the insertion-order of items. 2. Use a set if you want to eliminate duplicates . To easily construct such dictionaries, you can use collections.defaultdict . A feature of defaultdict is that it automatically initializes the first value so you can simply focus on adding items. 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( list ) ## use \"list\" as a constructor to initialize values map for new keys d [ \"a\" ] . append ( 1 ) ## d = {\"a\":[1]} d [ \"a\" ] . append ( 2 ) ## d = {\"a\":[1,2]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5]} d [ \"b\" ] . append ( 5 ) ## d = {\"a\":[1,2], \"b\":[5,5]} duplication of 5 is allowed in list 1 2 3 4 5 6 7 from collections import defaultdict d = defaultdict ( set ) ## use \"set\" as a constructor to initialize values map for new keys d [ \"a\" ] . add ( 1 ) ## d = {\"a\": {1}} d [ \"a\" ] . add ( 2 ) ## d = {\"a\": {1,2}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} d [ \"b\" ] . add ( 5 ) ## d = {\"a\": {1,2}, \"b\": {5}} duplicates NOT allowed in \"set\" NOTE : One caution with defaultdict is that it will automatically create dictionary entries for keys accessed later on ( even if they aren't found in the dictionary ) i.e. instead of throwing KeyError for keys that are not found, it adds that key to the dictinary and maps its value to the empty constructor ( list or set etc. as above). If you want to avoid this behavior, its better to use usual dict() with setdefault() . This process is a bit messy and hard-to-read as shown below; but provides user-control to handle edge cases. 1 2 3 4 d = {} ## a regular dictionary d . setdefault ( \"a\" , []) . append ( 1 ) ## d = {\"a\": [1]} d . setdefault ( \"a\" , []) . append ( 2 ) ## d = {\"a\": [1,2]} d . setdefault ( \"b\" , []) . append ( 5 ) ## d = {\"a\": [1,2], \"b\": [5]} Discussion In principle, constructing a multivariate dictionary is simple. However, initialization of the first value can be messy if you try to do it yourself. Below two code-snippets show this tradeoff. 1 2 3 4 5 6 7 8 9 10 11 12 d = {} for key , value in pairs : if key not in d : d [ key ] = [] d [ key ] . append ( value ) ##--------------- v/s -----------------## from collections import defaultdict d = defaultdict () for key , value in items : d [ key ] . append ( value )","title":"1.6: collections.defaultdict"},{"location":"python/cookbook_dabeaz/ch01/#19-finding-commonalities-in-two-dictionaries","text":"Problem You have two dictionaries and you want to find what they have in common (like same keys , same values etc.) Solution Consider two dictionaries 1 2 a = { \"x\" : 1 , \"y\" : 2 , \"z\" : 3 } b = { \"w\" : 10 , \"x\" : 11 , \"y\" : 2 } To find out what the two dictionaries have in common, simply perform the common set operations using the keys() and values() methods. For example: 1 2 ## finding keys in common a . keys () & b . keys () ##{\"x\", \"y\"} 1 2 ## finding keys in a, that are not in b a . keys () - b . keys () ## {\"z\"} 1 2 ## finding (key, value) pair in common a . items () & b . items () ## {(\"y\", 2)} These kinds of operations can also be used to alter or filter dictionary contents. For, example, suppose you want to make a new dictionary with selected keys removed. Below is a sample code using a dictionary comprehension 1 2 ## make a new dictionary with certain keys removed c = { key : a [ key ] for key in a . keys () - { \"z\" , \"w\" }} ## {\"x\":1, \"y\":2} Discussion A dictionary is a mapping between a set of keys and values The .keys() method on a dict returns keys-view object of the dict. This keys-view object support common set operations like join , intersection , difference etc. These set operations are supported because it is guranteed that the keys of a dict are uniquely hashable. The .items() method on a dict returns items-view object consisting of (key, value) pairs. This items-view object also supports common set operations as above. The .values() method on the dict returns a values-view object consisting of values of the dict. BUT, this values-view object DOES-NOT SUPPORT common set operations because the values of a dict are not guranteed to be unique . Although, if necessary we can always convert this values-view object into a set and then perform required set-operations as usual.","title":"1.9: Finding commonalities in two dictionaries"},{"location":"python/cookbook_dabeaz/ch01/#110-removing-duplicates-from-a-sequence-maintaining-order","text":"Problem You want to remove duplicates from the sequence while maintaining order Solution If the values in a sequence are hashable, then we solve this problem by using set and generator 1 2 3 4 5 6 7 8 9 10 11 12 13 def dedupe ( items ): seen = set () for x in items : if x not in seen : yield x seen . add ( x ) ##----------------------------------## a = [ 1 , 5 , 2 , 1 , 9 , 1 , 5 , 10 ] list ( dedupe ( a )) ## [1, 5, 2, 9, 10] ## NOTE: above the order of the items in the output list is maintained according to the input \"a\" But this above solution is valid only if the items in the sequence are hashable . For sequences, which have unhashable items (like dict ), the below solution works: 1 2 3 4 5 6 7 def dedupe_unhashable ( items , key = None ): seen = set () for item in items : val = item if key is None else key ( item ) if val not in seen : yield item seen . add ( item ) Here, the purpose of the key argument is to specify a function that converts sequence items into hashable type for the purpose of duplicate detection . For example: 1 2 3 4 5 a = [{ \"x\" : 1 , \"y\" : 2 }, { \"x\" : 1 , \"y\" : 3 }, { \"X\" : 1 , \"y\" : 2 }, { \"x\" : 2 , \"y\" : 4 } ] 1 list ( dedupe_unhashable ( a , key = lambda d : ( d [ \"x\" ], d [ \"y\" ]))) 1 2 3 [{ \"x\" :1, \"y\" :2 } , { \"x\" :1, \"y\" :3 } , { \"x\" :2, \"y\" :4 }] 1 list ( dedupe_unhashable ( a , key = lambda d : ( d [ \"x\" ]))) 1 2 [{ \"x\" :1, \"y\" :2 } , { \"x\" :2, \"y\" :4 }] This solution will work for any kind of data structure and a key function that returns a hashable value","title":"1.10: Removing duplicates from a Sequence (maintaining order)"},{"location":"python/cookbook_dabeaz/ch01/#112-frequency-of-items-in-a-sequence","text":"Problem You have a sequence of hashable items asn you would want ot count the frequency of each item in the sequence. Solution Use collections.Counter Suppose we are give a list of strings words as shown below and we want to find the frequency of each word in the list 1 2 3 4 5 6 words = [ 'look' , 'into' , 'my' , 'eyes' , 'look' , 'into' , 'my' , 'eyes' , 'the' , 'eyes' , 'the' , 'eyes' , 'the' , 'eyes' , 'not' , 'around' , 'the' , 'eyes' , \"don't\" , 'look' , 'around' , 'the' , 'eyes' , 'look' , 'into' , 'my' , 'eyes' , \"you're\" , 'under' ] 1 2 3 4 5 from collections import Counter word_counts = Counter ( words ) top_three = word_counts . most_common ( 3 ) ## returns the 3 most common items print ( top_three ) ## [('eyes', 8), ('the', 5), ('look', 4)] The Counter class has a method most_common() which returns the topn \"n\" most common items in the sequence. Discussion As input, the Counter object can be fed any sequence of hashable items. The Counter object is basically just a dictionary that holds the unique items in the input sequence as its keys and their resepective counts as its values . If you want to increment the count manually , simply use addition op. 1 2 3 morewords = [ 'why' , 'are' , 'you' , 'not' , 'looking' , 'in' , 'my' , 'eyes' ] for word in morewords : word_counts [ word ] += 1 Alternative, you can also use update method on the Counter object to update the counter object. 1 word_counts . update ( morewords ) ## does the same work as the above addiotion op. The Counter object also supports common mathematical operations like sum , difference etc. 1 2 3 4 5 6 7 8 9 10 11 12 from collections import Counter words = [ \"hello\" , \"world\" , \"hello\" , \"world\" , \"earth\" ] morewords = [ \"hello\" , \"vinay\" , \"earth\" ] a = Counter ( words ) ## {\"hello\":2, \"world\":2, \"earth\":1} b = Counter ( morewords ) ## {\"hello\":1, \"vinay\":1, \"earth\":1} ## adding the two counter objects together a + b ## {\"hello\":3, \"world\":2, \"earth\":2, \"vinay\":1} ## subtracting the two counter objects a - b ## {\"hello\":1, \"world\":2, \"vinay\":1}","title":"1.12: Frequency of items in a Sequence"},{"location":"python/cookbook_dabeaz/ch01/#113-sorting-a-list-of-dicts-by-a-common-key","text":"Problem You have a list of dictionaries and you would like to sort the items according to one or more of the dict values Solution Sorting this type of structure is easy using operator module's itemgetter() function. Let's say you've queried a database table to get a listing of the members on your website, and you receive the following data structure in return. 1 2 3 4 5 6 rows = [ { 'fname' : 'Brian' , 'lname' : 'Jones' , 'uid' : 1003 }, { 'fname' : 'David' , 'lname' : 'Beazley' , 'uid' : 1002 }, { 'fname' : 'John' , 'lname' : 'Cleese' , 'uid' : 1001 }, { 'fname' : 'Big' , 'lname' : 'Jones' , 'uid' : 1004 } ] It is fairly easy to output these rows ordered by any of the fields common to all of the rows in the dict. For example: 1 2 3 4 from operator import itemgetter rows_by_fname = sorted ( rows , key = itemgetter ( \"fname\" )) rows_by_uid = sorted ( rows , key = itemgetter ( \"uid\" )) 1 print ( rows_by_fname ) 1 2 3 4 [{'fname': 'Big', 'uid': 1004, 'lname': 'Jones'}, {'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'}, {'fname': 'David', 'uid': 1002, 'lname': 'Beazley'}, {'fname': 'John', 'uid': 1001, 'lname': 'Cleese'}] 1 print ( rows_by_uid ) 1 2 3 4 [{'fname': 'John', 'uid': 1001, 'lname': 'Cleese'}, {'fname': 'David', 'uid': 1002, 'lname': 'Beazley'}, {'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'}, {'fname': 'Big', 'uid': 1004, 'lname': 'Jones'}] The itemgetter() function also accepts multiple keys as arguments 1 2 rows_by_lfname = sorted ( rows , key = itemgetter ( \"lname\" , \"fname\" )) print ( rows_by_lfname ) 1 2 3 4 [{'fname': 'David', 'uid': 1002, 'lname': 'Beazley'}, {'fname': 'John', 'uid': 1001, 'lname': 'Cleese'}, {'fname': 'Big', 'uid': 1004, 'lname': 'Jones'}, {'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'}] Discussion In this example, rows is passed to the built-in sorted() function which accepts a keyword argument key . The key argument is expected to be a callable that accepts a single item from rows as input and returns a single value that is used as a basis for sorting. The itemgetter() is just such a callable. The operator.itemgetter() function takes as argument the lookup indices which is used to extract the desired values from the records in the rows . It can be a dictionary key name, a numeric list element, or any value that can be fed to the object's __getitem__() method. If you give multiple indices to itemgetter() , the callable it produces will return a tuple with all the indexed elements into it; which is then passed to the sorted() function. This is important if you want to simulatenously sort on multiple fields (as shown in above example rows_by_lfname , ie.e sorting by lname first then by fname ). The functionality of itemgetter() is sometimes replaced by lambda expressions, 1 2 rows_by_fanme = sorted ( rows , key = lambda r : r [ \"fname\" ]) rows_by_lfname = sorted ( rows , key = lambda r : ( r [ \"lname\" ], r [ \"fname\" ])) But itemgetter() is faster than lambda expressions. Note that this technique can also be used for other functions that does their operations which require key callable function such as min() , max() etc. 1 2 3 from operator import itemgetter min ( rows , key = itemgetter ( \"uid\" )) ## {'fname': 'John', 'lname': 'Cleese', 'uid': 1001} max ( rows , key = itemgetter ( \"uid\" )) ## {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}","title":"1.13: Sorting a List of dicts by a common key"},{"location":"python/cookbook_dabeaz/ch01/#114-sorting-objects-wo-native-comparision-support","text":"Problem You want to sort objects of the same class; but they don't natively support comparision operation. Solution The built-in sorted() function takes a key argument that can be passed a callable that will return a value in the object that sorted() will use to compare the objects. For example, if you have sequence of User instances and you want to sort the items in the sequence using their used_id attribute; you would supply a callable that will take a User instance as input and return the user_id of that input which can then be used by sorted() function as a key to sort the instances in the sequence. This is illustrated in the below code. 1 2 3 4 5 6 7 8 9 10 11 12 class User : def __init__ ( self , user_id ): self . user_id = user_id def __repr__ ( self ): return f \"User( { self . user_id } )\" ## ---------------------------------------------- ## users = [ User ( 23 ), User ( 1 ), User ( 9 )] sorted ( users , key = lambda u : u . user_id ) ## [User(1), User(9), User(23)] Instead of using lambda , you can use a faster operator.attrgetter() function 1 2 from operator import attrgetter sorted ( users , key = attrgetter ( \"user_id\" )) ## [user(1), User(9), User(23)] Discussion The choice of whether to use lambda or operator.attrgetter() is personal, but operator.attrgetter() is a bit faster and supports multiple attribute indexing as shown below. Suppose the User class has two attributes user_id and user_name and we want to sort sequence of User instances based on both these attributes; then we can use operator.attrgetter() very easily. 1 2 3 4 from operator import attrgetter ## assume that \"User\" class has two attributes \"user_id\" and \"user_name\" sorted ( users , key = attrgetter ( \"user_id\" , \"user_name\" )) This behavior of attrgetter() is analogous to itemgetter() function (used for dictionaries ) Similar to itemgetter() , we can use attrgetter() for other comparision operations that require a key attribute such as min() , max() etc. 1 2 min ( users , key = attrgetter ( \"user_id\" )) max ( users , key = attrgetter ( \"user_id\" ))","title":"1.14: Sorting objects w/o native comparision support"},{"location":"python/cookbook_dabeaz/ch02/","text":"Almost every useful program involve some kind of text processing whether it is data or generating output. Here we discuss about challenges involving text manipulation searching , substitution , lexing , parsing etc. Many of these problems can be easily solved with built-in methods. While more complicated operations might require the use of regular expressions . 2.1: Splitting string on any of multiple delimeters Problem You need to split the string into fields but the delimiters (and the space around them) aren't consistent throughtout the string. Solution The str.split() method of string objects is really meant for very simple use cases and doesn't allow for multiple delimiters . In case you need a bit more flexibility use re.split() instead as shown below. 1 2 3 4 5 6 import re line = \"vinay kumar, ram; lakshmi, devi anil-kumar-ram\" re . split ( r \"[;,-\\s]\\s*\" , line ) ## [\"vinay\", \"kumar\", \"ram\", \"lakshmi\", \"devi\", \"anil\", \"kumar\", \"ram\"] Here in the above re.split(r\"[;,-\\s]\\s*\", line) the delimiter is either a semi-colon ( ; ), a comma ( , ), a hyphen ( - ), a single space ( ) or any of these followed by any number of spaces . Discussion The re.split() is useful because you can specify multiple patterns for the delimiter . In the above solution using re.split() , the separator/delimiter is either a semi-colon ( ; ), a comma ( , ), a hyphen ( - ), a single space ( ) or any of these followed by any number of spaces . Whenever that pattern is found, the entire match becomes a delimiter between whatever fileds lie on either side of the match. The result is list of fileds just like str.split() When using re.split() , you need to be a bit careful if the regular expression involves a capture group enclosed in parenthesis . If capture groups are used, then the matched text (i.e. the delimiter/separator) is also included in the result as shown below. 1 2 3 4 5 6 7 8 import re line = \"vinay kumar, ram; lakshmi, devi anil-kumar-ram\" fields = re . split ( r \"(;|,|-|\\s)\\s*\" , line ) print ( fields ) ## [\"vinay\", \" \", \"kumar\", \",\", \"ram\", \";\", \"laksmi\", \",\", \"devi\", \" \", \"anil\", \"-\", \"kumar\", \"-\", \"ram\"] Getting the split characters / delimiters / separators might be useful in certain contexts. For example, you may want ot use the split characters later on to reform the output string. 1 2 3 4 5 values = fields [:: 2 ] ## [\"vinay\", \"kumar\", \"ram\", \"lakshmi\", \"devi\", \"anil\", \"kumar\", \"ram\"] delimiters = fields [ 1 :: 2 ] + [ \"\" ] ## [\" \", \",\", \";\", \"-\", \" \", \"-\", \"-\", \"\"] ## reform the line using the same delimiters \"\" . join ( v + d for v , d in zip ( values , delimiters )) ## \"vinay kumar,ram;lakshmi,devi anil-kumar-ram\" If you don't want the separator/delimiter to be in the result list but still need to use the parenthesis () to group parts of the regular expression pattern; then use a non-capture group specified by (?:...) as shown below. 1 re . split ( r \"(?:;|,|-|\\s)\\s*\" , line ) ## [\"vinay\", \"kumar\", \"ram\", \"lakshmi\", \"devi\", \"anil\", \"kumar\", \"ram\"]","title":"2. Strings & Texts"},{"location":"python/cookbook_dabeaz/ch02/#21-splitting-string-on-any-of-multiple-delimeters","text":"Problem You need to split the string into fields but the delimiters (and the space around them) aren't consistent throughtout the string. Solution The str.split() method of string objects is really meant for very simple use cases and doesn't allow for multiple delimiters . In case you need a bit more flexibility use re.split() instead as shown below. 1 2 3 4 5 6 import re line = \"vinay kumar, ram; lakshmi, devi anil-kumar-ram\" re . split ( r \"[;,-\\s]\\s*\" , line ) ## [\"vinay\", \"kumar\", \"ram\", \"lakshmi\", \"devi\", \"anil\", \"kumar\", \"ram\"] Here in the above re.split(r\"[;,-\\s]\\s*\", line) the delimiter is either a semi-colon ( ; ), a comma ( , ), a hyphen ( - ), a single space ( ) or any of these followed by any number of spaces . Discussion The re.split() is useful because you can specify multiple patterns for the delimiter . In the above solution using re.split() , the separator/delimiter is either a semi-colon ( ; ), a comma ( , ), a hyphen ( - ), a single space ( ) or any of these followed by any number of spaces . Whenever that pattern is found, the entire match becomes a delimiter between whatever fileds lie on either side of the match. The result is list of fileds just like str.split() When using re.split() , you need to be a bit careful if the regular expression involves a capture group enclosed in parenthesis . If capture groups are used, then the matched text (i.e. the delimiter/separator) is also included in the result as shown below. 1 2 3 4 5 6 7 8 import re line = \"vinay kumar, ram; lakshmi, devi anil-kumar-ram\" fields = re . split ( r \"(;|,|-|\\s)\\s*\" , line ) print ( fields ) ## [\"vinay\", \" \", \"kumar\", \",\", \"ram\", \";\", \"laksmi\", \",\", \"devi\", \" \", \"anil\", \"-\", \"kumar\", \"-\", \"ram\"] Getting the split characters / delimiters / separators might be useful in certain contexts. For example, you may want ot use the split characters later on to reform the output string. 1 2 3 4 5 values = fields [:: 2 ] ## [\"vinay\", \"kumar\", \"ram\", \"lakshmi\", \"devi\", \"anil\", \"kumar\", \"ram\"] delimiters = fields [ 1 :: 2 ] + [ \"\" ] ## [\" \", \",\", \";\", \"-\", \" \", \"-\", \"-\", \"\"] ## reform the line using the same delimiters \"\" . join ( v + d for v , d in zip ( values , delimiters )) ## \"vinay kumar,ram;lakshmi,devi anil-kumar-ram\" If you don't want the separator/delimiter to be in the result list but still need to use the parenthesis () to group parts of the regular expression pattern; then use a non-capture group specified by (?:...) as shown below. 1 re . split ( r \"(?:;|,|-|\\s)\\s*\" , line ) ## [\"vinay\", \"kumar\", \"ram\", \"lakshmi\", \"devi\", \"anil\", \"kumar\", \"ram\"]","title":"2.1: Splitting string on any of multiple delimeters"},{"location":"python/cookbook_dabeaz/ch03/","text":"","title":"Ch03"},{"location":"python/cookbook_dabeaz/ch04/","text":"Iterators are one of Python's most powerful features. At a high level, you might view iteration simply as a way to process items in a sequence, but there is much more than this such as creating your own iterator object, applying useful iterator patterns in itertools module, make generator functions etc. 4.1: Manually consuming an iterator problem You wan tto consume items in an iterable but for whatever reasons you can't or don't want to use a for loop Solution To manually consume the iterable , use the next() function and write code to catch the StopIteration exception as shown below. 1 2 3 4 5 6 7 with open ( \"etc/passwd\" ) as f : try : while True : line = next ( f ) print ( line , end = \"\" ) except StopIteration : pass Normally StopIteration exception is used to signal the end of the sequence. But, if you are using next , you can instruct next() to return a terminating value like None as shown below. 1 2 3 4 5 6 7 with open ( \"etc/passwd\" ) as f : try : while True : line = next ( f , None ) if line is None : break print ( line , end = \"\" ) Discussion In most cases the for is used to consume the iterable. However every now and then a problem statement calls for precise control over the underlying mechanism. The below example explains what happens underneath the iteration protocol. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> items = [ 1 , 2 , 3 ] ## the iterable >>> >>> ## Get the iterator >>> it = iter ( items ) ## invokes \"items.__iter__()\" >>> next ( it ) ## invokes \"items.__next__()\" 1 >>> next ( it ) 2 >>> next ( it ) 3 >>> next ( it ) ## this triggers \"StopIteration\" exception b'coz the iterator \"it\" is empty now Traceback ( most recent call last ) : file \"<stdin>\" , line 1 , in <module> StopIteration 4.2: Delegating Iteration Problem You have built a custom container object that internallt holds a list or tuple or other iterables . You want the iteration to work with this custom container. Solution Typically all you need to do is to define an internal iter() method that delegates iteration to internally held container as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Node : def __init__ ( self , value ): self . _value = value self . _children = [] def __repr__ ( self ): return f \"Node { self . _value !r} \" def add_child ( self , node ): self . _children . append ( node ) def __iter__ ( self ): return iter ( self . _children ) ## forwars the iteration request to the \"self._children\" ## ---------------------------------------------- ## if __naame__ == \"__main__\" : root = Node ( 0 ) child1 = Node ( 1 ) child2 = Node ( 2 ) root . add_child ( child1 ) root . add_child ( child2 ) for ch in root : print ( ch ) 1 2 >>> Node ( 1 ) Node ( 2 ) In the above example, the __iter__() method simply forwards the iteration request to the internally held self._children attribute. Discussion Python's iterator protocol requires the __iter__() method to return a special iterator object that implements a __next__() method which actually carries out the actual iteration. In the above example, we are delegating the implemeation of __next__() method by returning a list ( iter(self._children) ) which internally implements __iter__() . Calling the iter(x) function internally calls x.__iter__() . Note that this behaviour is similar to len(seq) and seq.__len__() 4.3: Creating new iteration patterns with GENERATORS","title":"4. Iterators & Generators"},{"location":"python/cookbook_dabeaz/ch04/#41-manually-consuming-an-iterator","text":"problem You wan tto consume items in an iterable but for whatever reasons you can't or don't want to use a for loop Solution To manually consume the iterable , use the next() function and write code to catch the StopIteration exception as shown below. 1 2 3 4 5 6 7 with open ( \"etc/passwd\" ) as f : try : while True : line = next ( f ) print ( line , end = \"\" ) except StopIteration : pass Normally StopIteration exception is used to signal the end of the sequence. But, if you are using next , you can instruct next() to return a terminating value like None as shown below. 1 2 3 4 5 6 7 with open ( \"etc/passwd\" ) as f : try : while True : line = next ( f , None ) if line is None : break print ( line , end = \"\" ) Discussion In most cases the for is used to consume the iterable. However every now and then a problem statement calls for precise control over the underlying mechanism. The below example explains what happens underneath the iteration protocol. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 >>> items = [ 1 , 2 , 3 ] ## the iterable >>> >>> ## Get the iterator >>> it = iter ( items ) ## invokes \"items.__iter__()\" >>> next ( it ) ## invokes \"items.__next__()\" 1 >>> next ( it ) 2 >>> next ( it ) 3 >>> next ( it ) ## this triggers \"StopIteration\" exception b'coz the iterator \"it\" is empty now Traceback ( most recent call last ) : file \"<stdin>\" , line 1 , in <module> StopIteration","title":"4.1: Manually consuming an iterator"},{"location":"python/cookbook_dabeaz/ch04/#42-delegating-iteration","text":"Problem You have built a custom container object that internallt holds a list or tuple or other iterables . You want the iteration to work with this custom container. Solution Typically all you need to do is to define an internal iter() method that delegates iteration to internally held container as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Node : def __init__ ( self , value ): self . _value = value self . _children = [] def __repr__ ( self ): return f \"Node { self . _value !r} \" def add_child ( self , node ): self . _children . append ( node ) def __iter__ ( self ): return iter ( self . _children ) ## forwars the iteration request to the \"self._children\" ## ---------------------------------------------- ## if __naame__ == \"__main__\" : root = Node ( 0 ) child1 = Node ( 1 ) child2 = Node ( 2 ) root . add_child ( child1 ) root . add_child ( child2 ) for ch in root : print ( ch ) 1 2 >>> Node ( 1 ) Node ( 2 ) In the above example, the __iter__() method simply forwards the iteration request to the internally held self._children attribute. Discussion Python's iterator protocol requires the __iter__() method to return a special iterator object that implements a __next__() method which actually carries out the actual iteration. In the above example, we are delegating the implemeation of __next__() method by returning a list ( iter(self._children) ) which internally implements __iter__() . Calling the iter(x) function internally calls x.__iter__() . Note that this behaviour is similar to len(seq) and seq.__len__()","title":"4.2: Delegating Iteration"},{"location":"python/cookbook_dabeaz/ch04/#43-creating-new-iteration-patterns-with-generators","text":"","title":"4.3: Creating new iteration patterns with GENERATORS"},{"location":"python/cookbook_dabeaz/ch05/","text":"","title":"5. Files & I/O"},{"location":"python/cookbook_dabeaz/ch06/","text":"","title":"6. Data Encoding & Processing"},{"location":"python/cookbook_dabeaz/ch07/","text":"Writing functions using def is a cornerstone of all programs. In this tutorial we will look into some of the advance usage of functions viz. closures callback-functions control-flow keyword-only arguments default-arguments annotations any-number-of-arguments ( *args & **kwargs ) etc. 7.1: Function with any number of arguments ( *args, **kwargs ) Problem You want to write a function that accepts any number of arguments. Solution For a function that accepts any number of positional arguments use a * argument. For a function that accepts any number of keyword arguments use a ** argument. To write any function that accepts any numbe rof positional arguments, use a * argument as shown below. In this example, rest is a tuple of all extra positional arguments passed. In above code, it is treated as a sequence in further calculations inside the function. 1 2 3 4 5 6 7 def avg ( first , * rest ): return ( first + sum ( rest )) / ( 1 + len ( rest )) ## ------------------------------------------------- ## avg ( 1 , 2 , 3 ) ## return=2.0; first=1, rest=(2, 3) avg ( 1 , 2 , 3 , 4 ) ## return=2.5; first=1, rest=(2, 3, 4) To accept any number of keyword arguments use a ** argument as shown below. In the below code, attrs is a dictionary that holds the passed keyword arguments (if any) 1 2 3 4 5 6 7 import html def make_element ( name , value , ** attrs ): keyvals = [ f \" { key } =' { val } '\" for key , val in atts . items ] attr_str = \"\" . join ( keyvals ) element = f \"< { name }{ attr_str } > { html . escape ( value ) } </ { value } >\" return element 1 2 ## Creates: \"<item size='large' quantity=6>Albatross</item>\" make_element ( \"item\" , \"Albatross\" , size = \"large\" , quantity = 6 ) 1 2 ## Creates: \"<p>&lt;spam&gt;</p>\" make_element ( p , \"<spam>\" ) If you want a function that accepts both any-number-of-positional-arguments aswell as any-number-of-keyword-arguments use both * & ** arguments as shown below 1 2 3 def anyargs ( * args , ** kwargs ): print ( args ) ## a tuple print ( kwargs ) ## a dictionary Discussion A * argument can only appear as the last positional argument in a function and a ** argumnet can only appear as the last argumnet in a function. A subtle aspect of function definition is that arguments can still appear after a * argument by they are treated as keyword argument only (as discussed in further lessons). 1 2 3 4 5 6 7 8 9 ## valid function definitions def a ( x , * args , y ): pass def b ( x , * args , y , ** kwargs ): pass ## WRONG function defintions ## here argument \"z\" appears after `**kwargs`; hence its a WRONG definition def c ( x , * args , ** kwargs , z ): pass 7.2: Keyword-only arguments Problem You want to write a function that accepts only keyword arguments . Solution This feature is easy to implement if you place the keyword argument after the * argument or a single unnamed * as shown below. 1 2 3 4 5 6 7 8 def recv ( maxsize , * , block ): \"\"\"Receives a message\"\"\" pass ##-------------------------------------## recv ( 1024 , True ) ## Type Error recv ( 2024 , block = True ) ## OK This technique can also be used to specify keyword arguments for functions that accept varying numbe rof positional arguments as shown below. 1 2 3 4 5 6 7 8 9 10 def minimum ( * values , clip = None ): m = min ( values ) if clip is not None : m = clip if clip > m else m return m ## ----------------------------------------- ## minimum ( 1 , 2 , 5 , - 5 , 10 ) ## -5 minimum ( 1 , 2 , 5 , - 5 , 10 , clip = 0 ) ## 0 Discussion Keyword-only arguments are a good way to enforce greater code-clarity when specifying optional function arguments. For example consider the following code: 1 msg = recv ( 1024 , False ) If someone is not familiar with recv (written in above section), they might not know what does False mean in this scenario. On the other hand, its much clearer to the user if someone writes the call as below: 1 msg = recv ( 1024 , block = False ) The use of keyword-only arguments is often very useful for tricks involving **kwargs , since they show up nicely when the user asks for help() 1 2 3 4 >>> help ( recv ) Help on function recv in module __main__: recv ( maxsize, *, block ) : \"\"\"Receives a message\"\"\" Keyword-only arguments also have utility in advance usage like argument injection using *args & **kwargs . 7.3: Function argument annotations Problem You've written a function but you want add some additional information about the arguments so that users can know more easily how a function is supposed to be used. Solution Function argument annotations can be very useful in givin gprogrammers hint about how a function is supposed to be used. Cosider the following annotated function. 1 2 3 4 5 6 7 ## normal function definition def add ( x , y ): return x + y ## Annotated function definition -- MUCH BETTER for users def add ( x : int , y : int ) -> int : return x + y The Python Interpreter does not add any semantic meaning to the attached annotations. Neither are they type-cheked nor does Puython behave any differently than before. However, they might give useful hunts about types that would be useful for users or third-party libraries. Any type of object can be uased as an annotation (eg. numbers, string, instances, types, etc.). Discussion Function annotations are merely stored in function's __annotations__ attribute. 1 2 3 4 5 >>> add . __annotations__ { \"y\" : < class \" int \">, \"return\" : < class \" int \">, \"x\" : < class \" int \">, } Although, annotations have many potential use-cases, their primary utility is probably just documentation . Because Python does not have type decalrations, it can be difficult to read a source code without much documentation and hind about the types of objects; function annotations are one way to resolve this problem. More advance usage of function annotations is to implement multiple dispatch (i.e. overloaded functions ) 7.7: Capturing variables in Anonymous functions Problem You have defined an anonymous function using lambda and but you also need to capture the value of certain variable at the tim eof definition. Solution Consider the behaviour of the following code a python console: 1 2 3 4 5 >>> x = 10 >>> a = lambda y : x + y >>> >>> x = 20 >>> b = lambda y : x + y Now ask yourself a question. What is the value of a(10) and b(10) now? If you think that the values will be 20 and 30 ; you would be wrong. The python console gives the follwoing results. 1 2 3 4 5 >>> a ( 10 ) 30 >>> >>> b ( 10 ) 30 The problem here is that x used here (in the lambda expression) is a free variable ; that gets bound at runtime , not at definition time . The value x in the lambda expression is whatever the value of x variable happens to be at the time of execution of the statement a(10), b(10) . For example see below code: 1 2 3 4 5 6 7 >>> x = 15 >>> a ( 10 ) 25 >>> >>> x = 3 >>> a ( 10 ) 13 If you want an anonymous lambda function to capture a value at the point of definition include that value as a default value in the lambda expression definition as follows. 1 2 3 4 5 6 7 8 9 10 11 >>> x = 10 >>> a = lambda y , x = x : x + y >>> >>> x = 20 >>> b = lambda y , x = x : x + y >>> >>> a ( 10 ) 20 ## Note the difference here from above code (earlier this was 30) >>> >>> b ( 10 ) 30 ## Note that \"b\" captured the correct value of \"x\" Discussion The problem addressed here comes up very often in code that tries to be a just a bit more clever. For example, creating a list of lambda expressions using a list comprehension or a loop of some kind and expecting the lambda expressions to remember the iteration variable at the time of defintion . For example: 1 2 3 4 5 6 7 8 9 10 >>> funcs = [ lambda x : x + n for n in range ( 5 )] >>> for f in funcs : ... print ( f ( 0 )) ... 4 4 4 4 4 >>> Notice, how all lambda expressions take the same final value of n from the range(5) expression. But, if we specifically captuer the value of n using default arguments , then we get the behaviour we want 1 2 3 4 5 6 7 8 9 10 >>> funcs = [ lambda x , n = n : x + n for n in range ( 5 )] >>> for f in funcs : ... print ( f ( 0 )) ... 0 1 2 3 4 >>> 7.8: functools.partial() Making an N-argumnet callable work asa callable with fewwer argumnets You have a callable that you want to make it work with other Python code. possbly as a callabel or handler , but it takes too many argumnets and causes an exception when called. Solution If you need to reduce the number of arguments to a function, you should use functools.partial() The partial() function allows you to assign fixed values to one or more of the arguments thus reduce the number of required argumnets in subsequent calls of the reduced function . as shown below. 1 2 def spam ( a , b , c , d ): print ( a , b , c , d ) Now consider functools.partial() to fix certain arguments. 1 2 3 4 5 >>> from functools import partial >>> >>> s1 = partial ( spam , 1 ) ## a=1 >>> s1 ( 2 , 3 , 4 ) ## note that it takes only 3 arguments 1 2 3 4 1 2 3 4 5 >>> s2 = partial ( spam , d = 42 ) ## d=42 >>> s2 ( 1 , 2 , 3 ) 1 2 3 42 >>> s2 ( 5 , 99 , 32 ) 5 99 32 42 1 2 3 4 >>> s3 = partial ( spam , 1 , 2 , d = 42 ) ## a=1, b=2, d=42 >>> s3 ( 99 ) 1 2 99 42 >>> Discussion ... 7.9: Replacing single method classes with functions Problem You have a class that only defines a single method except __init__() method. However, to simplify your code, you would much rather have a simple function. Solution In many cases, single method classes can be turned into functions using closures . Consider the following example, which allws users to fetch URLs using a kind of template-scheme . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from urllib.request import urlopen class UrlTemplate : def __init__ ( self , template ): self . template = template def open ( self , ** kwargs ): return urlopen ( self . template . format_map ( kwargs )) ## -------------------------------------------------------------------------------- ## ## Usage of above class ## Example Use: Download stock data from yahoo yahoo = UrlTemplate ( \"http://finance.yahoo.com/d/quotes.csv?s= {names} &f= {fields} \" ) for line in yahoo . open ( names = \"APPL, FB, TSLA\" , fields = \"sl1c1v\" ): print ( line . decode ( \"utf-8\" )) This URLTemplate class be very easily replaced with a much simpler function using closures . as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## Using closures from urllib.request import urlopen def url_template ( template ): def opener ( ** kwargs ): return urlopen ( template . format_map ( kwargs )) return opener ## ------------------------------------------------------------------------------- ## ## Example Usage of the above CLOSURE \"url_template\" yahoo = url_template ( \"http://finance.yahoo.com/d/quotes.csv?s= {names} &f= {fields} \" ) for line in yahoo ( names = \"APPL, FB, TSLA\" , fileds = \"sl1c1v\" ): print ( line . decode ( \"utf-8\" )) 7.10: Carrying extra state with callback functions Problem You are writing code that relies on the use of callback functions (e.g. event handlers , completion callback , etc.); but you want to have the callback function carry extra state to be used inside the callback function itself. Solution Let's first talk about callback functions which are used in asynchronous processing via the following example: 1 2 3 4 5 6 def apply_async ( func , args , * , callback ): ## compute the result result = func ( * args ) ## invoke the callback callback ( result ) In reality, such code might do all sorts of advanced processing involving threads, processes, & timers. But here we are just focusing on the invocation of the callback . Below, we show how to use the above code: 1 2 3 4 5 def print_result ( result ): print ( f \"Got: { result } \" ) def add ( x , y ): return x + y 1 2 3 4 >>> apply_async ( add , ( 2 , 3 ), callback = print_result ) Got : 5 >>> apply_result ( add , ( 'Hello\", \"World' ), callback = print_result ) Got : \"HelloWorld\" As you can notice above, the callbakc function print_result() only accepts a single argument i.e result . No other information is provided. This lack of information can be an issue when we want our callback function to interact with other contextual variables or other parts of the code. Below we provide some probable solutions to handle this issue: Some ways to carry extra information with callbacks: Use bound methods instead of regular sinple functions. Use closures Use coroutines . Using functools.partial() Using BOUND METHODS : One way to carry extra information in a callback is to use bound methods instead of simple function. For example, this below class keeps an internal sequence number that is incremented everytime a result is received. 1 2 3 4 5 6 class ResultHandler : def __init__ ( self ): self . sequence = 0 def handler ( self , result ): self . sequence += 1 print ( f \"[ { self . sequence } ] Got: { result } \" ) To use this class ResultHandler , we need to create its instance and use its handler() method as a callback. 1 2 3 4 5 >>> rh = ResultHandler () ## creating an instance of the class >>> apply_async ( add , ( 2 , 3 ), callback = rh . handler ) [ 1 ] Got : 5 >>> apply_async ( add , ( \"Hello\" , \"World\" ), callback = rh . handler ) [ 2 ] Got : \"HelloWorld\" Notice in the above output, how the instance of ResultHandler class rh uses its internal state variable self.sequence across two different calls of the callback function rh.handler . Using CLOSURES : As an alternative we can also use closures to embed additional information in the callback function. 1 2 3 4 5 6 7 def make_handler (): sequence = 0 def handler ( result ): nonlocal sequence sequence += 1 print ( f \"[ { sequence } ] Got: { result } \" ) return handler 1 2 3 4 5 >>> handler = make_handler () ## our callback function to be used >>> apply_async ( add , ( 2 , 3 ), callback = handler ) [ 1 ] Got : 5 >>> apply_async ( add , ( \"Hello\" , \"World\" ), callback = handler ) [ 2 ] Got : \"HelloWorld\" ## the callback remembers the count sequence Using COROUTINES : Sometimes we can also use a coroutine to accomplish what we achieved using a bound method or a closure . 1 2 3 4 5 6 7 8 ## Using COROUTINES to add context to a callback function def make_handler (): sequence = 0 while True : result = yield sequence += 1 print ( f \"[ { sequence } ] Got: { result } \" ) We can use it as usual as before. 1 2 3 4 5 >>> handler = make_handler () ## our callback function >>> apply_async ( add , ( 2 , 3 ), callback = handler . send ) [ 1 ] Got : 5 >>> apply_async ( add , ( \"Hello\" , \"WORLD!!\" ), callback = handler . send ) [ 2 ] Got : \"HelloWORLD!!\" NOTICE the use of send to push value to the yield in the callback coroutine Using functools.partial() : As an alternative, we can also carry state into a callback using an extra argument and a partial function application. 1 2 3 4 5 6 7 class SeqeunceNo : def __init__ ( self ): self . sequence = 0 def handler ( result , seq ): seq . sequence += 1 print ( f \"[ { seq . sequence } ] Got: { result } \" ) 1 2 3 4 5 6 >>> from functools import partial >>> seq = SequenceNo () >>> apply_async ( add , ( 2 , 3 ), callback = partial ( handler , seq = seq )) [ 1 ] Got : 5 >>> apply_async ( add , ( \"HELLO_\" , \"WORLD!!!\" ), callback = partial ( handler , seq = seq )) [ 2 ] Got : \"HELLO_WORLD!!!\" Because, lambda expressions can be very useful in creating partial functions. We can use lambda expressions (with added contextual argumnets) as callbacks as shown below. 1 2 3 >>> seq = SequenceNo () >>> apply_async ( add , ( 2 , 3 ), callback = lambda r : handler ( r , seq )) [ 1 ] Got : 5 Discussion Software based on callback functions often runs the risk of turning into a huge tangled mess. Part of the reason is that callback function is often disconnected from the code that made the initial request leading up the callback execution\". Thus the execution environment between making the request and handling the result is effectively lost. If you want the callback function to continue with a procedure involving multiple steps, you have to figure out how to save and restore the associated states. There are really two main promising ways to capture and restore context states: You can carry it around in a class instance . Attach it to bound method perhaps. Or you can carry it around in a closure (an inner function). Of the above two techniques, probably the closures approach is more natural and lightweight in that they are built from functions. They also automatically captures all the variables used. But, if using closures , we need to pay careful attention to mutable variables. In the above solution we use nonlocal declaration for variable sequence to specify that we were using the variable from withing the closure; otherwise we will get an ERROR . The use of coroutines is interesting and very closely resembles the usage of closures . In some sense, it is even cleaner as we don't have to worry about the nonlocal declarations. Only potential downsides of using coroutines is that its somewhat difficult to understand conceptually and we have to remembr some nitty-gritty details of its usage (for example, making sure to call next() before using the couroutine as a callback etc...) Nevertheless, coroutines are very useful in defining inlined callbacks .","title":"7. Functions"},{"location":"python/cookbook_dabeaz/ch07/#71-function-with-any-number-of-arguments-args-kwargs","text":"Problem You want to write a function that accepts any number of arguments. Solution For a function that accepts any number of positional arguments use a * argument. For a function that accepts any number of keyword arguments use a ** argument. To write any function that accepts any numbe rof positional arguments, use a * argument as shown below. In this example, rest is a tuple of all extra positional arguments passed. In above code, it is treated as a sequence in further calculations inside the function. 1 2 3 4 5 6 7 def avg ( first , * rest ): return ( first + sum ( rest )) / ( 1 + len ( rest )) ## ------------------------------------------------- ## avg ( 1 , 2 , 3 ) ## return=2.0; first=1, rest=(2, 3) avg ( 1 , 2 , 3 , 4 ) ## return=2.5; first=1, rest=(2, 3, 4) To accept any number of keyword arguments use a ** argument as shown below. In the below code, attrs is a dictionary that holds the passed keyword arguments (if any) 1 2 3 4 5 6 7 import html def make_element ( name , value , ** attrs ): keyvals = [ f \" { key } =' { val } '\" for key , val in atts . items ] attr_str = \"\" . join ( keyvals ) element = f \"< { name }{ attr_str } > { html . escape ( value ) } </ { value } >\" return element 1 2 ## Creates: \"<item size='large' quantity=6>Albatross</item>\" make_element ( \"item\" , \"Albatross\" , size = \"large\" , quantity = 6 ) 1 2 ## Creates: \"<p>&lt;spam&gt;</p>\" make_element ( p , \"<spam>\" ) If you want a function that accepts both any-number-of-positional-arguments aswell as any-number-of-keyword-arguments use both * & ** arguments as shown below 1 2 3 def anyargs ( * args , ** kwargs ): print ( args ) ## a tuple print ( kwargs ) ## a dictionary Discussion A * argument can only appear as the last positional argument in a function and a ** argumnet can only appear as the last argumnet in a function. A subtle aspect of function definition is that arguments can still appear after a * argument by they are treated as keyword argument only (as discussed in further lessons). 1 2 3 4 5 6 7 8 9 ## valid function definitions def a ( x , * args , y ): pass def b ( x , * args , y , ** kwargs ): pass ## WRONG function defintions ## here argument \"z\" appears after `**kwargs`; hence its a WRONG definition def c ( x , * args , ** kwargs , z ): pass","title":"7.1: Function with any number of arguments (*args, **kwargs)"},{"location":"python/cookbook_dabeaz/ch07/#72-keyword-only-arguments","text":"Problem You want to write a function that accepts only keyword arguments . Solution This feature is easy to implement if you place the keyword argument after the * argument or a single unnamed * as shown below. 1 2 3 4 5 6 7 8 def recv ( maxsize , * , block ): \"\"\"Receives a message\"\"\" pass ##-------------------------------------## recv ( 1024 , True ) ## Type Error recv ( 2024 , block = True ) ## OK This technique can also be used to specify keyword arguments for functions that accept varying numbe rof positional arguments as shown below. 1 2 3 4 5 6 7 8 9 10 def minimum ( * values , clip = None ): m = min ( values ) if clip is not None : m = clip if clip > m else m return m ## ----------------------------------------- ## minimum ( 1 , 2 , 5 , - 5 , 10 ) ## -5 minimum ( 1 , 2 , 5 , - 5 , 10 , clip = 0 ) ## 0 Discussion Keyword-only arguments are a good way to enforce greater code-clarity when specifying optional function arguments. For example consider the following code: 1 msg = recv ( 1024 , False ) If someone is not familiar with recv (written in above section), they might not know what does False mean in this scenario. On the other hand, its much clearer to the user if someone writes the call as below: 1 msg = recv ( 1024 , block = False ) The use of keyword-only arguments is often very useful for tricks involving **kwargs , since they show up nicely when the user asks for help() 1 2 3 4 >>> help ( recv ) Help on function recv in module __main__: recv ( maxsize, *, block ) : \"\"\"Receives a message\"\"\" Keyword-only arguments also have utility in advance usage like argument injection using *args & **kwargs .","title":"7.2: Keyword-only arguments"},{"location":"python/cookbook_dabeaz/ch07/#73-function-argument-annotations","text":"Problem You've written a function but you want add some additional information about the arguments so that users can know more easily how a function is supposed to be used. Solution Function argument annotations can be very useful in givin gprogrammers hint about how a function is supposed to be used. Cosider the following annotated function. 1 2 3 4 5 6 7 ## normal function definition def add ( x , y ): return x + y ## Annotated function definition -- MUCH BETTER for users def add ( x : int , y : int ) -> int : return x + y The Python Interpreter does not add any semantic meaning to the attached annotations. Neither are they type-cheked nor does Puython behave any differently than before. However, they might give useful hunts about types that would be useful for users or third-party libraries. Any type of object can be uased as an annotation (eg. numbers, string, instances, types, etc.). Discussion Function annotations are merely stored in function's __annotations__ attribute. 1 2 3 4 5 >>> add . __annotations__ { \"y\" : < class \" int \">, \"return\" : < class \" int \">, \"x\" : < class \" int \">, } Although, annotations have many potential use-cases, their primary utility is probably just documentation . Because Python does not have type decalrations, it can be difficult to read a source code without much documentation and hind about the types of objects; function annotations are one way to resolve this problem. More advance usage of function annotations is to implement multiple dispatch (i.e. overloaded functions )","title":"7.3: Function argument annotations"},{"location":"python/cookbook_dabeaz/ch07/#77-capturing-variables-in-anonymous-functions","text":"Problem You have defined an anonymous function using lambda and but you also need to capture the value of certain variable at the tim eof definition. Solution Consider the behaviour of the following code a python console: 1 2 3 4 5 >>> x = 10 >>> a = lambda y : x + y >>> >>> x = 20 >>> b = lambda y : x + y Now ask yourself a question. What is the value of a(10) and b(10) now? If you think that the values will be 20 and 30 ; you would be wrong. The python console gives the follwoing results. 1 2 3 4 5 >>> a ( 10 ) 30 >>> >>> b ( 10 ) 30 The problem here is that x used here (in the lambda expression) is a free variable ; that gets bound at runtime , not at definition time . The value x in the lambda expression is whatever the value of x variable happens to be at the time of execution of the statement a(10), b(10) . For example see below code: 1 2 3 4 5 6 7 >>> x = 15 >>> a ( 10 ) 25 >>> >>> x = 3 >>> a ( 10 ) 13 If you want an anonymous lambda function to capture a value at the point of definition include that value as a default value in the lambda expression definition as follows. 1 2 3 4 5 6 7 8 9 10 11 >>> x = 10 >>> a = lambda y , x = x : x + y >>> >>> x = 20 >>> b = lambda y , x = x : x + y >>> >>> a ( 10 ) 20 ## Note the difference here from above code (earlier this was 30) >>> >>> b ( 10 ) 30 ## Note that \"b\" captured the correct value of \"x\" Discussion The problem addressed here comes up very often in code that tries to be a just a bit more clever. For example, creating a list of lambda expressions using a list comprehension or a loop of some kind and expecting the lambda expressions to remember the iteration variable at the time of defintion . For example: 1 2 3 4 5 6 7 8 9 10 >>> funcs = [ lambda x : x + n for n in range ( 5 )] >>> for f in funcs : ... print ( f ( 0 )) ... 4 4 4 4 4 >>> Notice, how all lambda expressions take the same final value of n from the range(5) expression. But, if we specifically captuer the value of n using default arguments , then we get the behaviour we want 1 2 3 4 5 6 7 8 9 10 >>> funcs = [ lambda x , n = n : x + n for n in range ( 5 )] >>> for f in funcs : ... print ( f ( 0 )) ... 0 1 2 3 4 >>>","title":"7.7: Capturing variables in Anonymous functions"},{"location":"python/cookbook_dabeaz/ch07/#78-functoolspartial","text":"Making an N-argumnet callable work asa callable with fewwer argumnets You have a callable that you want to make it work with other Python code. possbly as a callabel or handler , but it takes too many argumnets and causes an exception when called. Solution If you need to reduce the number of arguments to a function, you should use functools.partial() The partial() function allows you to assign fixed values to one or more of the arguments thus reduce the number of required argumnets in subsequent calls of the reduced function . as shown below. 1 2 def spam ( a , b , c , d ): print ( a , b , c , d ) Now consider functools.partial() to fix certain arguments. 1 2 3 4 5 >>> from functools import partial >>> >>> s1 = partial ( spam , 1 ) ## a=1 >>> s1 ( 2 , 3 , 4 ) ## note that it takes only 3 arguments 1 2 3 4 1 2 3 4 5 >>> s2 = partial ( spam , d = 42 ) ## d=42 >>> s2 ( 1 , 2 , 3 ) 1 2 3 42 >>> s2 ( 5 , 99 , 32 ) 5 99 32 42 1 2 3 4 >>> s3 = partial ( spam , 1 , 2 , d = 42 ) ## a=1, b=2, d=42 >>> s3 ( 99 ) 1 2 99 42 >>> Discussion ...","title":"7.8: functools.partial()"},{"location":"python/cookbook_dabeaz/ch07/#79-replacing-single-method-classes-with-functions","text":"Problem You have a class that only defines a single method except __init__() method. However, to simplify your code, you would much rather have a simple function. Solution In many cases, single method classes can be turned into functions using closures . Consider the following example, which allws users to fetch URLs using a kind of template-scheme . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from urllib.request import urlopen class UrlTemplate : def __init__ ( self , template ): self . template = template def open ( self , ** kwargs ): return urlopen ( self . template . format_map ( kwargs )) ## -------------------------------------------------------------------------------- ## ## Usage of above class ## Example Use: Download stock data from yahoo yahoo = UrlTemplate ( \"http://finance.yahoo.com/d/quotes.csv?s= {names} &f= {fields} \" ) for line in yahoo . open ( names = \"APPL, FB, TSLA\" , fields = \"sl1c1v\" ): print ( line . decode ( \"utf-8\" )) This URLTemplate class be very easily replaced with a much simpler function using closures . as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## Using closures from urllib.request import urlopen def url_template ( template ): def opener ( ** kwargs ): return urlopen ( template . format_map ( kwargs )) return opener ## ------------------------------------------------------------------------------- ## ## Example Usage of the above CLOSURE \"url_template\" yahoo = url_template ( \"http://finance.yahoo.com/d/quotes.csv?s= {names} &f= {fields} \" ) for line in yahoo ( names = \"APPL, FB, TSLA\" , fileds = \"sl1c1v\" ): print ( line . decode ( \"utf-8\" ))","title":"7.9: Replacing single method classes with functions"},{"location":"python/cookbook_dabeaz/ch07/#710-carrying-extra-state-with-callback-functions","text":"Problem You are writing code that relies on the use of callback functions (e.g. event handlers , completion callback , etc.); but you want to have the callback function carry extra state to be used inside the callback function itself. Solution Let's first talk about callback functions which are used in asynchronous processing via the following example: 1 2 3 4 5 6 def apply_async ( func , args , * , callback ): ## compute the result result = func ( * args ) ## invoke the callback callback ( result ) In reality, such code might do all sorts of advanced processing involving threads, processes, & timers. But here we are just focusing on the invocation of the callback . Below, we show how to use the above code: 1 2 3 4 5 def print_result ( result ): print ( f \"Got: { result } \" ) def add ( x , y ): return x + y 1 2 3 4 >>> apply_async ( add , ( 2 , 3 ), callback = print_result ) Got : 5 >>> apply_result ( add , ( 'Hello\", \"World' ), callback = print_result ) Got : \"HelloWorld\" As you can notice above, the callbakc function print_result() only accepts a single argument i.e result . No other information is provided. This lack of information can be an issue when we want our callback function to interact with other contextual variables or other parts of the code. Below we provide some probable solutions to handle this issue: Some ways to carry extra information with callbacks: Use bound methods instead of regular sinple functions. Use closures Use coroutines . Using functools.partial() Using BOUND METHODS : One way to carry extra information in a callback is to use bound methods instead of simple function. For example, this below class keeps an internal sequence number that is incremented everytime a result is received. 1 2 3 4 5 6 class ResultHandler : def __init__ ( self ): self . sequence = 0 def handler ( self , result ): self . sequence += 1 print ( f \"[ { self . sequence } ] Got: { result } \" ) To use this class ResultHandler , we need to create its instance and use its handler() method as a callback. 1 2 3 4 5 >>> rh = ResultHandler () ## creating an instance of the class >>> apply_async ( add , ( 2 , 3 ), callback = rh . handler ) [ 1 ] Got : 5 >>> apply_async ( add , ( \"Hello\" , \"World\" ), callback = rh . handler ) [ 2 ] Got : \"HelloWorld\" Notice in the above output, how the instance of ResultHandler class rh uses its internal state variable self.sequence across two different calls of the callback function rh.handler . Using CLOSURES : As an alternative we can also use closures to embed additional information in the callback function. 1 2 3 4 5 6 7 def make_handler (): sequence = 0 def handler ( result ): nonlocal sequence sequence += 1 print ( f \"[ { sequence } ] Got: { result } \" ) return handler 1 2 3 4 5 >>> handler = make_handler () ## our callback function to be used >>> apply_async ( add , ( 2 , 3 ), callback = handler ) [ 1 ] Got : 5 >>> apply_async ( add , ( \"Hello\" , \"World\" ), callback = handler ) [ 2 ] Got : \"HelloWorld\" ## the callback remembers the count sequence Using COROUTINES : Sometimes we can also use a coroutine to accomplish what we achieved using a bound method or a closure . 1 2 3 4 5 6 7 8 ## Using COROUTINES to add context to a callback function def make_handler (): sequence = 0 while True : result = yield sequence += 1 print ( f \"[ { sequence } ] Got: { result } \" ) We can use it as usual as before. 1 2 3 4 5 >>> handler = make_handler () ## our callback function >>> apply_async ( add , ( 2 , 3 ), callback = handler . send ) [ 1 ] Got : 5 >>> apply_async ( add , ( \"Hello\" , \"WORLD!!\" ), callback = handler . send ) [ 2 ] Got : \"HelloWORLD!!\" NOTICE the use of send to push value to the yield in the callback coroutine Using functools.partial() : As an alternative, we can also carry state into a callback using an extra argument and a partial function application. 1 2 3 4 5 6 7 class SeqeunceNo : def __init__ ( self ): self . sequence = 0 def handler ( result , seq ): seq . sequence += 1 print ( f \"[ { seq . sequence } ] Got: { result } \" ) 1 2 3 4 5 6 >>> from functools import partial >>> seq = SequenceNo () >>> apply_async ( add , ( 2 , 3 ), callback = partial ( handler , seq = seq )) [ 1 ] Got : 5 >>> apply_async ( add , ( \"HELLO_\" , \"WORLD!!!\" ), callback = partial ( handler , seq = seq )) [ 2 ] Got : \"HELLO_WORLD!!!\" Because, lambda expressions can be very useful in creating partial functions. We can use lambda expressions (with added contextual argumnets) as callbacks as shown below. 1 2 3 >>> seq = SequenceNo () >>> apply_async ( add , ( 2 , 3 ), callback = lambda r : handler ( r , seq )) [ 1 ] Got : 5 Discussion Software based on callback functions often runs the risk of turning into a huge tangled mess. Part of the reason is that callback function is often disconnected from the code that made the initial request leading up the callback execution\". Thus the execution environment between making the request and handling the result is effectively lost. If you want the callback function to continue with a procedure involving multiple steps, you have to figure out how to save and restore the associated states. There are really two main promising ways to capture and restore context states: You can carry it around in a class instance . Attach it to bound method perhaps. Or you can carry it around in a closure (an inner function). Of the above two techniques, probably the closures approach is more natural and lightweight in that they are built from functions. They also automatically captures all the variables used. But, if using closures , we need to pay careful attention to mutable variables. In the above solution we use nonlocal declaration for variable sequence to specify that we were using the variable from withing the closure; otherwise we will get an ERROR . The use of coroutines is interesting and very closely resembles the usage of closures . In some sense, it is even cleaner as we don't have to worry about the nonlocal declarations. Only potential downsides of using coroutines is that its somewhat difficult to understand conceptually and we have to remembr some nitty-gritty details of its usage (for example, making sure to call next() before using the couroutine as a callback etc...) Nevertheless, coroutines are very useful in defining inlined callbacks .","title":"7.10: Carrying extra state with callback functions"},{"location":"python/cookbook_dabeaz/ch08/","text":"The primary focus in this article is to provide common programming patterns related to class definitions. Some of the topics include: Making objects support common Python features. usage of special methods. Encapsulation techniques. Inheritence. Memory management. Useful Design Patterns. 8.1: str () & repr () Problem You want to change the output produced by printing or viewing instances to something more sensible. Solution To change the string representation of the class instances define __str__() & __repr__() methods as shown below. 1 2 3 4 5 6 7 8 class Pair : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return \"( {0.x!s} , {0.y!s} )\" . format ( self ) def __repr__ ( self ): return \"Pair( {0.x!r} , {0.y!r} )\" . format ( self ) The __repr__() method returns the code represntation of the instance, and is usually the code you would type to re-create the instance. The built-in repr() function returns this text and so does the interactive interpreter while inspecting values. The __str__() method converts the instance to a string and is the output returned by print() or str() methods. 1 2 3 4 5 >>> p = Pair ( 2 , 3 ) >>> p Pair ( 2 , 3 ) ## __repr__() output >>> print ( p ) >>> ( 2 , 3 ) ## __str__() output The implementation of the above class also show how different string representations may be used during formatting. Specifically, the special !r formatting code indicates that the output of __repr__() should be used instead of __str__() , the default. An example below shows this behavior: 1 2 3 4 5 >>> p = Pair ( 3 , 4 ) >>> print ( \"p is {0!r} \" ) . format ( p ) p is Pair ( 3 , 4 ) >>> print ( \"p is {0!s} \" ) . format ( p ) p is ( 3 , 4 ) Discussion It is standard practice to for the output of __repr__() to produce text such that eval(repr(x)) == x If it is not prossible or desired then it is common to create a textual represntation enclosed in < & > instead as shown in below snippet. 1 2 3 >>> f = open ( \"file.dat\" ) >>> f < _io . TextIOWrapper name = 'file.dat' mode = 'r' encoding = 'utf-8' > If not __str__() is provided then __repr__() is used as a fallback. 8.2: Customizing string formatting Problem You want an object to support customized formatting through the formaat() function and string method. Solution To customize string formatting, define a custom __format__() method in the class definition. For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## The format codes ## _formats = { \"ymd\" : \" {d.year} - {d.month} - {d.day} \" , \"mdy\" : \" {d.month} / {d.day} / {d.year} \" , \"dmy\" : \" {d.day} / {d.month} / {d.year} \" } ## ----------------------------------------------- ## class date : def __init__ ( self , day , month , year ): self . day = day self . month = month self . year = year def __format__ ( self , code ): if code == \"\" : code = \"ymd\" fmt = _formats [ code ] return fmt . format ( d = self ) Instances of Date now supports formatting options such as the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d = Date ( 15 , 11 , 2021 ) >>> >>> format ( d ) '2021-11-15' >>> >>> format ( d , \"mdy\" ) '11-15-2021' >>> >>> \"The date is {:ymd}\" . format ( d ) 'The date is 2021-11-15' >>> >>> \"The date is {:mdy}\" . format ( d ) 'The date is 11-15-2021' The __format__() method provides HOOK into Python's string formatting functionality. Its important to know that the interpretation of the format codes (e.g. _formats in above code) is entirely upto the class defintion and developer. 8.6: Creating managed attributes Problem You want to add extra processing (e.e. type checking, validation) to the getting and setting of the instance attributes Solution A simple way to customize access to an attribute is to define it as property . For example, in below code, we define a property that adds simple type checking for its getter and setter methods. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Person : def __init__ ( self , first_name ): self . first_name = first_name ## NOTE: I'm defining \"self.first_name\" not \"self._first_name\" ## getter method @property def first_name ( self ): return self . _first_name ## setter method @first_name . setter def first_name ( self , value ): if not isinstance ( value , str ): raise TypeError ( \"Expected a string\" ) self . _first_name = value ## deleter method @first_name . deleter def first_name ( self ): raise AttributeError ( \"Can't delete attribute\" ) 8.9: Descriptor Class Creating a new kind of class or instance attribute You want to create a new kind of class with instance atrribute type with some extra functionality such as type checking Solution If you want to create an entirely new kind of instance attribute, define its functionality in the form of a descriptor class . For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## Descriptor attribute for an integer type-checked attribute class Integer : def __init__ ( self , name ): self . name = name def __get__ ( self , instance , cls ): if instance is None : return self else : return instance . __dict__ [ self . name ] def __set__ ( self , instance , val ): if not isinstance ( val , int ): raise TypeError ( \"Expected to be an int\" ) instance . __dict__ [ self . name ] = val def __delete__ ( self , instance ): del instance . __dict__ [ self . name ] A Descriptor is a class that implements three core attribute access operations (get, set, delete) via the special methods __get__(), __set__(), __delete__() . These methods work by receiving an instance as input. The underlying dictionary of the instance is then manipulated as appropriate. To use a descriptor, instances of the descriptor are placed into the class defintion as class variables as shown below. 1 2 3 4 5 6 7 8 ## Using a Descriptor in a class defintion class Point : x = Integer ( \"x\" ) y = Integer ( \"y\" ) def __init__ ( self , x , y ): self . x = x self . y = y When we do this, all access to the descriptor attributes ( x, y ) are captured by __get__(), __set__(), __delete__() methods of the descriptor class. For example: 1 2 3 4 5 6 7 8 >>> p = Point ( 2 , 3 ) >>> >>> p . x ## calls \"Point.x.__get__(p, Point)\" 2 >>> p . y = 5 ## calls \"Point.y.__set__(p, Point)\" >>> p . x = 2.5 ## calls \"Point.x.__set__(p, Point)\" ... TypeError : Expected an int As input, each method of the descriptor receives the instance being manipulated. To carry out the requested operation, the underlying instance dictionary (underlying __dict__() attribute) is manipulated. The self.name attribute of the descriptor holds the dictionary key being used to store the actual data in the instance dictionary. Discussion Descriptors provide the underlying logic for most of the Python's class features such as @classmethod , @staticmethod , @property and even __slots__ attribute. By defining descriptors , you can capture the core instance oprtations (get, set, delete) at a very low level and completely customoze what they do. It is one of the most important tool used by writers of most advance librarues & frameeeeworks One confusion with the descriptors is that they can only be defined at the class level and not at the per-instance basis . The following descriptor usage will not work. 1 2 3 4 5 6 7 8 ## this descriptor USAGE will not work class Point : def __init__ ( self , x , y ): self . x = Integer ( \"x\" ) ## NO! Must be a class variable self . y = Integer ( \"y\" ) ## NO! Must be a class variable self . x = x self . y = y 8.13: Implementing a Data Model or Type System Problem You want to define various kinds of Data Structures, but want to enforce constraints on the values that are allowed to be assigned to certain constraints. Solution ...","title":"8. Classes & Objects"},{"location":"python/cookbook_dabeaz/ch08/#81-str-repr","text":"Problem You want to change the output produced by printing or viewing instances to something more sensible. Solution To change the string representation of the class instances define __str__() & __repr__() methods as shown below. 1 2 3 4 5 6 7 8 class Pair : def __init__ ( self , x , y ): self . x = x self . y = y def __str__ ( self ): return \"( {0.x!s} , {0.y!s} )\" . format ( self ) def __repr__ ( self ): return \"Pair( {0.x!r} , {0.y!r} )\" . format ( self ) The __repr__() method returns the code represntation of the instance, and is usually the code you would type to re-create the instance. The built-in repr() function returns this text and so does the interactive interpreter while inspecting values. The __str__() method converts the instance to a string and is the output returned by print() or str() methods. 1 2 3 4 5 >>> p = Pair ( 2 , 3 ) >>> p Pair ( 2 , 3 ) ## __repr__() output >>> print ( p ) >>> ( 2 , 3 ) ## __str__() output The implementation of the above class also show how different string representations may be used during formatting. Specifically, the special !r formatting code indicates that the output of __repr__() should be used instead of __str__() , the default. An example below shows this behavior: 1 2 3 4 5 >>> p = Pair ( 3 , 4 ) >>> print ( \"p is {0!r} \" ) . format ( p ) p is Pair ( 3 , 4 ) >>> print ( \"p is {0!s} \" ) . format ( p ) p is ( 3 , 4 ) Discussion It is standard practice to for the output of __repr__() to produce text such that eval(repr(x)) == x If it is not prossible or desired then it is common to create a textual represntation enclosed in < & > instead as shown in below snippet. 1 2 3 >>> f = open ( \"file.dat\" ) >>> f < _io . TextIOWrapper name = 'file.dat' mode = 'r' encoding = 'utf-8' > If not __str__() is provided then __repr__() is used as a fallback.","title":"8.1: str() &amp; repr()"},{"location":"python/cookbook_dabeaz/ch08/#82-customizing-string-formatting","text":"Problem You want an object to support customized formatting through the formaat() function and string method. Solution To customize string formatting, define a custom __format__() method in the class definition. For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## The format codes ## _formats = { \"ymd\" : \" {d.year} - {d.month} - {d.day} \" , \"mdy\" : \" {d.month} / {d.day} / {d.year} \" , \"dmy\" : \" {d.day} / {d.month} / {d.year} \" } ## ----------------------------------------------- ## class date : def __init__ ( self , day , month , year ): self . day = day self . month = month self . year = year def __format__ ( self , code ): if code == \"\" : code = \"ymd\" fmt = _formats [ code ] return fmt . format ( d = self ) Instances of Date now supports formatting options such as the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> d = Date ( 15 , 11 , 2021 ) >>> >>> format ( d ) '2021-11-15' >>> >>> format ( d , \"mdy\" ) '11-15-2021' >>> >>> \"The date is {:ymd}\" . format ( d ) 'The date is 2021-11-15' >>> >>> \"The date is {:mdy}\" . format ( d ) 'The date is 11-15-2021' The __format__() method provides HOOK into Python's string formatting functionality. Its important to know that the interpretation of the format codes (e.g. _formats in above code) is entirely upto the class defintion and developer.","title":"8.2: Customizing string formatting"},{"location":"python/cookbook_dabeaz/ch08/#86-creating-managed-attributes","text":"Problem You want to add extra processing (e.e. type checking, validation) to the getting and setting of the instance attributes Solution A simple way to customize access to an attribute is to define it as property . For example, in below code, we define a property that adds simple type checking for its getter and setter methods. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Person : def __init__ ( self , first_name ): self . first_name = first_name ## NOTE: I'm defining \"self.first_name\" not \"self._first_name\" ## getter method @property def first_name ( self ): return self . _first_name ## setter method @first_name . setter def first_name ( self , value ): if not isinstance ( value , str ): raise TypeError ( \"Expected a string\" ) self . _first_name = value ## deleter method @first_name . deleter def first_name ( self ): raise AttributeError ( \"Can't delete attribute\" )","title":"8.6: Creating managed attributes"},{"location":"python/cookbook_dabeaz/ch08/#89-descriptor-class","text":"Creating a new kind of class or instance attribute You want to create a new kind of class with instance atrribute type with some extra functionality such as type checking Solution If you want to create an entirely new kind of instance attribute, define its functionality in the form of a descriptor class . For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## Descriptor attribute for an integer type-checked attribute class Integer : def __init__ ( self , name ): self . name = name def __get__ ( self , instance , cls ): if instance is None : return self else : return instance . __dict__ [ self . name ] def __set__ ( self , instance , val ): if not isinstance ( val , int ): raise TypeError ( \"Expected to be an int\" ) instance . __dict__ [ self . name ] = val def __delete__ ( self , instance ): del instance . __dict__ [ self . name ] A Descriptor is a class that implements three core attribute access operations (get, set, delete) via the special methods __get__(), __set__(), __delete__() . These methods work by receiving an instance as input. The underlying dictionary of the instance is then manipulated as appropriate. To use a descriptor, instances of the descriptor are placed into the class defintion as class variables as shown below. 1 2 3 4 5 6 7 8 ## Using a Descriptor in a class defintion class Point : x = Integer ( \"x\" ) y = Integer ( \"y\" ) def __init__ ( self , x , y ): self . x = x self . y = y When we do this, all access to the descriptor attributes ( x, y ) are captured by __get__(), __set__(), __delete__() methods of the descriptor class. For example: 1 2 3 4 5 6 7 8 >>> p = Point ( 2 , 3 ) >>> >>> p . x ## calls \"Point.x.__get__(p, Point)\" 2 >>> p . y = 5 ## calls \"Point.y.__set__(p, Point)\" >>> p . x = 2.5 ## calls \"Point.x.__set__(p, Point)\" ... TypeError : Expected an int As input, each method of the descriptor receives the instance being manipulated. To carry out the requested operation, the underlying instance dictionary (underlying __dict__() attribute) is manipulated. The self.name attribute of the descriptor holds the dictionary key being used to store the actual data in the instance dictionary. Discussion Descriptors provide the underlying logic for most of the Python's class features such as @classmethod , @staticmethod , @property and even __slots__ attribute. By defining descriptors , you can capture the core instance oprtations (get, set, delete) at a very low level and completely customoze what they do. It is one of the most important tool used by writers of most advance librarues & frameeeeworks One confusion with the descriptors is that they can only be defined at the class level and not at the per-instance basis . The following descriptor usage will not work. 1 2 3 4 5 6 7 8 ## this descriptor USAGE will not work class Point : def __init__ ( self , x , y ): self . x = Integer ( \"x\" ) ## NO! Must be a class variable self . y = Integer ( \"y\" ) ## NO! Must be a class variable self . x = x self . y = y","title":"8.9: Descriptor Class"},{"location":"python/cookbook_dabeaz/ch08/#813-implementing-a-data-model-or-type-system","text":"Problem You want to define various kinds of Data Structures, but want to enforce constraints on the values that are allowed to be assigned to certain constraints. Solution ...","title":"8.13: Implementing a Data Model or Type System"},{"location":"python/cookbook_dabeaz/ch09/","text":"","title":"9. Metaprogramming"},{"location":"python/cookbook_dabeaz/ch10/","text":"","title":"10. Modules & Packages"},{"location":"python/cookbook_dabeaz/ch11/","text":"","title":"Ch11"},{"location":"python/cookbook_dabeaz/ch12/","text":"","title":"12. Concurrency"},{"location":"python/cookbook_dabeaz/ch13/","text":"","title":"Ch13"},{"location":"python/cookbook_dabeaz/ch14/","text":"","title":"14. Testing, Debugging & Exceptions"},{"location":"python/cookbook_dabeaz/ch15/","text":"","title":"Ch15"},{"location":"transformers/about/","text":"References: Transformers explained: https://e2eml.school/transformers.html \u21a9 Positional Embeddings: https://kazemnejad.com/blog/transformer_architecture_positional_encoding/ \u21a9 Positional Embeddings: https://timodenk.com/blog/linear-relationships-in-the-transformers-positional-encoding/ \u21a9 POS Summation v/s Concat: https://github.com/tensorflow/tensor2tensor/issues/1591 \u21a9","title":"About"},{"location":"transformers/about/#references","text":"Transformers explained: https://e2eml.school/transformers.html \u21a9 Positional Embeddings: https://kazemnejad.com/blog/transformer_architecture_positional_encoding/ \u21a9 Positional Embeddings: https://timodenk.com/blog/linear-relationships-in-the-transformers-positional-encoding/ \u21a9 POS Summation v/s Concat: https://github.com/tensorflow/tensor2tensor/issues/1591 \u21a9","title":"References:"},{"location":"transformers/detr/","text":"ArXiv paper Review Presentation Slides","title":"DETR"},{"location":"transformers/detr/#arxiv-paper","text":"","title":"ArXiv paper"},{"location":"transformers/detr/#review-presentation-slides","text":"","title":"Review Presentation Slides"},{"location":"transformers/vaswani/","text":"","title":"Vaswani et al."},{"location":"work/about/","text":"Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque import torch as pt import pytorch_lightning as pl class FlashModel(pl.LightningModule): \"\"\"This defines a MODEL\"\"\" 1 2 3 4 5 def __init__(self, num_layers: int = 3): super().__init__() self.layer1 = pt.nn.Linear() self.layer2 = pt.nn.Linear() self.layer3 = pt.nn.Linear() class FlashModel(pl.LightningModule): \"\"\"This defines a SYSTEM\"\"\" 1 2 3 4 5 6 def __init__(self, encoder: pt.nn.Module = None, decoder: pt.nn.Module = None): super().__init__() self.encoder = encoder self.decoder = decoder","title":"About"},{"location":"work/about/#_1","text":"class FlashModel(pl.LightningModule): \"\"\"This defines a MODEL\"\"\" 1 2 3 4 5 def __init__(self, num_layers: int = 3): super().__init__() self.layer1 = pt.nn.Linear() self.layer2 = pt.nn.Linear() self.layer3 = pt.nn.Linear() class FlashModel(pl.LightningModule): \"\"\"This defines a SYSTEM\"\"\" 1 2 3 4 5 6 def __init__(self, encoder: pt.nn.Module = None, decoder: pt.nn.Module = None): super().__init__() self.encoder = encoder self.decoder = decoder","title":""},{"location":"work/aros/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Aros"},{"location":"work/cognizant/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Cognizant"},{"location":"work/flashai/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Flashai"},{"location":"work/ivmcl/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Ivmcl"},{"location":"work/meeami/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ##################################################################### ## \u092a\u094d\u0930\u094b\u091c\u0947\u0915\u094d\u091f-\u0936\u093f\u0915\u094d\u0937\u093e ##################################################################### def \u0935\u093f\u092d\u093e\u0917 ( \u092d\u093e\u091c\u094d\u092f , \u092d\u093e\u091c\u0915 ): \u092d\u093e\u0917\u092b\u0932 = 0 \u092d\u093e\u0917 = 1 \u0936\u0947\u0937\u092b\u0932 = 0 print ( f \"-----------------------------------\" ) print ( f \"\u092d\u093e\u091c\u094d\u092f - (\u092d\u093e\u091c\u0915 x \u092d\u093e\u0917) = \u0936\u0947\u0937 [?] \u092d\u093e\u091c\u0915\" ) print ( f \"-----------------------------------\" ) if \u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 : # print raise ValueError ( f \"\u092d\u093e\u091c\u094d\u092f < \u092d\u093e\u091c\u0915 [\u0917\u093c\u0932\u0924 \u0938\u0902\u0916\u094d\u092f\u093e\u090f\u0901 \u0926\u0940 \u0917\u092f\u0940\u0902. \u0915\u0943\u092a\u092f\u093e \u0938\u0939\u0940 \u0938\u0902\u0916\u094d\u092f\u093e \u0905\u0902\u0915\u093f\u0924 \u0915\u0930\u0947\u0902.]\" ) while True : \u0936\u0947\u0937 = \u092d\u093e\u091c\u094d\u092f - ( \u092d\u093e\u091c\u0915 * \u092d\u093e\u0917 ) if \u0936\u0947\u0937 >= \u092d\u093e\u091c\u0915 : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } > { \u092d\u093e\u091c\u0915 } \" ) \u092d\u093e\u0917 = \u092d\u093e\u0917 + 1 else : print ( f \" { \u092d\u093e\u091c\u094d\u092f } - ( { \u092d\u093e\u091c\u0915 } x { \u092d\u093e\u0917 } ) = { \u0936\u0947\u0937 } < { \u092d\u093e\u091c\u0915 } .\u0938\u092e\u093e\u092a\u094d\u0924\" ) \u092d\u093e\u0917\u092b\u0932 = \u092d\u093e\u0917 \u0936\u0947\u0937\u092b\u0932 = \u0936\u0947\u0937 print ( f \"-----------------------------------\" ) return { \"\u092d\u093e\u0917\u092b\u0932\" : \u092d\u093e\u0917\u092b\u0932 , \"\u0936\u0947\u0937\u092b\u0932\" : \u0936\u0947\u0937\u092b\u0932 } ##################################################################### lorem ipsum Image caption Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b\\in G\\) with \\(a\\neq b\\) such that \\(f(a)=f(b)\\) . The HTML specification is maintained by the W3C .","title":"Meeami"},{"location":"work/springboard/","text":"","title":"Springboard"}]}